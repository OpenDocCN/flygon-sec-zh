- en: Bypassing Machine Learning Malware Detectors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绕过机器学习恶意软件检测器
- en: In the previous chapter, you learned that you can break into machine learning
    models and make them perform malicious activities by using adversarial machine
    learning techniques. In this chapter, we are going to explore further techniques,
    like how to fool artificial neural networks and deep learning networks. We are
    going to look at anti-malware system evasion as a case study.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您了解到可以通过使用对抗性机器学习技术攻击机器学习模型并使其执行恶意活动。在本章中，我们将进一步探讨如何欺骗人工神经网络和深度学习网络等技术。我们将以反恶意软件系统规避为案例研究。
- en: 'In this chapter, we will cover the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Adversarial deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对抗性深度学习
- en: How to bypass next generation malware detectors with generative adversarial
    networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用生成对抗网络绕过下一代恶意软件检测器
- en: Bypassing machine learning with reinforcement learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用强化学习绕过机器学习
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can find the code files for this chapter at [https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter09](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter09).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在[https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter09](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter09)找到。
- en: Adversarial deep learning
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗性深度学习
- en: Information security professionals are doing their best to come up with novel
    techniques to detect malware and malicious software. One of the trending techniques
    is using the power of machine learning algorithms to detect malware. On the other
    hand, attackers and cyber criminals are also coming up with new approaches to
    bypass next-generation systems. In the previous chapter, we looked at how to attack
    machine learning models and how to bypass intrusion detection systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 信息安全专业人员正在尽力提出新技术来检测恶意软件和恶意软件。其中一种流行的技术是使用机器学习算法来检测恶意软件。另一方面，攻击者和网络犯罪分子也在想出新方法来绕过下一代系统。在上一章中，我们看了如何攻击机器学习模型以及如何绕过入侵检测系统。
- en: 'Malware developers use many techniques to bypass machine learning malware detectors.
    Previously, we explored an approach to build malware classifiers by training the
    system with grayscale image vectors. In a demonstration done by the **Search And
    RetrieVAl of Malware** (**SARVAM**) research unit, at the Vision Research Lab,
    UCSB, the researchers illustrated that, by changing a few bytes, a model can classify
    a malware as a goodware. This technique can be performed by attackers to bypass
    malware classifiers, through changing a few bytes and pixels. In the demonstration,
    the researchers used a variant of the NETSTAT program, which is a command-line
    network utility tool that displays network connections. In the following image,
    the left-hand side is a representation of the `NETSTAT.EXE` malware, and the second
    is detected as a goodware. As you can see, the difference between the two programs
    is unnoticeable (88 bytes out of 36,864 bytes: 0.78%), after converting the two
    types of files into grayscale images and checking the differences between the
    two of them:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 恶意软件开发人员使用许多技术来绕过机器学习恶意软件检测器。之前，我们探讨了一种通过使用灰度图像向量训练系统来构建恶意软件分类器的方法。在由** SARVAM
    **（**恶意软件搜索和检索**）研究单位在UCSB的Vision Research Lab进行的演示中，研究人员说明了通过更改几个字节，模型可以将恶意软件分类为良性软件。攻击者可以通过更改几个字节和像素来绕过恶意软件分类器执行此技术。在演示中，研究人员使用了NETSTAT程序的变体，这是一个显示网络连接的命令行网络实用工具。在下图中，左侧是`NETSTAT.EXE`恶意软件的表示，第二个被检测为良性软件。如您所见，两个程序之间的差异是不可察觉的（36,864字节中的88字节：0.78%），在将两种文件类型转换为灰度图像并检查它们之间的差异后：
- en: '![](img/00202.gif)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00202.gif)'
- en: This technique is just the beginning; in this chapter, we are going to dive
    deep into how we can trick them (the machine learning model, in our case the malware
    classifier) into performing malicious activities.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术只是一个开始；在本章中，我们将深入探讨如何欺骗它们（在我们的案例中是恶意软件分类器的机器学习模型）执行恶意活动。
- en: 'The previous chapter was an overview of adversarial machine learning. We learned
    how machine learning can be bypassed by attackers. In this chapter, we are going
    to go deeper, discovering how to bypass malware machine learning based detectors;
    before that, we are going to learn how to fool artificial neural networks and
    avoid deep learning networks with Python, open source libraries, and open source
    projects. Neural networks can be tricked by **adversarial samples**. Adversarial
    samples are used as inputs to the neural network, to influence the learning outcome.
    A pioneering research project, called *Explaining and Harnessing Adversarial Networks,* conducted
    by Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy (at Google), showed
    that a small amount of carefully constructed noise can fool the neural network
    into thinking that the entered image is an image of a gibbon and not a panda,
    with 99.3% confidence. The neural network originally thought that the provided
    image was a panda, with 57.7% confidence, which is true; but it is not the case
    in the second example, after fooling the network:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章是对对抗性机器学习的概述。我们了解了攻击者如何绕过机器学习。在本章中，我们将更深入地了解如何绕过基于机器学习的恶意软件检测器；在此之前，我们将学习如何欺骗人工神经网络并避开Python、开源库和开源项目的深度学习网络。神经网络可以被**对抗样本**欺骗。对抗样本被用作神经网络的输入，以影响学习结果。由Ian
    J. Goodfellow、Jonathon Shlens和Christian Szegedy（在Google）进行的一项开创性研究项目，名为*解释和利用对抗网络*，显示了一小部分精心构造的噪音可以欺骗神经网络，使其认为输入的图像是长臂猿而不是熊猫，且置信度为99.3%。神经网络最初认为提供的图像是熊猫，置信度为57.7%，这是正确的；但在第二个例子中，欺骗网络后情况并非如此：
- en: '![](img/00203.jpeg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00203.jpeg)'
- en: Many electronic devices and systems rely on deep learning as a protection mechanism,
    including face recognition; imagine what attackers can do to attack them and gain
    unauthorized access to critical systems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 许多电子设备和系统依赖深度学习作为保护机制，包括人脸识别；想象一下攻击者可以对它们进行的攻击，并未授权地访问关键系统。
- en: 'Now, let''s try to fool a neural network. We are going to fool a handwritten
    digit detector system by using the famous MNIST dataset. In [Chapter 4](part0081.html#2D7TI0-49a67f1d6e7843d3b2296f38e3fe05f5),
    *Malware Detection with Deep Learning*, we learned how to build one. For the demonstration,
    we are going to fool a pretrained neural network by Michael Nielsen. He used 50,000
    training images and 10,000 test images. Or, you can simply use your own neural
    network. You can find the training information in the GitHub repository of this
    chapter. The file is called `trained_network.pkl`; you will also find the MNIST
    file (`mnist.pkl.gz`):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们试图愚弄一个神经网络。我们将使用著名的MNIST数据集愚弄手写数字检测系统。在[第4章](part0081.html#2D7TI0-49a67f1d6e7843d3b2296f38e3fe05f5)中，*使用深度学习进行恶意软件检测*，我们学习了如何构建一个。为了演示，我们将愚弄Michael
    Nielsen的一个预训练神经网络。他使用了5万张训练图像和1万张测试图像。或者，您也可以使用自己的神经网络。您可以在本章的GitHub存储库中找到训练信息。文件名为`trained_network.pkl`；您还会找到MNIST文件（`mnist.pkl.gz`）：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s check whether the model is well-trained. Load the `pickle` file. Load
    the data with `pickle.load()`, and identify training,validation, and testing data:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查模型是否训练良好。加载`pickle`文件。使用`pickle.load()`加载数据，并识别训练、验证和测试数据：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To check digit 2, for example, we are going to select `test_data[1][0]`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要检查数字2，我们将选择`test_data[1][0]`：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following screenshot illustrates the preceding code:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图说明了前面的代码：
- en: '![](img/00204.gif)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00204.gif)
- en: 'Plot the result to check further by using `matplotlib.pyplot (plt)`:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`matplotlib.pyplot (plt)`绘制结果以进一步检查：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As you can see we generated the digit **2** so the model was trained well:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们生成了数字**2**，所以模型训练得很好：
- en: '![](img/00205.gif)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00205.gif)
- en: 'Everything is set up correctly. Now, we are going to attack the neural network
    with two types of attacks: **targeted** and **non-targeted.**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都设置正确。现在，我们将用两种类型的攻击来攻击神经网络：**有目标的**和**无目标的**。
- en: 'For a non-targeted attack, we are going to generate an adversarial sample and
    make the network give a certain output, for example, *6*:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于无目标攻击，我们将生成一个对抗样本，并使网络给出特定输出，例如*6*：
- en: '![](img/00206.gif)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00206.gif)
- en: 'In this attack, we want the neural network to think that the image entered
    is *6*. The target image (let''s call it *X)* is a *784* dimensional vector, because
    the image dimension is *28×28* pixels. Our goal is to find a vector  `*⃗x*` that
    minimizes the cost *C,* resulting in an image that the neural network predicts
    as our goal label. The cost function, *C,* is defined as the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次攻击中，我们希望神经网络认为输入的图像是*6*。目标图像（我们称之为*X*）是一个*784*维向量，因为图像尺寸是*28×28*像素。我们的目标是找到一个向量`*⃗x*`，使成本*C*最小化，从而得到一个神经网络预测为我们目标标签的图像。成本函数*C*定义如下：
- en: '![](img/00207.jpeg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00207.jpeg)
- en: 'The following code block is an implementation of a derivative function:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块是导数函数的实现：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To generate the adversarial sample, we need to set the goal:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成对抗样本，我们需要设定目标：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create a random image for gradient descent initialization, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个随机图像以进行梯度下降初始化，如下所示：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Compute the gradient descent, as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 计算梯度下降，如下所示：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, you can generate the sample:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以生成样本：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Plot the adversarial sample, as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制对抗样本，如下所示：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](img/00208.gif)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00208.gif)
- en: 'In targeted attacks, we use the same technique and the same code, but we add
    a new term to the cost function. So, it will be as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在有目标的攻击中，我们使用相同的技术和相同的代码，但是我们在成本函数中添加了一个新项。因此，它将如下所示：
- en: '![](img/00209.jpeg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00209.jpeg)
- en: Foolbox
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Foolbox
- en: 'Foolbox is a Python toolbox to benchmark the robustness of machine learning
    models. It is supported by many frameworks, including the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Foolbox是一个用于评估机器学习模型鲁棒性的Python工具包。它受到许多框架的支持，包括以下：
- en: TensorFlow
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow
- en: PyTorch
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch
- en: Theano
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Theano
- en: Keras
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras
- en: Lasagne
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lasagne
- en: MXNet
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MXNet
- en: 'To install Foolbox, use the `pip` utility:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Foolbox，请使用`pip`实用程序：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](img/00210.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00210.jpeg)
- en: 'The following are some Foolbox attacks:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些Foolbox攻击：
- en: '**Gradient-Based Attacks**: By linearizing the loss around an input, *x*'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于梯度的攻击**：通过在输入*x*周围线性化损失'
- en: '**Gradient Sign Attack (FGSM)**: By computing the gradient, *g(x0)*, once,
    and then seeking the minimum step size'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度符号攻击（FGSM）**：通过计算梯度*g(x0)*，然后寻找最小步长'
- en: '**Iterative Gradient Attack**: By maximizing the loss along small steps in
    the gradient direction, *g(x)*'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代梯度攻击**：通过在梯度方向上的小步骤中最大化损失*g(x)*'
- en: '**Iterative Gradient Sign Attack**: By maximizing the loss along small steps
    in the ascent direction, *sign(g(x))*'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代梯度符号攻击**：通过在上升方向上的小步骤中最大化损失*sign(g(x))*'
- en: '**DeepFool L2Attack**: By computing, for each class, the minimum distance,
    *d(ℓ, ℓ0)*, that it takes to reach the class boundary'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DeepFool L2攻击**：通过计算每个类的最小距离*d(ℓ, ℓ0)*，以达到类边界'
- en: '**DeepFool L∞Attack**: Like L2Attack, but minimizes the *L∞-norm* instead'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DeepFool L∞攻击**：类似于L2攻击，但最小化*L∞-范数*'
- en: '**Jacobian-Based Saliency Map Attack**: By computing a saliency score for each
    input feature'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于Jacobian的显著性图攻击**：通过计算每个输入特征的显著性分数'
- en: '**Single Pixel Attack**: By setting a single pixel to white or black'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单像素攻击**：通过将单个像素设置为白色或黑色'
- en: 'To implement an attack with Foolbox, use the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Foolbox实施攻击，请使用以下方法：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If you receive the error, `ImportError('`load_weights` requires h5py.')`, solve
    it by installing the **h5py** library (`pip install h5py`).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您收到错误消息，`ImportError('`load_weights` requires h5py.')`，请通过安装**h5py**库来解决（`pip
    install h5py`）。
- en: 'To plot the result, use the following code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制结果，请使用以下代码：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](img/00211.jpeg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00211.jpeg)
- en: Deep-pwning
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Deep-pwning
- en: Deep-pwning is a lightweight framework for experimenting with machine learning
    models, with the goal of evaluating their robustness against a motivated adversary.
    It is called the **metasploit of machine learning**. You can clone it from the
    GitHub repository at [https://github.com/cchio/deep-pwning](https://github.com/cchio/deep-pwning).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Deep-pwning是一个轻量级框架，用于实验机器学习模型，旨在评估其对抗性对抗有动机的对手。它被称为**机器学习的metasploit**。您可以从GitHub仓库克隆它：[https://github.com/cchio/deep-pwning](https://github.com/cchio/deep-pwning)。
- en: 'Don''t forget to install all of the requirements:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记安装所有的要求：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following are the Python libraries required to work with Deep-pwning:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是与Deep-pwning一起使用所需的Python库：
- en: Tensorflow 0.8.0
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tensorflow 0.8.0
- en: Matplotlib >= 1.5.1
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib >= 1.5.1
- en: Numpy >= 1.11.1
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Numpy >= 1.11.1
- en: Pandas >= 0.18.1
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas >= 0.18.1
- en: Six >= 1.10.0
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Six >= 1.10.0
- en: EvadeML
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EvadeML
- en: EvadeML ([https://evademl.org](https://evademl.org/) ) is an evolutionary framework
    based on genetic programming, for automatically finding variants that evade detection
    by machine learning based malware classifiers. It was developed by the Machine
    Learning Group and the Security Research Group at the University of Virginia.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: EvadeML ([https://evademl.org](https://evademl.org/) )是基于遗传编程的进化框架，用于自动查找能够逃避基于机器学习的恶意软件分类器检测的变体。它是由弗吉尼亚大学的机器学习组和安全研究组开发的。
- en: To download EvadeML, clone it from [https://github.com/uvasrg/EvadeML](https://github.com/uvasrg/EvadeML).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载EvadeML，请从[https://github.com/uvasrg/EvadeML](https://github.com/uvasrg/EvadeML)克隆它。
- en: 'To install EvadeML, you need to install these required tools:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装EvadeML，您需要安装这些必需的工具：
- en: 'A modified version of pdfrw for parsing PDFs: [https://github.com/mzweilin/pdfrw](https://github.com/mzweilin/pdfrw)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于解析PDF的pdfrw的修改版本：[https://github.com/mzweilin/pdfrw](https://github.com/mzweilin/pdfrw)
- en: 'Cuckoo Sandbox v1.2, as the oracle: [https://github.com/cuckoosandbox/cuckoo/releases/tag/1.2](https://github.com/cuckoosandbox/cuckoo/releases/tag/1.2)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cuckoo Sandbox v1.2，作为预言机：[https://github.com/cuckoosandbox/cuckoo/releases/tag/1.2](https://github.com/cuckoosandbox/cuckoo/releases/tag/1.2)
- en: 'The target classifier PDFrate-Mimicus: [https://github.com/srndic/mimicus](https://github.com/srndic/mimicus)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标分类器PDFrate-Mimicus：[https://github.com/srndic/mimicus](https://github.com/srndic/mimicus)
- en: 'The target classifier Hidost: [https://github.com/srndic/hidost](https://github.com/srndic/hidost)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标分类器Hidost：[https://github.com/srndic/hidost](https://github.com/srndic/hidost)
- en: 'To configure the project, copy the template, and configure it with an editor:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 要配置项目，请复制模板，并使用编辑器进行配置：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Before running the main program, `./gp.py` , run the centralized detection
    agent with predefined malware signatures, as indicated in the documentation:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行主程序`./gp.py`之前，运行带有预定义恶意软件签名的集中式检测代理，如文档中所示：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Select several benign PDF files:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 选择几个良性PDF文件：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To add a new classifier to evade, just add a wrapper in `./classifiers/`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要向逃避添加新的分类器，只需在`./classifiers/`中添加一个包装器。
- en: Bypassing next generation malware detectors with generative adversarial networks
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用生成对抗网络绕过下一代恶意软件检测器
- en: In 2014, Ian Goodfellow, Yoshua Bengio, and their team, proposed a framework
    called the **generative adversarial network (GAN)**. Generative adversarial networks
    have the ability to generate images from a random noise. For example, we can train
    a generative network to generate images for handwritten digits from the MNIST
    dataset.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 2014年，Ian Goodfellow、Yoshua Bengio及其团队提出了一个名为**生成对抗网络（GAN）**的框架。生成对抗网络能够从随机噪声生成图像。例如，我们可以训练一个生成网络，从MNIST数据集生成手写数字的图像。
- en: 'Generative adversarial networks are composed of two major parts: a **generator**
    and a **discriminator**.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络由两个主要部分组成：**生成器**和**鉴别器**。
- en: The generator
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成器
- en: 'The generator takes latent samples as inputs; they are randomly generated numbers,
    and they are trained to generate images:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器以潜在样本作为输入；它们是随机生成的数字，并且它们被训练以生成图像：
- en: '![](img/00212.jpeg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00212.jpeg)'
- en: 'For example, to generate a handwritten digit, the generator will be a fully
    connected network that takes latent samples and generates `784` data points, reshaping
    them into *28x28* pixel images (MNIST digits). It is highly recommended to use
    `tanh` as an activation function:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要生成手写数字，生成器将是一个完全连接的网络，它接受潜在样本并生成`784`个数据点，将它们重塑为*28x28*像素图像（MNIST数字）。强烈建议使用`tanh`作为激活函数：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The discriminator
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 鉴别器
- en: 'The discriminator is simply a classifier trained with supervised learning techniques
    to check if the image is real (`1`) or fake (`0`). It is trained by both the MNIST
    dataset and the generator samples. The discriminator will classify the MNIST data
    as real, and the generator samples as fake:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器只是一个使用监督学习技术训练的分类器，用于检查图像是否为真（`1`）或假（`0`）。它通过MNIST数据集和生成器样本进行训练。鉴别器将把MNIST数据分类为真实的，生成器样本分类为假的：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'By connecting the two networks, the generator and the discriminator, we produce
    a generative adversarial network:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接两个网络，生成器和鉴别器，我们产生了一个生成对抗网络：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This is a high-level representation of a generative adversarial network:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成对抗网络的高级表示：
- en: '![](img/00213.jpeg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00213.jpeg)'
- en: 'To train the GAN, we need to train the generator (the discriminator is set
    as non-trainable in further steps); in the training, the back-propagation updates
    the generator''s weights to produce realistic images. So, to train a GAN, we use
    the following steps as a loop:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练GAN，我们需要训练生成器（鉴别器在后续步骤中设置为不可训练）；在训练中，反向传播更新生成器的权重以生成逼真的图像。因此，要训练GAN，我们使用以下步骤作为循环：
- en: Train the discriminator with the real images (the discriminator is trainable
    here)
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用真实图像训练鉴别器（鉴别器在这里是可训练的）
- en: Set the discriminator as non-trainable
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将鉴别器设置为不可训练
- en: Train the generator
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练生成器
- en: The training loop will occur until both of the networks cannot be improved any
    further.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 训练循环将持续进行，直到两个网络都无法进一步改进。
- en: 'To build a GAN with Python, use the following code:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python构建GAN，请使用以下代码：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](img/00214.gif)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00214.gif)'
- en: To build a GAN with Python, we are going to use NumPy and TensorFlow.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python构建GAN，我们将使用NumPy和TensorFlow。
- en: MalGAN
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MalGAN
- en: 'To generate malware samples to attack machine learning models, attackers are
    now using GANs to achieve their goals. Using the same techniques we discussed
    previously (a generator and a discriminator), cyber criminals perform attacks
    against next-generation anti-malware systems, even without knowing the machine
    learning technique used (black box attacks). One of these techniques is MalGAN,
    which was presented in a research project called, *Generating Adversarial Malware
    Examples for Black Box Attacks Based on GAN,* conducted by Weiwei Hu and Ying
    Tan from the Key Laboratory of Machine Perception (MOE) and the Department of
    Machine Intelligence. The architecture of MalGAN is as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成恶意软件样本来攻击机器学习模型，攻击者现在正在使用GAN来实现他们的目标。使用我们之前讨论过的相同技术（生成器和鉴别器），网络犯罪分子对下一代反恶意软件系统进行攻击，甚至不知道使用的机器学习技术（黑盒攻击）。其中一种技术是MalGAN，它是由魏伟胡和应潭从机器感知（MOE）重点实验室和机器智能系进行的名为“基于GAN的黑盒攻击生成对抗性恶意软件示例”的研究项目中提出的。MalGAN的架构如下：
- en: '![](img/00215.jpeg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00215.jpeg)'
- en: The generator creates adversarial malware samples by taking malware (feature
    vector *m*) and a noise vector, *z,* as input. The substitute detector is a multilayer,
    feed-forward neural network, which takes a program feature vector, *X,* as input.
    It classifies the program between a benign program and malware.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器通过接受恶意软件（特征向量*m*）和噪声向量*z*作为输入来创建对抗性恶意软件样本。替代检测器是一个多层前馈神经网络，它以程序特征向量*X*作为输入。它对程序进行良性程序和恶意软件之间的分类。
- en: 'To train the generative adversarial network, the researchers used this algorithm:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练生成对抗网络，研究人员使用了这个算法：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Many of the samples generated may not be valid PE files. To preserve mutations
    and formats, the systems required a sandbox to ensure that functionality was preserved.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的许多样本可能不是有效的PE文件。为了保留变异和格式，系统需要一个沙盒来确保功能得到保留。
- en: 'Generative adversarial network training cannot simply produce great results;
    that is why many hacks are needed to achieve better results. Some tricks were
    introduced by Soumith Chintala, Emily Denton, Martin Arjovsky, and Michael Mathieu,
    to obtain improved results:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络训练不能简单地产生出优秀的结果；这就是为什么需要许多技巧来实现更好的结果。Soumith Chintala、Emily Denton、Martin
    Arjovsky和Michael Mathieu引入了一些技巧来获得改进的结果：
- en: Normalizing the images between *-1* and *1*
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像归一化在*-1*和*1*之间
- en: Using a max log, *D,* as a loss function, to optimize *G* instead of min (*log
    1-D*)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最大对数*D*作为损失函数，以优化*G*而不是最小化(*log 1-D*)
- en: Sampling from a Gaussian distribution, instead of a uniform distribution
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从高斯分布中抽样，而不是均匀分布
- en: Constructing different mini-batches for real and fake
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为真实和虚假构建不同的小批量
- en: Avoiding ReLU and MaxPool, and using LeakyReLU and Average Pooling instead
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免ReLU和MaxPool，而使用LeakyReLU和平均池化
- en: Using **Deep Convolutional GAN** (**DCGAN**), if possible
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能的话，使用**深度卷积GAN**（**DCGAN**）
- en: Using the `ADAM` optimizer
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`ADAM`优化器
- en: Bypassing machine learning with reinforcement learning
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过强化学习绕过机器学习
- en: In the previous technique, we noticed that if we are generating adversarial
    samples, especially if the outcomes are binaries, we will face some issues, including
    generating invalid samples. Information security researchers have come up with
    a new technique to bypass machine learning anti-malware systems with reinforcement
    learning.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的技术中，我们注意到如果我们生成对抗性样本，特别是如果结果是二进制的，我们将面临一些问题，包括生成无效样本。信息安全研究人员提出了一种绕过机器学习反恶意软件系统的新技术。
- en: Reinforcement learning
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: 'Previously (especially in the first chapter), we explored the different machine
    learning models: supervised, semi-supervised, unsupervised, and reinforcement
    models. Reinforcement machine learning models are important approaches to building
    intelligent machines. In reinforcement learning, an agent learns through experience,
    by interacting with an environment; it chooses the best decision based on a state
    and a reward function:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以前（特别是在第一章），我们探讨了不同的机器学习模型：监督、半监督、无监督和强化模型。强化机器学习模型是构建智能机器的重要方法。在强化学习中，代理通过与环境的交互来学习，根据状态和奖励函数选择最佳决策：
- en: '![](img/00216.jpeg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00216.jpeg)'
- en: 'A famous example of reinforcement learning is the AI-based Atari Breakout.
    In this case, the environment includes the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的一个著名例子是基于AI的Atari Breakout。在这种情况下，环境包括以下内容：
- en: The ball and the bricks
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 球和砖块
- en: The moving paddle (left or right)
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动挡板（左或右）
- en: The reward for eliminating the bricks
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消除砖块的奖励
- en: 'The following figure illustrates a high overview of the reinforcement model
    used to teach the model how to play Atari Breakout:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了用于教授模型如何玩Atari Breakout的强化模型的高级概述：
- en: '![](img/00217.jpeg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00217.jpeg)'
- en: 'With the Atari Breakout environment as an analogy to learn how to avoid anti-malware
    systems, our environment will be as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以Atari Breakout环境作为学习如何避开反恶意软件系统的类比，我们的环境将如下：
- en: '![](img/00218.jpeg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00218.jpeg)'
- en: For the agent, it takes the environment state (general file information, header
    information, imported and exported functions, strings, and so on) to optimize
    its performance and  the reward input  from the antivirus reports, and result
    actions (creating entry points and new sections, modifying sections and so on).
    In other words, to perform and learn the agent is taking two inputs (States and
    rewards).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代理，它需要环境状态（一般文件信息、头信息、导入和导出函数、字符串等）来优化其性能和来自反病毒报告的奖励输入，以及结果行动（创建入口点和新部分，修改部分等）。换句话说，为了执行和学习，代理正在接受两个输入（状态和奖励）。
- en: As an implementation of the concepts we've discussed, information security professionals
    worked on an OpenAI environment, to build a malware that can escape detection
    using reinforcement learning techniques. One of these environments is **Gym-malware**.
    This great environment was developed by endgame.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们讨论的概念的实现，信息安全专业人员致力于OpenAI环境，以利用强化学习技术构建可以逃避检测的恶意软件。其中一个环境是**Gym-malware**。这个出色的环境是由endgame开发的。
- en: 'OpenAI gym contains an open source Python framework, developed by a nonprofit
    AI research company called OpenAI ([https://openai.com/](https://openai.com/))
    to develop and evaluate reinforcement learning algorithms. To install OpenAI Gym,
    use the following code (you''ll need to have Python 3.5+ installed):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI gym包含一个开源的Python框架，由非营利性人工智能研究公司OpenAI（[https://openai.com/](https://openai.com/)）开发，用于开发和评估强化学习算法。要安装OpenAI
    Gym，请使用以下代码（您需要安装Python 3.5+）：
- en: '[PRE22]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'OpenAI Gym is loaded pre-made environments. You can check all of the available
    environments at [http://gym.openai.com/envs/](http://gym.openai.com/envs/):'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI Gym加载了预先制作的环境。您可以在[http://gym.openai.com/envs/](http://gym.openai.com/envs/)上检查所有可用的环境：
- en: '![](img/00219.jpeg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00219.jpeg)'
- en: '[PRE23]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To use the Gym-malware environment, you will need to install Python 3.6 and
    a library called Instrument Executable Formats, aptly named `LIEF`. You can add
    it by typing:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Gym-malware环境，您需要安装Python 3.6和一个名为`LIEF`的库，它可以通过输入以下内容来添加：
- en: '[PRE25]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Download Gym-malware from [https://github.com/endgameinc/gym-malware](https://github.com/endgameinc/gym-malware). [Move
    the installed Gym-malware environment to `gym_malware/gym_malware/envs/utils/samples/`.](https://github.com/endgameinc/gym-malware)
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 从[https://github.com/endgameinc/gym-malware](https://github.com/endgameinc/gym-malware)下载Gym-malware。将安装的Gym-malware环境移动到`gym_malware/gym_malware/envs/utils/samples/`。
- en: 'To check whether you have the samples in the correct directory, type the following:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查您是否在正确的目录中拥有样本，请输入以下内容：
- en: '[PRE26]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The actions available in this environment are as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 此环境中可用的操作如下：
- en: '`append_zero`'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`append_zero`'
- en: '`append_random_ascii`'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`append_random_ascii`'
- en: '`append_random_bytes`'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`append_random_bytes`'
- en: '`remove_signature`'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remove_signature`'
- en: '`upx_pack`'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upx_pack`'
- en: '`upx_unpack`'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upx_unpack`'
- en: '`change_section_names_from_list`'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`change_section_names_from_list`'
- en: '`change_section_names_to random`'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`change_section_names_to random`'
- en: '`modify_export`'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modify_export`'
- en: '`remove_debug`'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remove_debug`'
- en: '`break_optional_header_checksum`'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`break_optional_header_checksum`'
- en: Summary
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we continued our journey of learning how to bypass machine
    learning models. In the previous chapter, we discovered adversarial machine learning;
    in this continuation, we explored adversarial deep learning and how to fool deep
    learning networks. We looked at some real-world cases to learn how to escape anti-malware
    systems by using state of the art techniques. In the next and last chapter, we
    are going to gain more knowledge, learning how to build robust models.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们继续学习如何绕过机器学习模型。在上一章中，我们发现了对抗机器学习；在这一延续中，我们探讨了对抗深度学习以及如何欺骗深度学习网络。我们查看了一些真实案例，以了解如何使用最先进的技术逃避反恶意软件系统。在接下来的最后一章中，我们将获得更多知识，学习如何构建强大的模型。
- en: Questions
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the components of generative adversarial networks?
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成对抗网络的组成部分是什么？
- en: What is the difference between a generator and a discriminator?
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成器和鉴别器之间有什么区别？
- en: How can we make sure that the malware adversarial samples are still valid when
    we are generating them?
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生成对抗样本时，我们如何确保恶意软件对抗样本仍然有效？
- en: Do a bit of research, then briefly explain how to detect adversarial samples.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行一些研究，然后简要解释如何检测对抗样本。
- en: What distinguishes reinforcement learning from deep learning?
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 强化学习与深度学习有何不同？
- en: What is the difference between supervised and reinforcement learning?
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监督学习和强化学习之间有什么区别？
- en: How does an agent learn in reinforcement learning?
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在强化学习中，代理如何学习？
- en: Further reading
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The following resources include a great deal of information:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 以下资源包含大量信息：
- en: '*Explaining and Harnessing Adversarial Samples*: [https://arxiv.org/pdf/1412.6572.pdf](https://arxiv.org/pdf/1412.6572.pdf)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解释和利用对抗样本*：[https://arxiv.org/pdf/1412.6572.pdf](https://arxiv.org/pdf/1412.6572.pdf)'
- en: '*Delving Into Transferable Adversarial Examples and Black Box Attacks*: [https://arxiv.org/pdf/1611.02770.pdf](https://arxiv.org/pdf/1611.02770.pdf)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深入研究可转移对抗样本和黑盒攻击*：[https://arxiv.org/pdf/1611.02770.pdf](https://arxiv.org/pdf/1611.02770.pdf)'
- en: '*Foolbox - a Python toolbox to benchmark the robustness of machine learning
    models*: [https://arxiv.org/pdf/1707.04131.pdf](https://arxiv.org/pdf/1707.04131.pdf)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Foolbox-用于基准测试机器学习模型鲁棒性的Python工具包*：[https://arxiv.org/pdf/1707.04131.pdf](https://arxiv.org/pdf/1707.04131.pdf)'
- en: '*The Foolbox *GitHub: [https://github.com/bethgelab/foolbox](https://github.com/bethgelab/foolbox)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*The Foolbox* GitHub：[https://github.com/bethgelab/foolbox](https://github.com/bethgelab/foolbox)'
- en: '*Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN*: [https://arxiv.org/pdf/1702.05983.pdf](https://arxiv.org/pdf/1702.05983.pdf)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于GAN的黑盒攻击生成对抗恶意软件示例：[https://arxiv.org/pdf/1702.05983.pdf](https://arxiv.org/pdf/1702.05983.pdf)
- en: '*Malware Images: Visualization and Automatic Classification*: [https://arxiv.org/pdf/1702.05983.pdf](https://arxiv.org/pdf/1702.05983.pdf)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*恶意软件图像：可视化和自动分类*：[https://arxiv.org/pdf/1702.05983.pdf](https://arxiv.org/pdf/1702.05983.pdf)'
- en: '*SARVAM: Search And RetrieVAl of Malware*: [http://vision.ece.ucsb.edu/sites/vision.ece.ucsb.edu/files/publications/2013_sarvam_ngmad_0.pdf](http://vision.ece.ucsb.edu/sites/vision.ece.ucsb.edu/files/publications/2013_sarvam_ngmad_0.pdf)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SARVAM：恶意软件的搜索和检索*：[http://vision.ece.ucsb.edu/sites/vision.ece.ucsb.edu/files/publications/2013_sarvam_ngmad_0.pdf](http://vision.ece.ucsb.edu/sites/vision.ece.ucsb.edu/files/publications/2013_sarvam_ngmad_0.pdf)'
- en: '*SigMal: A Static Signal Processing Based Malware Triage*: [http://vision.ece.ucsb.edu/publications/view_abstract.cgi?416](http://vision.ece.ucsb.edu/publications/view_abstract.cgi?416)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SigMal：基于静态信号处理的恶意软件分类*：[http://vision.ece.ucsb.edu/publications/view_abstract.cgi?416](http://vision.ece.ucsb.edu/publications/view_abstract.cgi?416)'
