- en: Chapter 1. Gathering Open Source Intelligence
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。收集开源情报
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Gathering information using the Shodan API
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Shodan API收集信息
- en: Scripting a Google+ API search
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写Google+ API搜索脚本
- en: Downloading profile pictures using the Google+ API
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google+ API下载个人资料图片
- en: Harvesting additional results using the Google+ API pagination
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google+ API分页收集额外结果
- en: Getting screenshots of websites using QtWebKit
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用QtWebKit获取网站的屏幕截图
- en: Screenshots based on port lists
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于端口列表的屏幕截图
- en: Spidering websites
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬取网站
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '**Open Source Intelligence** (**OSINT**) is the process of gathering information
    from Open (overt) sources. When it comes to testing a web application, that might
    seem a strange thing to do. However, a great deal of information can be learned
    about a particular website before even touching it. You might be able to find
    out what server-side language the website is written in, the underpinning framework,
    or even its credentials. Learning to use APIs and scripting these tasks can make
    the bulk of the gathering phase a lot easier.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**开源情报**（**OSINT**）是从开放（公开）来源收集信息的过程。当涉及测试Web应用程序时，这可能看起来很奇怪。然而，在甚至触及网站之前，可以了解到关于特定网站的大量信息。您可能能够找出网站是用什么服务器端语言编写的，底层框架，甚至其凭据。学会使用API并编写这些任务可以使收集阶段的大部分工作变得更容易。'
- en: In this chapter, we will look at a few of the ways we can use Python to leverage
    the power of APIs to gain insight into our target.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看一下我们可以使用Python利用API的几种方式来获得有关目标的洞察力。
- en: Gathering information using the Shodan API
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Shodan API收集信息
- en: Shodan is essentially a vulnerability search engine. By providing it with a
    name, an IP address, or even a port, it returns all the systems in its databases
    that match. This makes it one of the most effective sources for intelligence when
    it comes to infrastructure. It's like Google for internet-connected devices. Shodan
    constantly scans the Internet and saves the results into a public database. Whilst
    this database is searchable from the Shodan website ([https://www.shodan.io](https://www.shodan.io)),
    the results and services reported on are limited, unless you access it through
    the **Application Programming Interface** (**API**).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Shodan本质上是一个漏洞搜索引擎。通过提供名称、IP地址甚至端口，它返回与其数据库中匹配的所有系统。这使得它成为基础设施情报的最有效来源之一。它就像互联网连接设备的谷歌。Shodan不断扫描互联网并将结果保存到公共数据库中。虽然可以从Shodan网站（[https://www.shodan.io](https://www.shodan.io)）搜索此数据库，但结果和报告的服务是有限的，除非通过**应用程序编程接口**（**API**）访问。
- en: Our task for this section will be to gain information about the Packt Publishing
    website by using the Shodan API.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的任务是通过使用Shodan API获取有关Packt Publishing网站的信息。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: At the time of writing this, Shodan membership is $49, and this is needed to
    get an API key. If you're serious about security, access to Shodan is invaluable.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Shodan会员费为49美元，这是需要获取API密钥的。如果您对安全性很认真，访问Shodan是非常宝贵的。
- en: If you don't already have an API key for Shodan, visit [www.shodan.io/store/member](http://www.shodan.io/store/member)
    and sign up for it. Shodan has a really nice Python library, which is also well
    documented at [https://shodan.readthedocs.org/en/latest/](https://shodan.readthedocs.org/en/latest/).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有Shodan的API密钥，请访问[www.shodan.io/store/member](http://www.shodan.io/store/member)并注册。Shodan有一个非常好的Python库，也在[https://shodan.readthedocs.org/en/latest/](https://shodan.readthedocs.org/en/latest/)上有很好的文档。
- en: 'To get your Python environment set up to work with Shodan, all you need to
    do is simply install the library using `cheeseshop`:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置Python环境以与Shodan一起工作，您只需要使用`cheeseshop`安装库：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How to do it…
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Here''s the script that we are going to use for this task:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将用于此任务的脚本：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding script should produce an output similar to the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上述脚本应该产生类似以下的输出：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I've just chosen a few of the available data items that Shodan returns, but
    you can see that we get a fair bit of information back. In this particular instance,
    we can see that there is a potential vulnerability identified. We also see that
    this server is listening on ports `80` and `443` and that according to the banner
    information, it appears to be running `nginx` as the HTTP server.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我只选择了Shodan返回的一些可用数据项，但您可以看到我们得到了相当多的信息。在这种特定情况下，我们可以看到存在潜在的漏洞。我们还看到这台服务器正在端口`80`和`443`上监听，并且根据横幅信息，它似乎正在运行`nginx`作为HTTP服务器。
- en: How it works…
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: 'Firstly, we set up our static strings within the code; this includes our API
    key:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在代码中设置我们的静态字符串；这包括我们的API密钥：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The next step is to create our API object:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是创建我们的API对象：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In order to search for information on a host using the API, we need to know
    the host''s IP address. Shodan has a DNS resolver but it''s not included in the
    Python library. To use Shodan''s DNS resolver, we simply have to make a GET request
    to the Shodan DNS Resolver URL and pass it the domain (or domains) we are interested
    in:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使用API搜索主机的信息，我们需要知道主机的IP地址。Shodan有一个DNS解析器，但它没有包含在Python库中。要使用Shodan的DNS解析器，我们只需向Shodan
    DNS解析器URL发出GET请求，并传递我们感兴趣的域（或域）：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The returned JSON data will be a dictionary of domains to IP addresses; as we
    only have one target in our case, we can simply pull out the IP address of our
    host using the `target` string as the key for the dictionary. If you were searching
    on multiple domains, you would probably want to iterate over this list to obtain
    all the IP addresses.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回的JSON数据将是一个域到IP地址的字典；在我们的情况下，我们只有一个目标，我们可以简单地使用`target`字符串作为字典的键来提取我们主机的IP地址。如果您正在搜索多个域，您可能希望遍历此列表以获取所有IP地址。
- en: 'Now, we have the host''s IP address, we can use the Shodan libraries `host`
    function to obtain information on our host. The returned JSON data contains a
    wealth of information about the host, though in our case we will just pull out
    the IP address, organization, and if possible the operating system that is running.
    Then we will loop over all of the ports that were found to be open and their respective
    banners:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们有了主机的IP地址，我们可以使用Shodan库的“host”函数来获取有关我们的主机的信息。返回的JSON数据包含大量关于主机的信息，尽管在我们的情况下，我们只会提取IP地址、组织，如果可能的话，正在运行的操作系统。然后，我们将循环遍历找到的所有打开端口及其各自的横幅：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The returned data may also contain potential **Common Vulnerabilities and Exposures**
    (**CVE**) numbers for vulnerabilities that Shodan thinks the server may be susceptible
    to. This could be really beneficial to us, so we will iterate over the list of
    these (if there are any) and use another function from the Shodan library to get
    information on the exploit:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回的数据还可能包含Shodan认为服务器可能容易受到的**通用漏洞和暴露**（**CVE**）编号。这对我们可能非常有益，因此我们将遍历这些列表（如果有的话），并使用Shodan库的另一个函数获取有关利用的信息：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: That's it for our script. Try running it against your own server.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们的脚本。尝试针对您自己的服务器运行它。
- en: There's more…
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We've only really scratched the surface of the Shodan Python library with our
    script. It is well worth reading through the Shodan API reference documentation
    and playing around with the other search options. You can filter results based
    on "facets" to narrow down your searches. You can even use searches that other
    users have saved using the "tags" search.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是真正开始了Shodan Python库的使用。值得阅读Shodan API参考文档，并尝试使用其他搜索选项。您可以根据“facets”筛选结果以缩小搜索范围。您甚至可以使用其他用户使用“tags”搜索保存的搜索。
- en: Tip
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Downloading the example code**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**下载示例代码**'
- en: You can download the example code files from your account at [http://www.packtpub.com](http://www.packtpub.com)
    for all the Packt Publishing books you have purchased. If you purchased this book
    elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[http://www.packtpub.com](http://www.packtpub.com)的帐户中下载示例代码文件，以获取您购买的所有Packt
    Publishing图书。如果您在其他地方购买了本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便直接通过电子邮件接收文件。
- en: Scripting a Google+ API search
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写Google+ API搜索脚本
- en: Social media is a great way to gather information on a target company or person.
    Here, we will be showing you how to script a Google+ API search to find contact
    information for a company within the Google+ social sites.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 社交媒体是收集有关目标公司或个人信息的好方法。在这里，我们将向您展示如何编写一个Google+ API搜索脚本，以在Google+社交网站中查找公司的联系信息。
- en: Getting ready
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Some Google APIs require authorization to access them, but if you have a Google
    account, getting the API key is easy. Just go to [https://console.developers.google.com](https://console.developers.google.com)
    and create a new project. Click on **API & auth** | **Credentials**. Click on
    **Create new key** and **Server key**. Optionally enter your IP or just click
    on **Create**. Your API key will be displayed and ready to copy and paste into
    the following recipe.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一些Google API需要授权才能访问，但是如果您有Google帐户，获取API密钥很容易。只需转到[https://console.developers.google.com](https://console.developers.google.com)，创建一个新项目。单击**API和身份验证**
    | **凭据**。单击**创建新密钥**，然后**服务器密钥**。可选择输入您的IP，或者只需单击**创建**。您的API密钥将显示并准备好复制并粘贴到以下示例中。
- en: How to do it…
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Here''s a simple script to query the Google+ API:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的查询Google+ API的脚本：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works…
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'The preceding code makes a request to the Google+ search API (authenticated
    with your API key) and searches for accounts matching the target; `packtpub.com`.
    Similarly to the preceding Shodan script, we set up our static strings including
    the API key and target:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码向Google+搜索API发出请求（使用您的API密钥进行身份验证），并搜索与目标`packtpub.com`匹配的帐户。与前面的Shodan脚本类似，我们设置了静态字符串，包括API密钥和目标：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The next step does two things: first, it sends the HTTP `GET` request to the
    API server, then it reads in the response and stores the output into an `api_response`
    variable:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步有两个作用：首先，它向API服务器发送HTTP“GET”请求，然后读取响应并将输出存储到一个“api_response”变量中：
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This request returns a JSON formatted response; an example snippet of the results
    is shown here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此请求返回JSON格式的响应；这里显示了结果的一个示例片段：
- en: '![How it works…](img/B04044_01_01.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理...](img/B04044_01_01.jpg)'
- en: 'In our script, we convert the response into a list so it''s easier to parse:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的脚本中，我们将响应转换为列表，以便更容易解析：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The final part of the code loops through the list and prints only the lines
    that contain `displayName`, as shown here:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的最后一部分循环遍历列表，并仅打印包含“displayName”的行，如下所示：
- en: '![How it works…](img/B04044_01_02.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理...](img/B04044_01_02.jpg)'
- en: See also…
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅...
- en: In the next recipe, *Downloading profile pictures using the Google+ API*, we
    will look at improving the formatting of these results.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，*使用Google+ API下载个人资料图片*，我们将看到如何改进这些结果的格式。
- en: There's more…
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: By starting with a simple script to query the Google+ API, we can extend it
    to be more efficient and make use of more of the data returned. Another key aspect
    of the Google+ platform is that users may also have a matching account on another
    of Google's services, which means you can cross-reference accounts. Most Google
    products have an API available to developers, so a good place to start is [https://developers.google.com/products/](https://developers.google.com/products/).
    Grab an API key and plug the output from the previous script into it.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从一个简单的脚本开始查询Google+ API，我们可以扩展它以提高效率，并利用返回的更多数据。Google+平台的另一个关键方面是用户可能还在Google的其他服务上拥有匹配的帐户，这意味着您可以交叉引用帐户。大多数Google产品都提供给开发人员的API，因此一个很好的起点是[https://developers.google.com/products/](https://developers.google.com/products/)。获取API密钥并将上一个脚本的输出插入其中。
- en: Downloading profile pictures using the Google+ API
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Google+ API下载个人资料图片
- en: Now that we have established how to use the Google+ API, we can design a script
    to pull down pictures. The aim here is to put faces to names taken from web pages.
    We will send a request to the API through a URL, handle the response through JSON,
    and create picture files in the working directory of the script.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了如何使用Google+ API，我们可以设计一个脚本来下载图片。这里的目标是从网页中获取姓名的照片。我们将通过URL向API发送请求，通过JSON处理响应，并在脚本的工作目录中创建图片文件。
- en: How to do it
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到
- en: 'Here''s a simple script to download profile pictures using the Google+ API:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用Google+ API下载个人资料图片的简单脚本：
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: 'The first change is to store the display name into a variable, as this is then
    reused later on:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个更改是将显示名称存储到变量中，因为稍后会重复使用它：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, we grab the image URL from the JSON response:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从JSON响应中获取图像URL：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The final part of the code does a number of things in three simple lines: firstly
    it opens a file on the local disk, with the filename set to the `name` variable.
    The `wb+` flag here indicates to the OS that it should create the file if it doesn''t
    exist and to write the data in a raw binary format. The second line makes a HTTP
    `GET` request to the image URL (stored in the `image` variable) and writes the
    response into the file. Finally, the file is closed to free system memory used
    to store the file contents:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的最后部分在三行简单的代码中做了很多事情：首先，它在本地磁盘上打开一个文件，文件名设置为`name`变量。这里的`wb+`标志指示操作系统，如果文件不存在，则应创建文件，并以原始二进制格式写入数据。第二行向图像URL（存储在`image`变量中）发出HTTP
    `GET`请求，并将响应写入文件。最后，关闭文件以释放用于存储文件内容的系统内存：
- en: '[PRE15]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: After the script is run, the console output will be the same as before, with
    the display names shown. However, your local directory will now also contain all
    the profile images, saved as JPEG files.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本运行后，控制台输出将与以前相同，显示名称也会显示。但是，您的本地目录现在还将包含所有个人资料图片，保存为JPEG文件。
- en: Harvesting additional results from the Google+ API using pagination
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分页从Google+ API中获取额外的结果
- en: By default, the Google+ APIs return a maximum of 25 results, but we can extend
    the previous scripts by increasing the maximum value and harvesting more results
    through pagination. As before, we will communicate with the Google+ API through
    a URL and the `urllib` library. We will create arbitrary numbers that will increase
    as requests go ahead, so we can move across pages and gather more results.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Google+ API返回最多25个结果，但我们可以通过增加最大值并通过分页收集更多结果来扩展先前的脚本。与以前一样，我们将通过URL和`urllib`库与Google+
    API进行通信。我们将创建任意数字，随着请求的进行而增加，这样我们就可以跨页面移动并收集更多结果。
- en: How to do it
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到
- en: 'The following script shows how you can harvest additional results from the
    Google+ API:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本显示了如何从Google+ API中获取额外的结果：
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: How it works
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: 'The first big change in this script that is the main code has been moved into
    a `while` loop:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本中的第一个重大变化是主要代码已经移入了一个`while`循环中：
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here, the number of loops is set to a maximum of 10 to avoid sending too many
    requests to the API servers. This value can of course be changed to any positive
    integer. The next change is to the request URL itself; it now contains two additional
    trailing parameters `maxResults` and `pageToken`. Each response from the Google+
    API contains a `pageToken` value, which is a pointer to the next set of results.
    Note that if there are no more results, a `pageToken` value is still returned.
    The `maxResults` parameter is self-explanatory, but can only be increased to a
    maximum of 50:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，循环的次数设置为最多10次，以避免向API服务器发送过多请求。当然，这个值可以更改为任何正整数。下一个变化是请求URL本身；它现在包含了两个额外的尾部参数`maxResults`和`pageToken`。来自Google+
    API的每个响应都包含一个`pageToken`值，它是指向下一组结果的指针。请注意，如果没有更多结果，仍然会返回一个`pageToken`值。`maxResults`参数是不言自明的，但最多只能增加到50：
- en: '[PRE18]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The next part reads the same as before in the JSON response, but this time
    it also extracts the `nextPageToken` value:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分在JSON响应中读取与以前相同，但这次它还提取了`nextPageToken`的值：
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The main `while` loop can stop if the `loops` variable increases up to 10,
    but sometimes you may only get one page of results. The next part in the code
    checks to see how many results were returned; if there were none, it exits the
    loop prematurely:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 主`while`循环如果`loops`变量增加到10，就会停止，但有时您可能只会得到一页结果。代码中的下一部分检查返回了多少结果；如果没有结果，它会过早地退出循环：
- en: '[PRE20]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, we ensure that we increase the value of the `loops` integer each time.
    A common coding mistake is to leave this out, meaning the loop will continue forever:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们确保每次增加`loops`整数的值。一个常见的编码错误是忽略这一点，这意味着循环将永远继续：
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Getting screenshots of websites with QtWebKit
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用QtWebKit获取网站的屏幕截图
- en: They say a picture is worth a thousand words. Sometimes, it's good to get screenshots
    of websites during the intelligence gathering phase. We may want to scan an IP
    range and get an idea of which IPs are serving up web pages, and more importantly
    what they look like. This could assist us in picking out interesting sites to
    focus on and we also might want to quickly scan ports on a particular IP address
    for the same reason. We will take a look at how we can accomplish this using the
    `QtWebKit` Python library.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 他们说一张图片价值千言。有时，在情报收集阶段获取网站的屏幕截图是很有用的。我们可能想要扫描一个IP范围，并了解哪些IP正在提供网页，更重要的是它们的样子。这可以帮助我们挑选出有趣的网站进行关注，我们也可能想要快速扫描特定IP地址上的端口，出于同样的原因。我们将看看如何使用`QtWebKit`
    Python库来实现这一点。
- en: Getting ready
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The QtWebKit is a bit of a pain to install. The easiest way is to get the binaries
    from [http://www.riverbankcomputing.com/software/pyqt/download](http://www.riverbankcomputing.com/software/pyqt/download).
    For Windows users, make sure you pick the binaries that fit your `python/arch`
    path. For example, I will use the `PyQt4-4.11.3-gpl-Py2.7-Qt4.8.6-x32.exe` binary
    to install Qt4 on my Windows 32bit Virtual Machine that has Python version 2.7
    installed. If you are planning on compiling Qt4 from the source files, make sure
    you have already installed `SIP`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: QtWebKit安装起来有点麻烦。最简单的方法是从[http://www.riverbankcomputing.com/software/pyqt/download](http://www.riverbankcomputing.com/software/pyqt/download)获取二进制文件。对于Windows用户，请确保选择适合你的`python/arch`路径的二进制文件。例如，我将使用`PyQt4-4.11.3-gpl-Py2.7-Qt4.8.6-x32.exe`二进制文件在我的安装了Python
    2.7的Windows 32位虚拟机上安装Qt4。如果你打算从源文件编译Qt4，请确保你已经安装了`SIP`。
- en: How to do it…
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Once you''ve got PyQt4 installed, you''re pretty much ready to go. The following
    script is what we will use as the base for our screenshot class:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你安装了PyQt4，你基本上就可以开始了。下面的脚本是我们将用作截图类的基础：
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Create the preceding script and save it in the Python `Lib` folder. We can then
    reference it as an import in our scripts.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 创建前面的脚本并将其保存在Python的`Lib`文件夹中。然后我们可以在我们的脚本中将其作为导入引用。
- en: How it works…
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: 'The script makes use of `QWebView` to load the URL and then creates an image
    using QPainter. The `get_image` function takes a single parameter: our target.
    Knowing this, we can simply import it into another script and expand the functionality.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本利用`QWebView`加载URL，然后使用QPainter创建图像。`get_image`函数接受一个参数：我们的目标。有了这个，我们可以简单地将其导入到另一个脚本中并扩展功能。
- en: Let's break down the script and see how it works.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解脚本，看看它是如何工作的。
- en: 'Firstly, we set up our imports:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们设置我们的导入：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, we create our class definition; the class we are creating extends from
    `QWebView` by inheritance:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建我们的类定义；我们正在创建的类通过继承从`QWebView`继承：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we create our initialization method:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建我们的初始化方法：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The initialization method sets the `self.__loaded` property. This is used along
    with the `__loadFinished` and `wait_load` functions to check the state of the
    application as it runs. It waits until the site has loaded before taking a screenshot.
    The actual screenshot code is contained in the `get_image` function:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化方法设置了`self.__loaded`属性。这与`__loadFinished`和`wait_load`函数一起用于检查应用程序运行时的状态。它会等到站点加载完成后再截图。实际的截图代码包含在`get_image`函数中：
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Within this `get_image` function, we set the size of the viewport to the size
    of the contents within the main frame. We then set the image format, assign the
    image to a painter object, and then render the frame using the painter. Finally,
    we return the processed image.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个`get_image`函数中，我们将视口的大小设置为主框架中内容的大小。然后设置图像格式，将图像分配给绘图对象，然后使用绘图器渲染框架。最后，我们返回处理过的图像。
- en: There's more…
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'To use the class we''ve just made, we just import it into another script. For
    example, if we wanted to just save the image we get back, we could do something
    like the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用我们刚刚创建的类，我们只需将其导入到另一个脚本中。例如，如果我们只想保存我们收到的图像，我们可以做如下操作：
- en: '[PRE27]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: That's all there is to it. In the next script, we will create something a little
    more useful.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。在下一个脚本中，我们将创建一些更有用的东西。
- en: Screenshots based on a port list
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于端口列表的截图
- en: In the previous script, we created our base function to return an image for
    a URL. We will now expand on that to loop over a list of ports that are commonly
    associated with web-based administration portals. This will allow us to point
    the script at an IP and automatically run through the possible ports that could
    be associated with a web server. This is to be used in cases when we don't know
    which ports are open on a server, rather than when where we are specifying the
    port and domain.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个脚本中，我们创建了一个基本函数来返回URL的图像。现在我们将扩展该功能，循环遍历与基于Web的管理门户常见相关的端口列表。这将允许我们将脚本指向一个IP，并自动运行可能与Web服务器相关的可能端口。这是用于在我们不知道服务器上开放了哪些端口的情况下使用，而不是在我们指定端口和域时使用。
- en: Getting ready
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In order for this script to work, we'll need to have the script created in the
    *Getting screenshots of a website with QtWeb Kit* recipe. This should be saved
    in the `Pythonxx/Lib` folder and named something clear and memorable. Here, we've
    named that script `screenshot.py`. The naming of your script is particularly essential
    as we reference it with an important declaration.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个脚本工作，我们需要在*使用QtWeb Kit获取网站截图*配方中创建脚本。这应该保存在`Pythonxx/Lib`文件夹中，并命名为清晰和易记的名称。在这里，我们将该脚本命名为`screenshot.py`。你的脚本的命名特别重要，因为我们会用一个重要的声明引用它。
- en: How to do it…
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'This is the script that we will be using:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将要使用的脚本：
- en: '[PRE28]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: How it works…
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: We first create our import declarations. In this script, we use the `screenshot`
    script we created before and also the `requests` library. The `requests` library
    is used so that we can check the status of a request before trying to convert
    it to an image. We don't want to waste time trying to convert sites that don't
    exist.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建我们的导入声明。在这个脚本中，我们使用了之前创建的`screenshot`脚本，还有`requests`库。`requests`库用于我们在尝试将其转换为图像之前检查请求的状态。我们不想浪费时间尝试转换不存在的站点。
- en: 'Next, we import our libraries:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们导入我们的库：
- en: '[PRE29]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The next step sets up the array of common port numbers that we will be iterating
    over. We also set up a string with the IP address we will be using:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是设置我们将要迭代的常见端口号数组。我们还设置了一个包含我们将要使用的IP地址的字符串：
- en: '[PRE30]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, we create strings to hold the protocol part of the URL that we will be
    building later; this just makes the code later on a little bit neater:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建字符串来保存我们稍后将构建的URL的协议部分；这只是为了稍后的代码更加整洁：
- en: '[PRE31]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, we create our method, which will do the work of building the URL string.
    After we''ve created the URL, we check whether we get a `200` response code back
    for our `get` request. If the request is successful, we convert the web page returned
    to an image and save it with the filename being the successful port number. The
    code is wrapped in a `try` block because if the site doesn''t exist when we make
    the request, it will throw an error:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建我们的方法，它将负责构建URL字符串的工作。创建URL后，我们检查我们的`get`请求是否返回`200`响应代码。如果请求成功，我们将返回的网页转换为图像，并以成功的端口号作为文件名保存。代码包裹在`try`块中，因为如果我们发出请求时网站不存在，它将抛出一个错误：
- en: '[PRE32]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now that our method is ready, we simply iterate over each port in the port
    list and call our method. We do this once for the HTTP protocol and then with
    HTTPS:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的方法已经准备好了，我们只需遍历端口列表中的每个端口，并调用我们的方法。我们先对HTTP协议进行一次，然后对HTTPS进行一次：
- en: '[PRE33]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: And that's it. Simply run the script and it will save the images to the same
    location as the script.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。只需运行脚本，它就会将图像保存在与脚本相同的位置。
- en: There's more…
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: You might notice that the script takes a while to run. This is because it has
    to check each port in turn. In practice, you would probably want to make this
    a multithreaded script so that it can check multiple URLs at the same time. Let's
    take a quick look at how we can modify the code to achieve this.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到脚本运行起来需要一些时间。这是因为它必须依次检查每个端口。实际上，你可能希望将这个脚本改成多线程脚本，这样它就可以同时检查多个URL。让我们快速看一下如何修改代码来实现这一点。
- en: 'First, we''ll need a couple more import declarations:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要几个额外的导入声明：
- en: '[PRE34]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we need to create a new function that we will call `threader`. This new
    function will handle putting our `testAndSave` functions into the queue:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个名为`threader`的新函数。这个新函数将处理将我们的`testAndSave`函数放入队列中：
- en: '[PRE35]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now that we have our new function, we just need to set up a new `Queue` object
    and make a few threading calls. We will take out the `testAndSave` calls from
    our `FOR` loop over the `portList` variable and replace it with this code:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了新的函数，我们只需要设置一个新的`Queue`对象，并进行一些线程调用。我们将从我们对`portList`变量的`FOR`循环中取出`testAndSave`调用，并用这段代码替换它：
- en: '[PRE36]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'So, our new script in total now looks like this:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的新脚本现在总共看起来是这样的：
- en: '[PRE37]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If we run this now, we will get a much quicker execution of our code as the
    web requests are now being executed in parallel with each other.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在运行这个脚本，我们将更快地执行我们的代码，因为Web请求现在是并行执行的。
- en: You could try to further expand the script to work on a range of IP addresses
    too; this can be handy when you're testing an internal network range.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试进一步扩展脚本，使其适用于一系列IP地址；当你测试内部网络范围时，这可能会很方便。
- en: Spidering websites
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 爬取网站
- en: Many tools provide the ability to map out websites, but often you are limited
    to style of output or the location in which the results are provided. This base
    plate for a spidering script allows you to map out websites in short order with
    the ability to alter them as you please.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 许多工具提供了绘制网站地图的功能，但通常你只能限制输出样式或提供结果的位置。这个爬虫脚本的基础版本允许你快速绘制网站地图，并且可以根据需要进行修改。
- en: Getting ready
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In order for this script to work, you'll need the `BeautifulSoup` library, which
    is installable from the `apt` command with `apt-get install python-bs4` or alternatively
    `pip install beautifulsoup4`. It's as easy as that.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个脚本工作，你需要`BeautifulSoup`库，可以通过`apt`命令安装，使用`apt-get install python-bs4`，或者使用`pip
    install beautifulsoup4`。就是这么简单。
- en: How to do it…
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This is the script that we will be using:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将要使用的脚本：
- en: '[PRE38]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: How it works…
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We first import the necessary libraries and create two empty lists called `urls`
    and `urls2`. These will allow us to run through the spidering process twice. Next,
    we set up input to be added as an addendum to the script to be run from the command
    line. It will be run like:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入必要的库，并创建两个名为`urls`和`urls2`的空列表。这将允许我们对爬虫过程进行两次运行。接下来，我们设置输入，作为脚本的附录添加到命令行中运行。它将运行如下：
- en: '[PRE39]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We then open the provided `url` variable and pass it to the `beautifulsoup`
    tool:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们打开提供的`url`变量，并将其传递给`beautifulsoup`工具：
- en: '[PRE40]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The `beautifulsoup` tool splits the content into parts and allows us to only
    pull the parts that we want to:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`beautifulsoup`工具将内容分成部分，并允许我们只提取我们想要的部分：'
- en: '[PRE41]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: We then pull all of the content that is marked as a tag in HTML and grab the
    element within the tag specified as `href`. This allows us to grab all the URLs
    listed in the page.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们提取在HTML中标记为标签的所有内容，并抓取标记指定为`href`的元素。这允许我们抓取页面中列出的所有URL。
- en: 'The next section handles relative and absolute links. If a link is relative,
    it starts with a slash to indicate that it is a page hosted locally to the web
    server. If a link is absolute, it contains the full address including the domain.
    What we do with the following code is ensure that we can, as external users, open
    all the links we find and list them as absolute links:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分处理相对链接和绝对链接。如果一个链接是相对的，它以斜杠开头，表示它是一个托管在Web服务器本地的页面。如果一个链接是绝对的，它包含完整的地址，包括域名。我们在下面的代码中所做的是确保我们作为外部用户可以打开我们找到的所有链接并将它们列为绝对链接：
- en: '[PRE42]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We then repeat the process once more with the `urls` list that we identified
    from that page by iterating through each element in the original `url` list:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们再次使用从该页面识别出的`urls`列表重复这个过程，通过遍历原始`url`列表中的每个元素：
- en: '[PRE43]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Other than a change in the referenced lists and variables, the code remains
    the same.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 除了引用列表和变量的更改，代码保持不变。
- en: We combine the two lists and finally, for ease of output, we take the full list
    of the `urls` list and turn it into a set. This removes duplicates from the list
    and allows us to output it neatly. We iterate through the values in the set and
    output them one by one.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们合并这两个列表，最后，为了方便输出，我们将`urls`列表的完整列表转换为一个集合。这将从列表中删除重复项，并允许我们整齐地输出它。我们遍历集合中的值，并逐个输出它们。
- en: There's more…
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This tool can be tied in with any of the functionality shown earlier and later
    in this book. It can be tied to *Getting Screenshots of a website with QtWeb Kit*
    to allow you to take screenshots of every page. You can tie it to the email address
    finder in the [Chapter 2](ch02.html "Chapter 2. Enumeration"), *Enumeration*,
    to gain email addresses from every page, or you can find another use for this
    simple technique to map web pages.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工具可以与本书中早期和后期展示的任何功能相结合。它可以与*使用QtWeb Kit获取网站截图*结合，允许您对每个页面进行截图。您可以将其与[第2章](ch02.html
    "第2章. 枚举")中的电子邮件地址查找器*枚举*结合，从每个页面获取电子邮件地址，或者您可以找到另一种用途来映射网页的简单技术。
- en: The script can be easily changed to add in levels of depth to go from the current
    level of 2 links deep to any value set by system argument. The output can be changed
    to add in URLs present on each page, or to turn it into a CSV to allow you to
    map vulnerabilities to pages for easy notation.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本可以很容易地更改，以添加深度级别，从当前的2个链接深度到系统参数设置的任何值。输出可以更改以添加每个页面上存在的URL，或将其转换为CSV，以便您可以将漏洞映射到页面进行简单的注释。
