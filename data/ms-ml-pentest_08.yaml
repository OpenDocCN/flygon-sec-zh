- en: Evading Intrusion Detection Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规避入侵检测系统
- en: Deploying intrusion detection systems is essential for every modern company,
    in order to defend against attackers. In the previous chapters, we learned how
    to build machine learning, based intrusion detection systems. Now, it is time
    to learn how to bypass these systems with adversarial learning; to defend your
    systems, you need to learn how to attack them first.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 部署入侵检测系统对于每家现代公司来说都是必不可少的，以防御攻击者。在前几章中，我们学习了如何构建基于机器学习的入侵检测系统。现在，是时候学习如何通过对抗学习来绕过这些系统了；为了保护您的系统，您需要先学会如何攻击它们。
- en: 'In this chapter, we will cover the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Adversarial machine learning algorithms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对抗机器学习算法
- en: Machine learning threat models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习威胁模型
- en: Evading intrusion detection systems with adversarial network systems
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用对抗网络系统规避入侵检测系统
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will need the following libraries:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将需要以下库：
- en: PyYAML
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyYAML
- en: NumPy
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy
- en: SciPy
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SciPy
- en: CVXPY
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CVXPY
- en: Python 3
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3
- en: Matplotlib
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib
- en: scikit-learn
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn
- en: Progress
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进展
- en: Pathos
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pathos
- en: CVXOPT (optional, as a CVXPY solver)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CVXOPT（作为CVXPY求解器的可选项）
- en: Jupyter Notebook
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter Notebook
- en: You can find the code files at [https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter08](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter08).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下网址找到代码文件：[https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter08](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter08)。
- en: Adversarial machine learning algorithms
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗机器学习算法
- en: 'Before studying adversarial machine learning, let''s explore two important
    terminologies: overfitting and underfitting.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习对抗机器学习之前，让我们探讨两个重要的术语：过拟合和欠拟合。
- en: Overfitting and underfitting
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合和欠拟合
- en: Overfitting is one of the biggest obstacles that machine learning practitioners
    face. Knowing how to spot overfitting is a required skill for building robust
    machine learning models, because achieving 99% accuracy is not the end of the
    story. In machine learning, we make predictions. By definition, the **fit** is
    how well we approximate the target function. As we saw in the first chapter, the
    aim of supervised learning is to map the function between the input data and the
    targets. Thus, a good fit is a good approximation of that function.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是机器学习从业者面临的最大障碍之一。知道如何发现过拟合是构建健壮的机器学习模型所必需的技能，因为达到99%的准确率并不是故事的结束。在机器学习中，我们进行预测。根据定义，**拟合**是我们对目标函数的逼近程度。正如我们在第一章中看到的，监督学习的目标是映射输入数据和目标之间的函数。因此，一个良好的拟合是对该函数的良好逼近。
- en: Overfitting happens when a model learns the details and noise in the training
    data, to the extent that it negatively impacts the performance of the model. In
    other words, noise is picked up and learned by the model, so it can no longer
    generalize well when it is fed new data. The following graph illustrates an overfitting
    situation. You will notice that the model has been trained too well, which makes
    it hard to achieve accuracy when we feed the model with data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合发生在模型学习训练数据中的细节和噪音，以至于负面影响了模型的性能。换句话说，模型学习到了噪音，因此在输入新数据时无法很好地进行泛化。下图说明了过拟合的情况。您会注意到模型已经训练得太好，这使得在向模型输入数据时很难实现准确性。
- en: 'Another obstacle is underfitting. This occurs when a machine learning model
    does not fit the data well enough. In other words, when the model is too simple:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个障碍是欠拟合。当机器学习模型不足够拟合数据时就会发生这种情况。换句话说，当模型过于简单时：
- en: '![](img/00191.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00191.jpeg)'
- en: Overfitting and underfitting with Python
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python进行过拟合和欠拟合
- en: 'Let''s look at a real-world demonstration of overfitting and underfitting,
    with scikit-learn. Import the required modules:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用scikit-learn来看一下过拟合和欠拟合的真实演示。导入所需的模块：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will now build a small model and visualize the model, the samples, and the
    `true` function, to see overfitting and underfitting. We will use the following
    code:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将构建一个小模型，并可视化模型、样本和`true`函数，以查看过拟合和欠拟合。我们将使用以下代码：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'By running the previous script, we draw the following graphs that illustrate
    3 cases: under-fitting, Good fitting and over-fitting (from left to right):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行前面的脚本，我们绘制了以下图表，说明了3种情况：欠拟合、良好拟合和过拟合（从左到右）：
- en: '![](img/00192.jpeg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00192.jpeg)'
- en: 'The following table was created using the terms highlighted in the previous
    code, and the corresponding URLs:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格是使用前面代码中突出显示的术语和相应的URL创建的：
- en: '| **Modules** | **URL** |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **模块** | **URL** |'
- en: '| `plt.subplot` | [https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html#matplotlib.pyplot.subplot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html#matplotlib.pyplot.subplot)
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `plt.subplot` | [https://matplotlib.org/api/_as-gen/matplotlib.pyplot.subplot.html#matplotlib.pyplot.subplot](https://matplotlib.org/api/_as-gen/matplotlib.pyplot.subplot.html#matplotlib.pyplot.subplot)
    |'
- en: '| `plt.setp` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.setp.html#matplotlib.pyplot.setp](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.setp.html#matplotlib.pyplot.setp)
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| `plt.setp` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.setp.html#matplotlib.pyplot.setp](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.setp.html#matplotlib.pyplot.setp)
    |'
- en: '| `PolynomialFeatures` | [http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures)
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| `PolynomialFeatures` | [http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures)
    |'
- en: '| `LinearRegression` | [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `LinearRegression` | [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)
    |'
- en: '| `Pipeline` | [http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `Pipeline` | [http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline)
    |'
- en: '| `np.newaxis` | [http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis](http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis)
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `np.newaxis` | [http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis](http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis)
    |'
- en: '| `cross_val_score` | [http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `cross_val_score` | [http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)
    |'
- en: '| `np.newaxis` | [http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis](http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `np.newaxis` | [http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis](http://docs.scipy.org/doc/numpy-1.8.1/reference/arrays.indexing.html#numpy.newaxis)
    |'
- en: '| `np.linspace` | [http://docs.scipy.org/doc/numpy-1.8.1/reference/generated/numpy.linspace.html#numpy.linspace](http://docs.scipy.org/doc/numpy-1.8.1/reference/generated/numpy.linspace.html#numpy.linspace)
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `np.linspace` | [http://docs.scipy.org/doc/numpy-1.8.1/reference/generated/numpy.linspace.html#numpy.linspace](http://docs.scipy.org/doc/numpy-1.8.1/reference/generated/numpy.linspace.html#numpy.linspace)
    |'
- en: '| `plt.plot` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot)
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `plt.plot` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot)
    |'
- en: '| `plt.scatter` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter)
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `plt.scatter` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter)
    |'
- en: '| `plt.xlabel` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `plt.xlabel` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel)
    |'
- en: '| `plt.ylabel` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel)
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `plt.ylabel` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel)
    |'
- en: '| `plt.xlim` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlim.html#matplotlib.pyplot.xlim](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlim.html#matplotlib.pyplot.xlim)
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `plt.xlim` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.xlim.html#matplotlib.pyplot.xlim](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.xlim.html#matplotlib.pyplot.xlim)
    |'
- en: '| `plt.ylim` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylim.html#matplotlib.pyplot.ylim](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylim.html#matplotlib.pyplot.ylim)
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `plt.ylim` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.ylim.html#matplotlib.pyplot.ylim](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.ylim.html#matplotlib.pyplot.ylim)
    |'
- en: '| `plt.legend` | [http://matplotlib.org/api/legend_api.html#matplotlib.legend](http://matplotlib.org/api/legend_api.html#matplotlib.legend)
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `plt.legend` | [http://matplotlib.org/api/legend_api.html#matplotlib.legend](http://matplotlib.org/api/legend_api.html#matplotlib.legend)
    |'
- en: '| `plt.title` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title)
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `plt.title` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title)
    |'
- en: '| `plt.show` | [http://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show](http://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `plt.show` | [http://matplotlib.org/api/_as-gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show](http://matplotlib.org/api/_as-gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show)
    |'
- en: Detecting overfitting
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测过拟合
- en: To detect overfitting, it is highly recommended to split the initial dataset
    into a training set and a testing set. If the training set performs way better
    than the testing set, then we have a problem. Also, it is highly recommended to
    start with a simple algorithm and move on to more complex models later, checking
    whether upgrading the level of complexity was worth it. To defend against overfitting,
    we can use cross-validation. Cross-validation is the process of evaluating many
    machine learning techniques by training models with different subsets (*k* subsets).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测过拟合，强烈建议将初始数据集分成训练集和测试集。如果训练集的表现远远好于测试集，那么我们就有问题。此外，强烈建议从简单的算法开始，然后再转向更复杂的模型，检查升级复杂度是否值得。为了防止过拟合，我们可以使用交叉验证。交叉验证是通过使用不同子集（*k*子集）训练模型来评估许多机器学习技术的过程。
- en: Adversarial machine learning
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗机器学习
- en: 'Adversarial machine learning is the art of studying how to break and secure
    machine learning models. You can consider it an intersection between machine learning
    and information security. As a security professional, learning how to build defensive
    layers with machine learning is important, but knowing how to break them is also
    an amazing addition to your skill set:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗机器学习是研究如何破解和保护机器学习模型的艺术。您可以将其视为机器学习和信息安全之间的交集。作为安全专业人士，学习如何使用机器学习构建防御层很重要，但了解如何破解它们也是您技能组合的一个很棒的补充：
- en: '![](img/00193.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00193.jpeg)'
- en: 'In 2006, Barreno, et al., proposed a taxonomy for the threat models against
    machine learning systems. The model is based on three axes:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 2006年，Barreno等人提出了针对机器学习系统的威胁模型的分类法。该模型基于三个轴：
- en: Influence
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 影响
- en: Security violations
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全违规
- en: Specificity
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特异性
- en: 'In 2011, the model was extended by Huang, et al., to include another axis,
    called **privacy**. In 2016, Papernot, McDaniel, Jha, Fredrikson, Celik, and Swami,
    introduced a new taxonomy that focuses on only two axes:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 2011年，黄等人扩展了该模型，包括另一个称为**隐私**的轴。2016年，Papernot，McDaniel，Jha，Fredrikson，Celik和Swami引入了一个专注于两个轴的新分类法：
- en: Complexity of the attack
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击的复杂性
- en: Knowledge of the attacker
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者的知识
- en: 'The following diagram illustrates the machine learning threat taxonomy:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了机器学习威胁分类：
- en: '![](img/00194.jpeg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00194.jpeg)'
- en: To attack machine learning models, attackers can perform many techniques, addressed
    in the following sections.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了攻击机器学习模型，攻击者可以执行许多技术，这些技术在以下部分中进行了讨论。
- en: Evasion attacks
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规避攻击
- en: To perform machine learning evasion attacks, cyber criminals try to bypass the
    learning outcomes by observing how the model works, especially the outcome, by
    trying many different samples simply by feeding the model with different inputs
    and trying to find the learning patterns. This technique is very popular. For
    example, if an attacker wants to bypass a machine learning spam filter, he needs
    to feed the system with different emails and search for a pattern that makes a
    spam email goes through (Not detected as a spam email) and bypass detection by
    doing only a few modifications to previously detected emails.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为执行机器学习规避攻击，网络犯罪分子尝试通过观察模型的工作方式，尤其是结果，尝试许多不同的样本，只需向模型提供不同的输入并尝试找到学习模式。这种技术非常流行。例如，如果攻击者想要规避机器学习垃圾邮件过滤器，他需要向系统提供不同的电子邮件并搜索使垃圾邮件通过（未被检测为垃圾邮件）并通过仅对先前检测到的电子邮件进行少量修改来规避检测的模式。
- en: 'The following workflow illustrates how an evasion attack works:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 以下工作流说明了规避攻击的工作原理：
- en: '![](img/00195.jpeg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00195.jpeg)'
- en: Poisoning attacks
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 毒害攻击
- en: 'In machine learning poisoning attacks, attackers poison the model in order
    to change the learning outcome, by adding malicious data in the model training
    phase. This method can be performed, for example, by sending and injecting carefully
    designed samples when data collection is occurring during network operations,
    to train a network intrusion detection system model. The following workflow illustrates
    how a poisoning attack occurs:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中毒攻击中，攻击者通过在模型训练阶段添加恶意数据来毒害模型，以改变学习结果。例如，可以通过在网络操作期间进行数据收集时发送和注入精心设计的样本来执行此方法，以训练网络入侵检测系统模型。以下工作流说明了毒害攻击的发生过程：
- en: '![](img/00196.jpeg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00196.jpeg)'
- en: 'Some of the greatest research conducted on adversarial machine learning was
    done in the *Pattern recognition and applications lab Italy, *including *Poisoning
    Attacks Against Support Vector Machines,* when Battista Biggio and his team presented
    a great framework to attack support vector machine systems. The steps are as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在*意大利模式识别与应用实验室*进行的一些最重要的对抗机器学习研究包括*针对支持向量机的毒害攻击*，当Battista Biggio及其团队提出了一个攻击支持向量机系统的重要框架。步骤如下：
- en: Identify a proper adversary's goal
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定适当的对手目标
- en: Define the adversary's knowledge
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义对手的知识
- en: Formulate the corresponding optimization problem
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制定相应的优化问题
- en: Resample the collected (training and test) data accordingly
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相应地重新采样收集的（训练和测试）数据
- en: Evaluate the classifier's security on the resampled data
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估在重新采样数据上的分类器安全性
- en: Repeat the evaluation for different levels of adversary knowledge
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 针对不同水平的对手知识重复评估
- en: If you are familiar with MATLAB, I highly recommend that you to try **ALFASVMLib**.
    It is a MATLAB library on adversarial label flip attacks on SVM. You can download
    it from [https://github.com/feuerchop/ALFASVMLib](https://github.com/feuerchop/ALFASVMLib).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您熟悉MATLAB，我强烈建议您尝试**ALFASVMLib**。这是一个关于SVM上对抗性标签翻转攻击的MATLAB库。您可以从[https://github.com/feuerchop/ALFASVMLib](https://github.com/feuerchop/ALFASVMLib)下载它。
- en: Adversarial clustering
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗聚类
- en: Clustering techniques are widely used in many real-world applications. Attackers
    are coming up with new techniques to attack clustering models. One of them is
    adversarial clustering, wherein the attackers manipulate the input data (adding
    a small percentage of attack samples), so that the newly added sample can hide
    within the existing clusters.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类技术广泛应用于许多实际应用中。攻击者正在提出新的技术来攻击聚类模型。其中之一是对抗聚类，攻击者通过操纵输入数据（添加少量攻击样本），使新添加的样本可以隐藏在现有的聚类中。
- en: Adversarial features
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗特征
- en: Feature selection is an important step in every machine learning project. Attackers
    are also using adversarial feature selection to attack models. I highly recommend
    that you read the research done by the same team (*Pattern recognition and applications
    lab Italy researchers*), presented in a paper called, *Is Feature Selection Secure
    Against Training Data Poisoning?*
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择是每个机器学习项目中的重要步骤。攻击者也在使用对抗性特征选择来攻击模型。我强烈建议您阅读同一团队（*意大利模式识别与应用实验室研究人员*）在一篇名为*特征选择对训练数据毒害是否安全？*的论文中所做的研究。
- en: The team showed that by poisoning the embedded feature selection algorithms,
    including LASSO, ridge regression, and the ElasticNet, they fooled a PDF malware
    detector.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 团队表明，通过污染嵌入式特征选择算法，包括LASSO、岭回归和ElasticNet，他们愚弄了PDF恶意软件检测器。
- en: There are many Python frameworks and open source projects that were developed
    by researchers to attack and evaluate machine learning models, like **CleverHans**,
    the **Adversarial Machine Learning** (**AML**) library, and **EvadeML-Zoo**.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多Python框架和开源项目是由研究人员开发的，用于攻击和评估机器学习模型，例如**CleverHans**，**对抗机器学习**（**AML**）库和**EvadeML-Zoo**。
- en: CleverHans
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CleverHans
- en: CleverHans is under continual development; it is an adversarial example library
    for constructing attacks, building defenses, and benchmarking machine learning
    systems' vulnerability to adversarial attacks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: CleverHans正在不断发展； 它是一个对抗性示例库，用于构建攻击、构建防御和评估机器学习系统对对抗性攻击的脆弱性。
- en: 'You can clone it from [https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans)克隆它：
- en: '![](img/00197.jpeg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00197.jpeg)'
- en: 'Or, you can install it by using the `pip` utility, as shown here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用`pip`实用程序进行安装，如下所示：
- en: '![](img/00198.jpeg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00198.jpeg)'
- en: The AML library
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AML库
- en: The AML library is a game-theoretic adversarial machine learning library, developed
    by the Computational Economics Research Lab at Vanderbilt University. By game
    theory we mean the study of mathematical models of cooperation between intelligent
    decision making agents. You can clone the library from [https://github.com/vu-aml/adlib](https://github.com/vu-aml/adlib).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: AML库是由范德堡大学计算经济研究实验室开发的博弈论对抗机器学习库。 通过博弈论，我们指的是智能决策代理之间合作的数学模型的研究。 您可以从[https://github.com/vu-aml/adlib](https://github.com/vu-aml/adlib)克隆该库。
- en: EvadeML-Zoo
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EvadeML-Zoo
- en: EvadeML-Zoo is a benchmarking and visualization tool for adversarial machine
    learning, developed by the Machine Learning Group and the Security Research Group
    at the University of Virginia. You can download it from [https://github.com/mzweilin/EvadeML-Zoo](https://github.com/mzweilin/EvadeML-Zoo).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: EvadeML-Zoo是由弗吉尼亚大学的机器学习组和安全研究组开发的对抗机器学习基准测试和可视化工具。 您可以从[https://github.com/mzweilin/EvadeML-Zoo](https://github.com/mzweilin/EvadeML-Zoo)下载它。
- en: Evading intrusion detection systems with adversarial network systems
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用对抗网络系统规避入侵检测系统
- en: By now, you will have acquired a fair understanding of adversarial machine learning,
    and how to attack machine learning models. It's time to dive deep into more technical
    details, learning how to bypass machine learning based intrusion detection systems
    with Python. You will also learn how to defend against those attacks.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经对对抗性机器学习有了相当的了解，以及如何攻击机器学习模型。 现在是时候深入了解更多技术细节，学习如何使用Python绕过基于机器学习的入侵检测系统。
    您还将学习如何防御这些攻击。
- en: 'In this demonstration, you are going to learn how to attack the model with
    a poisoning attack. As discussed previously, we are going to inject malicious
    data, so that we can influence the learning outcome of the model. The following
    diagram illustrates how the poisoning attack will occur:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个演示中，您将学习如何使用污染攻击攻击模型。 正如之前讨论的，我们将注入恶意数据，以便影响模型的学习结果。 以下图表说明了污染攻击的发生方式：
- en: '![](img/00199.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00199.jpeg)'
- en: In this attack, we are going to use a **Jacobian-Based Saliency Map Attack**
    (**JSMA**). This is done by searching for adversarial examples by modifying only
    a limited number of pixels in an input.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次攻击中，我们将使用**基于雅可比显著图攻击**（**JSMA**）。 这是通过仅修改输入中有限数量的像素来搜索对抗性示例。
- en: Let's look at how to attack a machine based intrusion detection system with
    Python. The code is a little bit long, so I am only going to include some important
    snippets; later, you can find the full code in the chapter's GitHub repository.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用Python攻击基于机器的入侵检测系统。 代码有点长，所以我只会包含一些重要的片段；稍后，您可以在本章的GitHub存储库中找到完整的代码。
- en: For this project, we need the NumPy, pandas, Keras, CleverHans, TensorFlow,
    scikit-learn, and matplotlib Python libraries.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，我们需要NumPy、pandas、Keras、CleverHans、TensorFlow、scikit-learn和matplotlib
    Python库。
- en: 'These are some of the imported libraries:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些导入的库：
- en: '[PRE2]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next step is pre-processing the data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是预处理数据：
- en: '[PRE3]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will then load the data with pandas:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用pandas加载数据：
- en: '[PRE4]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, concatenate the training and testing sets:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，连接训练和测试集：
- en: '[PRE5]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Select the data and identify the features:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 选择数据并识别特征：
- en: '[PRE6]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To identify DoS attacks, use the following:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要识别DoS攻击，请使用以下内容：
- en: '[PRE7]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Identify other attacks (**User-to-Root** (**U2R**), **Remote-to -Local** (**R2L**),
    and **Probe**) with the same technique.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同技术识别其他攻击（**User-to-Root**（**U2R**）、**Remote-to-Local**（**R2L**）和**Probe**）。
- en: 'To generate one-hot encoding, use the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成一热编码，请使用以下内容：
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Identify the training and testing sets again:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 再次识别训练和测试集：
- en: '[PRE9]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To scale the data, use the following command:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要缩放数据，请使用以下命令：
- en: '[PRE10]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'An example of `scale X_train` is as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`scale X_train`的示例如下：'
- en: '[PRE11]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s suppose that we are going to attack a logistic regression model; we
    need to process data to train that model and generate label encoding:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们要攻击逻辑回归模型； 我们需要处理数据以训练该模型并生成标签编码：
- en: '[PRE12]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We have now completed the pre-processing phase.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完成了预处理阶段。
- en: 'For the Jacobian-Based Saliency Map attack, we are going to use the following
    Python implementation:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于雅可比显著图攻击，我们将使用以下Python实现：
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To build a `MultiLayer Perceptron` network, use the following code snippet:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建`MultiLayer Perceptron`网络，请使用以下代码片段：
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/00200.jpeg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00200.jpeg)'
- en: 'For adversarial prediction, use the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于对抗性预测，请使用以下内容：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, we need to evaluate the model by feeding it with the adversarial testing
    data:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要通过提供对抗性测试数据来评估模型：
- en: '![](img/00201.jpeg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00201.jpeg)'
- en: If you get errors, check the chapter's GitHub repository. The code may be updated
    and enhanced after publishing this book.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出现错误，请检查本章的GitHub存储库。代码可能在出版后进行更新和增强。
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we provided an overview of adversarial learning techniques,
    and described how attackers and cyber criminals perform attacks against machine
    learning models.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们概述了对抗性学习技术，并描述了攻击者和网络犯罪分子如何对机器学习模型进行攻击。
- en: The next chapter will be a great complementary guide, exploring how to attack
    artificial neural networks and deep learning networks. You will learn how attackers
    can bypass modern anti-malware systems by using adversarial deep learning and
    reinforcement learning.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将是一个很好的补充指南，探讨如何攻击人工神经网络和深度学习网络。您将了解攻击者如何通过使用对抗性深度学习和强化学习来绕过现代反恶意软件系统。
- en: Questions
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Can you briefly explain why overtraining a machine learning model is not a good
    idea?
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您能简要解释一下为什么过度训练机器学习模型不是一个好主意吗？
- en: What is the difference between overfitting and underfitting?
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过拟合和欠拟合之间有什么区别？
- en: What is the difference between an evasion and poisoning attack?
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 规避攻击和中毒攻击之间有什么区别？
- en: How does adversarial clustering work?
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对抗性聚类是如何工作的？
- en: What type of adversarial attack is used to avoid the intrusion detection system?
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于规避入侵检测系统的对抗性攻击类型是什么？
- en: Is the preceding attack an evasion or poisoning attack?
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前面的攻击是规避还是中毒攻击？
- en: Further reading
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and
    Mitigation*: [https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf](https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人工智能的恶意使用：预测、预防和缓解*：[https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf](https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf)'
- en: '*Attacking Machine Learning with Adversarial Examples*: [https://blog.openai.com/adversarial-example-research/](https://blog.openai.com/adversarial-example-research/)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用对抗性示例攻击机器学习*：[https://blog.openai.com/adversarial-example-research/](https://blog.openai.com/adversarial-example-research/)'
- en: '*Awesome Adversarial Machine Learning*: [https://github.com/yenchenlin/awesome-adversarial-machine-learning](https://github.com/yenchenlin/awesome-adversarial-machine-learning)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*令人敬畏的对抗性机器学习*：[https://github.com/yenchenlin/awesome-adversarial-machine-learning](https://github.com/yenchenlin/awesome-adversarial-machine-learning)'
- en: '*Ensemble Adversarial Training: Attacks and Defenses*: [https://arxiv.org/pdf/1705.07204.pdf](https://arxiv.org/pdf/1705.07204.pdf)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*集成对抗训练：攻击和防御*：[https://arxiv.org/pdf/1705.07204.pdf](https://arxiv.org/pdf/1705.07204.pdf)'
- en: '*Introduction to Adversarial Machine Learning*: [https://mascherari.press/introduction-to-adversarial-machine-learning/](https://mascherari.press/introduction-to-adversarial-machine-learning/)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对抗性机器学习简介*：[https://mascherari.press/introduction-to-adversarial-machine-learning/](https://mascherari.press/introduction-to-adversarial-machine-learning/)'
- en: '*Adversarial Deep Learning Against Intrusion Detection Classifiers*: [http://www.diva-portal.org/smash/get/diva2:1116037/FULLTEXT01.pdf](http://www.diva-portal.org/smash/get/diva2:1116037/FULLTEXT01.pdf)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对抗性深度学习对入侵检测分类器的攻击*：[http://www.diva-portal.org/smash/get/diva2:1116037/FULLTEXT01.pdf](http://www.diva-portal.org/smash/get/diva2:1116037/FULLTEXT01.pdf)'
- en: '*Is Feature Selection Secure Against Training Data Poisoning?* ([http://pralab.diee.unica.it/sites/default/files/biggio15-icml.pdf](http://pralab.diee.unica.it/sites/default/files/biggio15-icml.pdf)
    )'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征选择是否能够抵御训练数据中毒？* ([http://pralab.diee.unica.it/sites/default/files/biggio15-icml.pdf](http://pralab.diee.unica.it/sites/default/files/biggio15-icml.pdf)
    )'
- en: '*Security evaluation of learning algorithms*: [http://pralab.diee.unica.it/en/SecurityEvaluation](http://pralab.diee.unica.it/en/SecurityEvaluation)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习算法的安全评估*：[http://pralab.diee.unica.it/en/SecurityEvaluation](http://pralab.diee.unica.it/en/SecurityEvaluation)'
- en: '*General Framework for AI and Security Threats*: [https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf](https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AI和安全威胁的通用框架*：[https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf](https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf)'
- en: '*The challenge of verification and testing of machine learning*: [http://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html:](http://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习验证和测试的挑战*：[http://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html:](http://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html)'
- en: '*Attacks Against Intrusion Detection Networks: Evasion, Reverse Engineering,
    and Optimal Countermeasures* (PhD thesis): [http://www.seg.inf.uc3m.es/~spastran/phd/PhD_Thesis_Sergio_Pastrana.pdf](http://www.seg.inf.uc3m.es/~spastran/phd/PhD_Thesis_Sergio_Pastrana.pdf)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*入侵检测网络的攻击：规避、逆向工程和最佳对策*（博士论文）：[http://www.seg.inf.uc3m.es/~spastran/phd/PhD_Thesis_Sergio_Pastrana.pdf](http://www.seg.inf.uc3m.es/~spastran/phd/PhD_Thesis_Sergio_Pastrana.pdf)'
