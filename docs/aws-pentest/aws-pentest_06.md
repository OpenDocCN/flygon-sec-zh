# 第四章：利用 S3 存储桶

S3 存储桶是 AWS 用来存储数据的主要资源之一。S3 存储桶是存储对象（如数据和元数据）的好方法。然而，与其他文件存储解决方案一样，S3 存储桶可以通过简单的配置错误轻松被利用。这些配置错误可能导致数据泄露和其他严重的安全问题。

在本章中，我们将深入研究 S3 存储桶、它们的功能以及如何利用公共存储桶和配置错误的存储桶。我们还将讨论现实世界的情景，以及 S3 存储桶中的漏洞如何成为许多公司普遍的全球问题。

在本章中，我们将涵盖以下主题：

+   AWS 区域和可用区

+   操作 S3 存储桶

+   S3 存储桶策略

+   了解公共存储桶

+   用于查找私有存储桶的脚本

+   一个基于目标的渗透测试场景

+   使用 Grayhat Warfare 发现存储桶

+   构建本地 S3 环境

# 技术要求

要按照本章的说明进行操作，您需要以下内容：

+   AWS CLI（在*第一章**中介绍，构建您的 AWS 环境*）

+   Bash

本章中使用的代码可在以下链接找到：

+   [`github.com/PacktPublishing/AWS-Penetration-Testing/tree/master/Chapter%204:%20Exploiting%20S3`](https://github.com/PacktPublishing/AWS-Penetration-Testing/tree/master/Chapter%204:%20Exploiting%20S3)

+   [`github.com/sa7mon/S3Scanner`](https://github.com/sa7mon/S3Scanner)

+   [`github.com/kromtech/s3-inspector`](https://github.com/kromtech/s3-inspector)

+   [`github.com/minio/minio`](https://github.com/minio/minio)

+   [`realpython.com/python-boto3-aws-s3/`](https://realpython.com/python-boto3-aws-s3/)

查看以下视频以查看代码的实际操作：[`bit.ly/3mJdY89`](https://bit.ly/3mJdY89)

# AWS 区域和可用区

在开始使用 S3 之前，我们应该讨论一些事情。了解 AWS 如何存储数据至关重要，因为了解如何和为什么有助于我们更好地理解基本原理。具有基本的理解能够让我们进一步理解我们已经知道的内容并从中发展。为了帮助我们更好地理解这一点，让我们在深入研究 S3 之前先讨论一下基础设施。

就像本地服务器通常存储在您的业务或组织附近一样，将存储在 AWS 中的信息尽可能地靠近您进行托管是明智的。我的意思是使用地理位置靠近您的系统来帮助支持您的云资源任务。这就是 AWS 区域发挥作用的地方，它允许您根据您的需求和位置地理分配资源。这些地理位置区域称为**区域**，可以在 AWS 中找到。您可以通过在 AWS 控制台右上角选择它们来查看区域。本书中我们一直在使用的当前区域是**俄勒冈**：

！图 4.1 - AWS 区域列表



图 4.1 - AWS 区域列表

AWS 区域是 AWS 用来托管数据和基础设施的各种地理位置。幸运的是，它们在全球范围内托管，各个主要国家都设有区域，允许您选择离您最近的区域。选择离您最近的基础设施意味着您或最终用户的延迟更小。目前，您可以选择几个区域。以下截图直接来自亚马逊，突出显示了所有区域和您可以选择的本地区域：

！图 4.2 - AWS 区域的更长列表



图 4.2 - AWS 区域的更长列表

您可以看到这里有许多区域可供选择。正如已经提到的，确保选择离您最近的区域。这将确保最佳资源利用，因为它们将位于您附近。

现在我们已经了解了 AWS 区域，让我们来看一些最佳实践。

AWS 区域最佳实践

在查看区域时，有一些日常维护的提示你需要记住。这些日常维护提示可以帮助你更好地使用你的云系统并优化速度。这些最佳实践更适用于企业级，但仍然是理解的关键：

+   选择离你最近的区域以最小化延迟。

+   一些较新的服务可能无法承载你需要的服务，所以确保你选择的区域具有你需要的服务。如果没有，选择下一个最接近支持所需服务的区域。

+   我无法再次强调这一点——*合规性*！确保无论你在做什么，都符合你所在地区的法规。不同的国家有不同的法律，所以确保你了解该地区内的协议。

现在我们了解了区域是什么，让我们来看看区域内托管的服务。这些服务被称为**可用区**。

## 可用区

可用区非常适合最小化冗余和停机时间，如果一个 EC2 实例宕机。可用区被创建用于允许你在多个区域分布 EC2 实例，这样如果你的实例在一个区域失败，它仍然可以在另一个区域访问。当然，这一切都是在后台发生的，你作为用户并没有注意到！如果你需要快速回顾一下 EC2 实例，回到*第一章**，构建你的 AWS 环境*，并快速复习一下。

继续前进，让我们看看下一个图表。该图表说明了 AWS 如何在每个区域内利用可用区。在本书中，我们将使用俄勒冈`us-west-2`的**可用区**：

![图 4.3 – 可用区的冗余](img/Figure_4.03_B15630.jpg)

图 4.3 – 可用区的冗余

考虑冗余非常重要，因为当一个服务宕机时，冗余是一个故障检查，确保这些服务保持运行。在生产或商业案例中，系统宕机可能意味着损失数百万，甚至数十亿美元！

重要提示

你可以在这里找到更多关于可用区的信息：[`docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions`](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions)

现在我们对资源如何分布在可用区有了更好的了解，让我们开始看看可能使用这些区域的服务。我们要讨论的第一个服务是 S3 及其存储解决方案 S3 存储桶。

# 连接和操作 S3 存储桶

中央文件存储对于组织来说是传统的，用于保护和存储数据。如果你在 IT 领域工作过，很可能你曾经设置过**服务器消息块**（**SMB**）共享在 Windows 上，以允许多个主机之间进行文件共享。允许文件集中资源化是协作和共享信息的好方法，同时也允许人员从另一个系统远程访问数据。设置文件服务器，存储和检索数据并不新鲜。新鲜的是我们如何可以使用同样的方法存储数据，只是现在我们可以使用被称为**S3**的技术在云中存储数据，或者如果你想拼出来的话，叫做**简单存储服务**。

那么，什么是 S3？S3 是一个简单的存储系统（顾名思义），允许用户在云中存储数据。就像我们在文件服务器上存储数据一样，我们可以将数据存储在所谓的 S3 存储桶中，这将保存我们数据的内容。你可以在这些存储桶中存储大量的数据，并随时检索它。

在这一部分，我们将学习关于 S3 存储桶的使用，以及如何创建和上传文件到 S3。让我们首先了解一下 S3 代表什么。

## 了解 S3 存储桶

正如前面提到的，S3 是一个简单的存储服务，允许用户将他们的数据存储在云中。这种存储解决方案默认是安全的；然而，用户和管理员对存储设置了一些策略，使其容易受到攻击。我们暂时不会担心 S3 存储桶的攻击和漏洞，因为我们需要先了解基础知识。在我们深入攻击之前，让我们先解答一些关于存储解决方案的问题：

+   信息是如何存储的？

+   它去哪了？

+   我们可以存储多少，它有多耐用？

S3 将您的数据存储在所谓的**对象**中，也被称为**对象存储**。对象存储允许您以对象的形式存储诸如图片、视频、文件以及与它们相关的任何数据。有各种存储类别我们不打算详细介绍，但您可以在这里了解更多：https://aws.amazon.com/s3/features/。

S3 被设计为“11 9's”模型，这意味着它具有数据耐久性，并且会自动在多个系统上创建和存储所有 S3 对象的副本。然而，这并不意味着 S3 对象将存储在操作系统中。S3 不像 EC2 实例，无法托管 Windows 或 Linux 等操作系统。

S3 也具有高度可扩展性，允许您存储看似无限的存储量；然而，没有什么是无限的，对吧？使 S3 存储无限增加了“11 9's！”模型，为安全可靠的存储带来成功。

现在，让我们开始看一下 S3 的使用以及在企业中的实际原则。

## 使用 S3 存储桶

重要的是，我们要理解为什么要使用云存储。它为公司提供了存储数据并能够访问数据的关键服务。正如前面提到的，S3 存储以下类型的数据：

+   图片

+   视频

+   文件

+   包含敏感数据的文件等

虽然我们了解可以存储的数据类型，但 S3 是如何使用的呢？它不仅仅是加载一个新的文本文档 - 它涉及冗余和备份数据！

在企业中使用 S3 解决方案的主要原因之一是备份和归档数据，否则这些数据将存储在备份位置，如热站点、温站点和冷站点。S3 就像一个热站点，因为数据随时可用和可访问。将 S3 作为备份存储解决方案也是灾难恢复的一个很好的实施。如果您的主文件系统意外崩溃，您的数据仍然可以在云中通过 S3 访问。

S3 也可以作为一个中央位置，用于在企业用户之间存储和分发数据。记住：S3 是关于扩展和存储，因此能够全球访问数据对于生产力非常重要。

现在我们对 S3 及其所包含的内容有了更好的理解，是时候开始看看 S3 存储桶以及我们如何可能利用它们了。

## S3 存储桶

现在我们对 S3 是什么以及它是如何工作的有了很好的理解，涉及存储信息和为企业备份数据。正如之前所述，S3 是一个简单的存储服务，将数据存储为对象。这些**对象**存储在所谓的**存储桶**中。简单来说，存储桶是 S3 中托管您的数据对象的基本容器。让我们简要了解一下这意味着什么，然后设置我们自己的存储桶。

重要提示

记住，S3 是云中的本地文件系统！

如前所述，S3 存储桶基本上类似于您在本地文件系统中找到的简单文件服务器，但它们存储在云中而不是在本地。存储桶存储可以随时上传和下载的对象。一些资源将存储在公共存储桶中，而其他资源将存储在内部，并且只有具有访问权限的用户才能使用。

为了简洁地介绍 S3 属性，这里有一些需要记住的事项：

+   S3 存储桶名称是唯一的，不能与其他人相同。这些名称特定于特定区域内的特定存储桶。我们稍后会看一下这一点。

+   您最多可以创建 100 个存储桶！这将为您提供充分的练习和存储空间。

+   存储桶是按区域分配的。重要的是要记住您将存储桶存储在哪些区域 – 这是您访问它们的方式！

+   它们可靠且足够满足您所有的存储需求。

+   S3 具有一个通用的命名空间，用于创建存储桶。

+   它们可以通过虚拟方式或通过路径访问 – 我们将在创建存储桶后讨论这一点。

现在您应该对 S3 是什么以及它是如何工作有了很好的理解。但是，如果您仍然不确定，不要担心 – 随着我们在本章中的深入学习，您将会更多地理解，并且随着我们在本书中的进一步学习，我们将应用更多的理论和实践。

接下来，让我们创建一个 S3 存储桶，然后看一些常见的安全问题以及如何利用它们。我们将使用 Kali Linux 作为我们的主机操作系统来与 S3 进行交互 – 确保您的本地 AWS Kali Linux 镜像是最新的，并且已安装 AWS CLI，如本章的*技术要求*部分所述。

### 创建 S3 存储桶

让我们开始将我们对 S3 的理论应用到实践中，并开始登录 AWS 控制台。登录后，让我们将 S3 服务图标固定到我们的主页上。我们将会经常使用它，所以将其保留在主页上是一个好的做法。

让我们按照以下步骤创建一个存储桶：

1.  首先，点击屏幕顶部的图钉图标。一旦您点击它，您将看到一个广泛的资源列表。点击并拖动**S3**图标到顶部：![图 4.4 – AWS 服务列表](img/Figure_4.04_B15630.jpg)

图 4.4 – AWS 服务列表

1.  您的屏幕顶部应该有以下内容。注意您屏幕顶部的**S3**图标：![图 4.5 – S3 图标添加为服务快捷方式](img/Figure_4.05_B15630.jpg)

图 4.5 – S3 图标添加为服务快捷方式

1.  现在您可以点击 S3 图标，然后转到 S3 存储桶页面。这就是我们开始创建存储桶的地方！点击上面写着**创建存储桶**的图标开始：![图 4.6 – S3 存储桶仪表板](img/Figure_4.06_B15630.jpg)

图 4.6 – S3 存储桶仪表板

1.  在下一个屏幕上，您需要为存储桶输入名称和区域：

重要提示

使用离您最近的区域。确保您的存储桶使用全球唯一的名称。例如，您不能有两个名为`AWSBucket`的存储桶。

![图 4.7 – S3 存储桶仪表板（创建和命名）](img/Figure_4.07_B15630.jpg)

图 4.7 – S3 存储桶仪表板（创建和命名）

1.  下一个屏幕将显示**配置选项**。在企业环境中，这是您开始考虑通过分配加密和日志记录来保护您的存储桶的起点。但是，对于此操作，我们将保持所有内容未选中：![图 4.8 – S3 存储桶配置选项](img/Figure_4.08_B15630.jpg)

图 4.8 – S3 存储桶配置选项

1.  接下来，我们将希望将存储桶设为公开。如果这是一个真实的场景，我们会避免设置一个这样的存储桶；然而，我们希望确保存储桶对我们的实验目的是公开的。公开的存储桶是导致 S3 成为主要漏洞的攻击的大多数来源。通过取消**阻止所有公共访问**，你将使存储桶对任何人都是公开的：![图 4.9 – S3 存储桶配置选项](img/Figure_4.09_B15630.jpg)

图 4.9 – S3 存储桶配置选项

1.  检查所有你的配置并点击**创建存储桶**：

![图 4.10 – S3 存储桶审查](img/Figure_4.10_B15630.jpg)

图 4.10 – S3 存储桶审查

干得好！你刚刚创建了你的第一个 S3 存储桶！这个存储桶将作为本书中易受攻击的存储解决方案，所以确保你不要删除它。

现在让我们看看上传数据的方法，并了解渗透测试 S3 存储桶的方法如何检索信息。在开始之前，让我们创建一个管理员用户，这个用户将给我们一个访问 ID 和一个密钥，我们可以用它来连接到我们的 AWS S3 环境。

## 快速绕道 - 创建 IAM 用户

有一个用户访问 S3 是至关重要的，所以前往 AWS 控制台的以下区域并开始：https://console.aws.amazon.com/iam/home?#/users。

一旦你到达**身份和访问管理（IAM）**页面，按照下面的步骤创建一个用户，我们可以用它来访问我们的 S3 存储桶：

1.  点击左上角的**添加用户**。

1.  给你的用户取一个名字。

1.  勾选以下选项：

--**AWS 管理控制台访问**

**--程序化访问**

1.  点击**下一步**。

1.  跳过添加标签。

1.  审查并创建一个**用户**！

之后，你将得到一个**访问密钥 ID**、**秘密访问密钥**和**密码**。保存这些并将它们存放在一个安全的地方：

![图 4.11 – 成功创建 IAM 用户](img/Figure_4.11_B15630.jpg)

图 4.11 – 成功创建 IAM 用户

现在我们了解了如何创建用户，让我们看看如何配置它们用于我们的 AWS 环境，并将数据复制和上传到 S3 存储桶。

## 复制并上传到 S3

太好了 - 现在我们有一个用户可以用来访问我们的 S3 存储桶。上传文件到 S3 存储桶是处理 S3 存储桶最基本的用途。这是我们将信息安全地和安全地传输到云端的方式。

数据可以上传到 S3 的两种方式：

1.  使用 Web 浏览器

1.  使用 AWS CLI

我们将两者都使用，但依赖 CLI 进行我们的渗透测试方法。虽然拥有**图形用户界面**（**GUI**）是一个很好的选择，但在可用时最好使用 CLI - 这通常会给你更多的选择，并且在 GUI 失败时会更加稳定。这个用户拥有管理员权限，这意味着它有**读**和**写**权限。让我们看看我们如何通过 CLI 上传文件到 S3：

1.  使用你创建的用户的**访问密钥 ID**和**秘密访问密钥**连接到你的 AWS 环境：

```
$ aws configure
```

1.  输入你的用户的 ID 和密钥。在提示时，将区域和输出格式留空。现在你应该已经设置好并连接上了。现在让我们来检查一下存储桶，并通过列出 S3 存储桶的内容来验证内容：

```
$ aws s3 ls s3://
```

现在你应该能够看到你创建的存储桶以 Linux 类型的格式列出。在我们继续之前，让我们分解这个命令，这样我们就能理解每个参数的作用：

+   `aws`：这个命令允许你与你的 AWS 环境进行交互。

+   `s3`：这个参数将使你能够访问你的`s3`存储桶。我们可以在这里放其他命令，我们稍后会发现。

+   `ls`：我们之前提到过这个。`ls`允许用户列出文件系统的内容。我们可以在各种操作系统和`s3`文件系统中使用它。

+   `s3://`：简单地说，这允许你通过`s3`访问文件系统。这种语法类似于其他访问本地文件系统的语法，比如 SMB 或 FTP。

现在您了解了命令的作用，让我们继续前进并创建一个可以上传到存储桶的文件。我们找到了我们创建的目录；下一步是列出可能在目录中的任何内容。在这种情况下，我们不会有任何内容。

以下将允许我们创建一个文件：

1.  输入以下命令以列出目标存储桶的内容：

```
$ aws s3 ls s3://packetawspentesting
```

1.  现在在终端中创建一个稍后可以上传的文件：

```
$ echo "TESTING FOR AWS PENETESTING" > test.txt
```

1.  确保文件内容被正确写入：

```
$ cat test.txt
```

1.  现在上传文件的内容：

```
$ aws s3 cp test.txt s3://packtawspentesting
```

1.  验证文件：

```
$ aws s3 ls s3://packtawspentesting
```

恭喜，您已成功从 AWS 命令行上传了一个文件！您还可以在 AWS Web 控制台中检查您的文件，其内容应该如下所示：

![图 4.12 - 从 AWS 控制台查看文本文件](img/Figure_4.12_B15630.jpg)

图 4.12 - 从 AWS 控制台查看文本文件

回顾一下，这是我们完成 S3 存储桶上线的步骤：

1.  创建了 IAM 用户

1.  配置并连接到您的 AWS 环境

1.  列出了 S3 存储桶的内容

1.  创建了一个文件并将其复制到存储桶中

现在我们已经创建了一个存储桶，让我们看看在进行 S3 渗透测试时可能会看到的一些常见配置错误。

# 存储桶策略和 ACL

存储桶策略和**访问控制列表**（**ACLs**）用于访问控制 - 作为允许和拒绝对 AWS 环境中 S3 资源访问的第一道防线。ACL 和存储桶都使用 JSON 或 YAML 来编写它们的策略，这可能会使事情变得困难或容易，这取决于您的观点。

现在让我们继续向前看看这些策略是如何创建的！

## 公共存储桶策略

在进行 S3 渗透测试时，您首先要做的事情之一是查看 S3 存储桶的策略是什么。以下是一个简单的存储桶策略的示例，我们将创建它，并且如何根据该策略开始与存储桶进行交互。

按照以下步骤创建一个存储桶，然后列出其策略：

1.  转到 S3 存储桶页面，点击我们创建的存储桶。

1.  接下来，点击**权限**选项卡。

1.  确保在**阻止所有公共访问**上没有选中任何内容：![图 4.13 - S3 存储桶访问视图](img/Figure_4.13_B15630.jpg)

图 4.13 - S3 存储桶访问视图

1.  接下来，转到**存储桶策略**部分，点击**策略生成器**，位于页面左下角附近。

1.  从这里，您将希望设置以下参数：

--**选择策略类型**：**S3 存储桶策略**

--**效果**：**允许**

--**主体**：***** – 放置***注释表示我们选择了“全部”

--**AWS 服务**：**Amazon S3**

--**操作**：**所有操作**

--**ARN**：**您的存储桶的 ARN**

1.  您将能够创建策略并上传它：

![图 4.14 - S3 存储桶策略](img/Figure_4.14_B15630.jpg)

图 4.14 - S3 存储桶策略

现在我们已经更新了策略，让我们看看如何从 AWS CLI 中读取它：

```
$ aws s3api get-bucket-policy --bucket packtawspentesting 
```

这将给我们提供存储桶策略的结果；但是，我们可以使用以下命令使格式更加易读，使用`json 工具`输出信息：

```
$ aws s3api get-bucket-policy --bucket packtawspentesting --output text | python -m json.tool
```

以下截图显示了前面命令的输出：

![图 4.15 - 通过终端获取 S3 存储桶策略](img/Figure_4.15_B15630.jpg)

图 4.15 - 通过终端获取 S3 存储桶策略

如您所见，我们已成功以更易读的格式列出了我们存储桶的策略。

## 了解策略属性

了解策略的每个部分意味着什么以及它的作用是至关重要的。您不需要了解 JSON 就知道策略在做什么。让我们解剖刚刚制作的策略，并看看每个属性的含义。让我们看看我们将要查看的一些基本属性是什么：

+   `ID`：用作参考号。

+   `版本`：告诉用户正在使用的策略版本。

+   `操作`：这告诉您正在使用的资源类型。在本章中，我们使用的是 S3。

+   `效果`：策略的这部分将“拒绝”或“允许”访问资源。

+   `资源`：ARN 放在这里，告诉策略策略被应用到哪个资源。

## 编写策略绕过策略

现在让我们来看看如何编写一个新的存储桶策略。在这个练习中，使用内置在 AWS 控制台中的策略生成器。为此，我们将创建一个新的存储桶；只是这一次，我们将创建一个具有更严格策略的存储桶。它的`效果`应该设置为`拒绝`而不是`允许`。

你的新存储桶的策略应该是这样的：

```
{
  "Id": "Policy1582144841563",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1582144836532",
      "Action": "s3:*",
      "Effect": "Deny",
      "Resource": "arn:aws:s3:::readthisblockthis",
      "Principal": "*"
    }
  ]
}
```

继续前进，让我们看看如何上传文件到我们的 S3 存储桶：

1.  列出存储桶的内容：

```
$ aws s3 ls s3://
```

现在我们知道要针对哪些存储桶，让我们制作一个文件并上传到存储桶中：

![图 4.16 - 列出存储桶的内容并将文件复制到存储桶中](img/Figure_4.16_B15630.jpg)

图 4.16 - 列出存储桶的内容并将文件复制到存储桶中

1.  现在我们已经确认我们可以上传文件到存储桶，这给了我们一个暗示，我们应该能够上传几乎任何文件到存储桶。接下来，让我们拿出我们的策略，改变一行，这将允许我们对 S3 存储桶进行任何操作：

```
{
  "Id": "Policy1582144841563",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1582144836532",
      "Action": "s3:*",
      "Effect": "Allow",
      "Resource": "arn:aws:s3:::readthisblockthis",
      "Principal": "*"
    }
  ]
}
```

1.  就是这么简单。现在我们需要将这个上传到我们的存储桶。将新策略保存为`policy.json`，并使用以下命令上传它：

```
$ aws s3api put-bucket-policy --bucket readthisblockthis  --policy policy.json
```

现在你将有一个更过度宽松的策略，允许你更多的控制。这在企业级别上可能是危险的——它将使用户能够在没有适当授权的情况下随意更改策略。

现在我们了解了如何制定存储桶策略，让我们继续前进，开始看看公共存储桶的危险。

# 公共存储桶

公共存储桶是 AWS 和 S3 最大的安全风险之一。由于 S3 的配置错误导致了大量数据泄漏。一些已经报告的问题如下：

+   对 S3 存储桶的监控不足。没有监控，确实没有稳定的方法来检查对 S3 环境的访问。

+   对 S3 环境的测试和审计不足，这证明是一个安全问题。像漏洞评估或者简单的渗透测试这样简单的事情都会帮助发现可以轻松修复的问题。

+   宽松的策略是另一个问题。如果策略允许太多用户访问 S3 资源，如果这些帐户被攻破，问题可能会出现。

围绕 S3 安全的普遍观点强调，监控将提高 S3 的安全姿态；然而，监控只是战斗的一半。正如我们所看到的，过度宽松的策略也可以允许用户进行被认为是“未经授权”的更改。未经授权这个词被轻描淡写地使用，因为策略在技术上说是允许的，但是良好的做法建议不要这样做。

现在让我们开始继续前进，看看存储桶中的公共配置错误。

## 存储桶配置错误

就像本地文件系统一样，配置错误可能是保护网络的全部和终极目标。重要的是要寻找可以被利用的简单和微小的细节。S3 是以安全为前提的，这意味着它是默认安全的。在这本书和现实世界中，你将看到的配置错误通常涉及到配置错误的策略允许对特定资源过多的访问，或者可以轻松绕过的权限。

虽然在本章中我们创建了容易受攻击的存储桶，并在整本书中总体上看了一些弱点问题，但是确保你保护所有资源以防止它们被利用是至关重要的。

我们已经讨论了如何查找配置错误的策略，在“编写策略绕过策略”部分。现在让我们看看在 AWS 环境中如何搜索公共存储桶中的数据。

让我们开始，使用我们的**访问密钥 ID**和**秘密访问密钥**进行认证。一旦在环境中进行了认证，让我们使用以下步骤来查找公共存储桶：

1.  列出 AWS 环境中的存储桶：

```
awspublicpackt that seems like a possible target for public misconfigurations. Let's move forward and pull the public block from it.
```

1.  下一条命令将向我们显示存储桶是否允许任何公共访问：

```
$ aws s3api get-public-access-block --bucket awspublicpackt
```

运行命令后，我们将看到一些输出，列出了所有设置为 false 的访问控制列表。将 ACL 设置为 false 意味着所有访问都是公开的，存储桶没有授权控制围绕它放置：

![图 4.17 - 公共存储桶 awspublicpackt 的输出](img/Figure_4.17_B15630.jpg)

图 4.17 - 公共存储桶 awspublicpackt 的输出

从命令的输出中可以看出，我们可以确认存储桶是公开的。如果在渗透测试中发现了这一点，就需要记录下来，并告知客户应拒绝公共访问，除非存储桶出于业务原因是公开的。此外，如果存储桶需要保持公开，就需要告知用户不要在被视为敏感的存储桶中存储任何信息。

在接下来的部分，我们将讨论一个略有不同的主题。我们将讨论脚本编写以及如何在 S3 存储桶的安全方面使用脚本。

# 查找私有存储桶的脚本

脚本编写在网络安全领域是一项备受追捧的技能，因为拥有脚本任务的知识和能力可以让你以更高效的速度自动化并提供结果，同时执行另一个任务。脚本编写也是解决可能是独特的问题的好方法 - 在这种情况下，查找可能没有常见名称的存储桶。存储桶只能有一个唯一的名称，没有一个存储桶是相同的，所以拥有已知存储桶的字典列表对你没有直接帮助。这意味着你需要制作存储桶名称的修改版本，并将其放在一个文本文件中，以便用于发现存储桶名称。

现在我们对 S3 有了大量的知识，让我们来看看你可以在下一次渗透测试中使用的一些脚本。我们将看两种流行的语言：Python 和 Bash。

## Python 脚本

Python 是安全社区中的标准编程语言，因为它简单易用。许多安全工程师使用它，因为它允许你即时创建、自动化和监控一切！回想一下，我们在*第二章**，渗透测试和道德黑客*中设置了 PyCharm，并编写了一个简单的程序来了解 Python 的工作原理。

请注意，这不是一门 Python 课程，所以我们不会讨论 Python 的内部工作原理；然而，**Packt Publishing**提供了大量的 Python 书籍。鼓励大家去阅读本书未涉及的材料。

我们需要安装 AWS 的 Boto3 SDK。**SDK**是**软件开发工具包**的缩写，在这种情况下，你可以使用 Boto3 直接从你的 Python 脚本中创建、更新和删除 AWS 资源。

重要提示

Boto3 是 AWS 的**软件开发工具包**（**SDK**），用于 Python，允许开发人员编写可以利用 S3 和 EC2 等服务的代码。

以下步骤将帮助你正确执行这一过程：

1.  打开终端并输入以下命令来安装`boto3`：

```
$ pip install boto3
```

1.  现在你有了允许你使用 Python 构建 S3 存储桶的 SDK！让我们创建一个文件，我们可以在其中存储我们的凭据：

```
$ touch ~/.aws/credentials
```

1.  这将创建一个文件，你可以在其中存储你的凭据。使用文件编辑器打开文件，并输入以下参数：

```
west 2. 
```

现在你已经准备好使用`boto3`和 Python 与你的 S3 存储桶进行交互了！

有很多与 S3 和 Python 交互的方式 - 本书的目的是展示这样做的基础知识，但是，请将本书作为入门指南，并“保持好奇”，查看更多有关 Python 脚本编写的资源。

现在您已经设置了 boto3，这是一个很好的资源：https://docs.ceph.com/docs/master/radosgw/s3/python/

现在让我们创建一个脚本，可以帮助我们查找允许我们在 S3 环境中查找存储桶的脚本。您可以使用 Python 终端来编写以下脚本：

1.  我们在末尾使用`.py`扩展名创建一个文件 - 例如，`myBucket.py`。

无论您选择使用哪种方式，以下脚本都将帮助您查找存储桶：

```
import boto3
s3 = boto3.resource('s3')
my_bucket = s3.Bucket('my_bucket_name')
for object_summary in my_bucket.objects.filter(Prefix="dir_name/"):
    print(object_summary.key)
```

强烈建议将此脚本放在 PyCharm 中，以便以后使用 - 或者扩展它的功能。在 PyCharm 中编辑文件也可以成为默认操作，使 PyCharm 成为您的主要工作空间。

现在我们已经看到了如何制作一个简单的脚本来查找存储桶，让我们来看看一些**Bash**脚本。

## Bash 脚本

**Bash**是一种支持自动化任务的脚本语言，在我们的情况下，它帮助我们实现测试 S3 的目标。**Bourne Again SHell**，或者简称**Bash**，是一个经常内置于操作系统中的 shell 进程 - 就像我们在整本书中都在使用的 Kali Linux 发行版一样。

为了确保您的环境中已经设置了**Bash**，请在 Kali Linux 终端中键入以下命令：

```
$ echo $SHELL
```

现在您已经验证了您的机器上是否设置了**Bash**，让我们创建一个可以用来查找可能没有常见名称的存储桶的脚本。按照以下步骤进行：

1.  使用`vi`文本编辑器打开一个新文件：

```
$ vi Buckets.sh
```

1.  您应该已经打开了`vi`编辑器。现在，在终端中输入以下文本。您需要同时按下*Shift* **+** *I*开始输入。

以下脚本是用来发现潜在存储桶的：

![图 4.18 - Bash 脚本](img/Figure_4.18_B15630.jpg)

图 4.18 - Bash 脚本

完成后，按*Esc*，然后输入`:wq`保存并关闭终端。该命令将允许您保存并退出程序。

如果您想要验证脚本是否保存正确，您可以从文件中使用`cat`命令，应该会看到以下代码：

```
#!/bin/bash
while read F ; do
    count=$(curl $1/$F -s | grep -E "NoSuchBucket|InvalidBucketName" |wc -l)
    if [[ $count -eq 0]]
    then
       echo "Bucket Found: "$F
    fi
done < $2
```

一旦您准备好脚本，使用您的存储桶的 ARN 并扫描存储桶。

现在我们将利用到目前为止学到的所有知识，并且做一些非常重要的事情 - 在渗透测试场景中使用它。这个演练有助于突出 AWS 渗透测试可能执行的真实潜在方式。

# 基于目标的渗透测试场景

现在让我们开始向前迈进，看一些在现实环境中相对常见的渗透测试 S3 的真实场景。虽然它可能看起来不像典型的“渗透测试”，因为 AWS 渗透测试不使用典型的渗透测试方法，但它仍然可以实现发现问题并利用它们的任务。基于目标的渗透测试意味着以“目标”为目标测试一个目标。在这种情况下，我们正在寻找可能存在于 S3 存储桶中的问题和失误。通常，组织希望了解特定资源的脆弱性以及导致脆弱性的路径如何被利用。

在这个例子中，我们将看看一个不安全的存储桶是如何导致我们删除一个重要文档，然后上传一个同名文档的。我们将使用一个“假设模型”，这意味着我们已经对系统有某种类型的访问。在我们进行练习之前，让我们看看我们将要做什么：

1.  我们需要访问 S3 环境 - 我们将使用我们的凭据。由于我们是在一个假设的模型上操作，这意味着我们将作为一个近端操作。

1.  接下来，我们将获取存储桶中对象的信息。

1.  然后我们将删除对象并创建自己的对象进行上传 - 然后将对象上传到存储桶中。

现在我们有了需要的东西，让我们执行这个计划并继续前进。以下是如何正确执行这一步骤的逐步过程：

1.  使用`AWS configure`进入你的环境。记住，因为我们使用的是“假设”模型，我们就像已经有权限访问环境的人一样行事。

一旦你配置并连接好了，下一步就是列出存储桶的内容：

```
$ aws s3 ls s3://
```

1.  既然我们看到了存储桶，让我们来看看`test`存储桶：

```
$ aws s3 ls s3://the-moose-bucket-test
```

1.  嗯，看起来我们有一个秘密文件，肯定是有人留下的。不幸的是，存储桶是公开的，并且很快就被创建，所以安全性是事后考虑的。接下来，让我们去获取这个秘密文件：

```
$ aws s3 cp s3://the-moose-bucket-test
```

1.  很好，现在我们有了文件！使用我们的 Kali Linux 机器，让我们看看文件的内容：

```
$ cat secret.txt
```

![图 4.19 - 列出存储桶的文件](img/Figure_4.19_B15630.jpg)

图 4.19 - 列出存储桶的文件

1.  我们可以深入研究并查看谁拥有这个对象。在真正的渗透测试中，这可能是欺骗或社会工程攻击的有用信息：

```
$ aws s3api list-objects --bucket the-moose-bucket-test
```

![图 4.20 - 列出对象的内容](img/Figure_4.20_B15630.jpg)

图 4.20 - 列出对象的内容

看起来这不是为我们准备的；然而，因为我们正在进行渗透测试，向客户说明安全性的重要性是至关重要的。为了做到这一点，我们需要删除文件并上传一个新的文件。确保你保留原文件，以便客户可以拿回文件。

重要提示

如果这是一次真正的渗透测试，并且文件包含敏感数据，那么你会立即停止渗透测试，并在继续之前通知客户。

继续我们的测试，让我们看看是否可以删除文件：

1.  所以，我们有了我们的文件，现在让我们删除那个文件：

```
$ aws s3api delete-object --bucket the-moose-bucket-test --key secret.txt
```

1.  创建一个新文件：

```
$ echo "You have been pwn'd! Please ensure to secure your buckets!" >> secret.txt
```

1.  上传文件：

```
$ aws s3api put-object --bucket the-moose-bucket-test --key secret.txt
```

我们成功删除了旧文件，并上传了我们自己的新文件！正如你所看到的，留下公开的存储桶是一个严重的问题，可以通过设置适当的访问控制来轻松解决，从而拒绝未经授权的用户访问包含不适合他们的数据的文件。

现在我们对如何在现实的渗透测试情况下找到存储桶有了更好的理解，让我们看看另一个你可以通过自己选择的浏览器使用的工具。这个名为**Grayhat Warfare**的 Web 工具允许你通过其搜索引擎进行查询来发现存储桶。

# 使用 Grayhat Warfare 发现存储桶

我们接下来要提到的工具是我个人最喜欢的。它使发现开放的 S3 存储桶变得简单高效。基于 Web 的工具**Grayhat Warfare**允许用户通过简单的查询快速找到开放的存储桶，并且还允许我们通过搜索各种文件类型快速找到其他文档。

让我们快速看一个例子，它将在`packtpub.com`域下查找文件。

首先，打开你的网络浏览器，然后转到[`buckets.grayhatwarfare.com/`](https://buckets.grayhatwarfare.com/)：

1.  接下来，在工具的**关键词**部分搜索[packtpub.com](http://packtpub.com)。一旦在**关键词**框中输入名称，点击**搜索**：![图 4.21 - 使用 Grayhat Warfare 搜索 packtpub.com](img/Figure_4.21_B15630.jpg)

图 4.21 - 使用 Grayhat Warfare 搜索 packtpub.com

1.  你会看到一个横幅，上面写着**“packtpub com”的结果**。在横幅下面，你会看到一个存储桶列表。在我们的例子中，我们只发现了一个存储桶，但是随着时间的推移，你完成这个练习时可能会发生变化：![图 4.22 - 使用 Grayhat Warfare 发现 packtpub.com 存储桶](img/Figure_4.22_B15630.jpg)

图 4.22 - 使用 Grayhat Warfare 发现 packtpub.com 存储桶

1.  从这里，你可以点击存储桶并下载存储桶内的对象，如果你选择的话。这个例子更多地关注方法论，而不是执行完整的工具。

在使用**Grayhat Warfare**时，请确保您使用最佳实践，并且仅出于道德目的使用该工具。这是什么意思？这意味着虽然使用该工具是 100%合法的，但如果您发现与其域关联的泄漏的存储桶，您应该通知任何公司。

重要提示

泄漏的存储桶是一个向互联网开放并泄漏敏感信息的 S3 存储桶。如果发现泄漏的存储桶，请立即联系所有者并通知他们！

这也意味着不要出于不道德的原因使用该工具，例如使用发现的数据来伤害组织。

继续前进，让我们开始结束本章。我们已经学到了很多关于 S3 环境以及如何操纵和利用 S3 存储桶。接下来，让我们讨论一些关于 S3 的额外内容，然后开始结束。

# S3 Burp Suite 扩展

Burp Suite 是一个常用于 Web 应用程序测试的工具。我们不打算深入了解 Burp Suite 的工作原理，但是请访问 PortSwigger 网站以获取更多详细信息：https://portswigger.net/burp。

有了大量可用的扩展，`aws-extender`。该扩展允许您扫描 S3 存储桶中的配置错误。

在我们开始之前，我们需要确保安装了最新的 Python 软件包。

在这里下载：[`github.com/jythontools/jython`](https://github.com/jythontools/jython)。

现在让我们继续并获取该工具的副本：

1.  首先获取软件包的副本：

```
$ git clone https://github.com/jythontools/jython.git
```

按照网站上提供的说明继续。

1.  安装新的`jython`软件包后，从此存储库将该工具克隆到您的计算机：[`github.com/VirtueSecurity/aws-extender.git`](https://github.com/VirtueSecurity/aws-extender.git)：

```
$ git clone https://github.com/VirtueSecurity/aws-extender.git
```

1.  完成后，您需要转到扩展并使用`pip`安装要求：

```
$ pip install -r requirements.txt
```

这部分可能需要一些时间，所以请耐心等待。

现在您需要将扩展加载到 Burp Suite 中。您可以在终端中找到`burpsuite`，然后启动该应用程序。启动应用程序后，转到`aws-extender` Python 程序目录。

我们将迅速转向另一个方向，看一些非常有趣的东西 - 创建一个本地 S3 实验室，供您练习使用！

## 创建一个本地 S3 实验室

有时您可能希望在不设置云中的文件系统的情况下测试 S3。由于 S3 只允许唯一名称，因此查找“测试”名称可能变得麻烦，并且创建测试环境可能会很繁琐。但是，这不应妨碍您能够设置一个本地实验室，以便更多地了解 S3。

**MinIO**是一个本地存储系统，可用于存储您希望在云中使用的数据。我们在书中提到它的原因是因为它是学习本地网络上的 S3 存储的一个很好的方式，而不仅仅局限于使用 AWS 中可用的名称。然而，MinIO 的一个缺点是，如果您习惯于使用 AWS 进行典型策略生成，那么策略设置可能会有点学习曲线或奇怪。

现在您可以这样做 - 设置一个本地 S3 实验室，您可以使用一个名为**MinIO**的程序，根据他们的说法：

*MinIO 是根据 Apache 许可证 v2.0 发布的高性能对象存储。它与 Amazon S3 云存储服务兼容。使用 MinIO 构建用于机器学习、分析和应用数据工作负载的高性能基础设施。*

*- MinIO*

您可以在这里找到有关 MinIO 项目的更多信息：[`github.com/minio/minio`](https://github.com/minio/minio)。

重要提示

您可以在这里找到有关如何设置 MinIO 的完整演练：`medium.com/@jonathanchelmus/creating-an-s3-lab-on-an-ec2-instance-95ffd8ac6c1`。

我强烈建议查阅文档，并建立一个本地实验室，用于测试和构建您的 S3 技能，方便使用您的本地实验室。

# 总结

在本章中，我们学到了很多关于 S3 存储桶以及一些利用常见公共存储桶问题的方法。我们还了解了更多关于 AWS 区域和可用区域以及它们与 S3 存储桶和 AWS 的关系。本章还介绍了各种脚本语言，如 Python 和 Bash，以及我们如何使用 Python 和 Bash 来扫描 S3 存储桶。

最后，我们通过将概念验证应用于我们创建的公共 S3 存储桶，来看了一个“现实世界”的场景。鼓励您创建自己的场景并执行它们-同时要遵守 AWS 实践和政策的法律范围。

最后，我们看了一些其他项目，可以帮助我们更深入地了解 S3，而无需使用 AWS。像 MinIO 这样的技术是一个很好的资源，如果您想要建立一个本地 S3 存储桶实验室。

在下一章中，我们将讨论 RDS 的概念，讨论一些关键点，并使用 MySQL 设置 RDS 数据库。

# 进一步阅读

+   公共存储桶工具：[`github.com/Moos1e/Recon-Public-Buckets/tree/master`](https://github.com/Moos1e/Recon-Public-Buckets/tree/master)

+   EC2 中的 MinIO 设置：`medium.com/@jonathanchelmus/creating-an-s3-lab-on-an-ec2-instance-95ffd8ac6c1`

+   关于 S3 的更多信息：[`aws.amazon.com/s3/features/`](https://aws.amazon.com/s3/features/)

+   创建存储桶：[`docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html`](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html)

+   关于 boto3 的更多信息：[`realpython.com/python-boto3-aws-s3/`](https://realpython.com/python-boto3-aws-s3/)
