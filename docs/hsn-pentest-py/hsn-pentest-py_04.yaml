- en: Advanced Python Modules
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级Python模块
- en: 'This chapter will allow us to become familiar with certain advanced Python
    modules that are very handy when it comes to parameters such as response time,
    processing speed, interoperability, and sending data over the network. We will
    be looking at parallel processing in Python with the help of threads and processes.
    We will also read about establishing communication between processes with the
    help of IPC and subprocesses. After that, we will explore socket programming in
    Python and end by entering the domain of cybersecurity by implementing a reverse
    TCP shell. The following topics will be covered in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使我们熟悉一些高级Python模块，当涉及到响应时间、处理速度、互操作性和通过网络发送数据等参数时非常有用。我们将研究如何使用线程和进程在Python中进行并行处理。我们还将了解如何使用IPC和子进程在进程之间建立通信。之后，我们将探讨Python中的套接字编程，并通过实现反向TCP
    shell进入网络安全领域。本章将涵盖以下主题：
- en: Multitasking with threads
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程进行多任务处理
- en: Multitasking with processes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用进程进行多任务处理
- en: Subprocesses
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子进程
- en: The basics of socket programming
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 套接字编程的基础
- en: Implementing a reverse TCP shell with Python
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python实现反向TCP shell
- en: Multitasking with threads
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线程进行多任务处理
- en: A **thread** is a lightweight process that shares the same address and memory
    space as its parent process. It runs in parallel on the processor cores, thereby
    giving us parallelism and multitasking capabilities. The fact that it shares the
    same address and memory space as that of the parent process makes the whole operation
    of multitasking very lightweight, because there is no context switching overhead
    involved. In context switching, when a new process is scheduled to be executed,
    the operating system needs to save the state of the previous process, including
    the process ID, the instruction pointer, the return address, and so on.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**线程**是一个轻量级的进程，与其父进程共享相同的地址和内存空间。它在处理器核心上并行运行，从而为我们提供了并行性和多任务处理能力。它与父进程共享相同的地址和内存空间的事实使得整个多任务处理操作非常轻量级，因为没有涉及上下文切换开销。在上下文切换中，当调度新进程以执行时，操作系统需要保存前一个进程的状态，包括进程ID、指令指针、返回地址等。'
- en: 'This is a time-consuming activity. Since multitasking with threads doesn''t
    involve the creation of new processes to achieve parallelism, threads provide
    a very good performance in multitasking activities. Just as in Java we have the
    `Thread` class or the runnable interface to implement threads, in Python we can
    do this using the `Thread` module to implement threads. There are typically two
    ways to implement threads in Python: one in Java style and one that is more Pythonic.
    Let''s take a look at both.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个耗时的活动。由于使用线程进行多任务处理不涉及创建新进程来实现并行性，线程在多任务处理活动中提供了非常好的性能。就像在Java中我们有`Thread`类或可运行接口来实现线程一样，在Python中我们可以使用`Thread`模块来实现线程。通常有两种在Python中实现线程的方法：一种是Java风格的，另一种更符合Python的风格。让我们一起来看看这两种方法。
- en: 'The following code shows the Java-like implementation, where we subclass the
    threading class and override the `run()` method. We place the logic or task that
    we wish to run in parallel with the threads inside the `run()` method:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了类似于Java的实现，我们在其中对线程类进行子类化并覆盖`run()`方法。我们将希望与线程并行运行的逻辑或任务放在`run()`方法内：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, we have got a method (`run()`), which, in this case, is made to execute
    in parallel. This is what Python explores with its other method of threading,
    in which we can make any method execute in parallel with the help of threads.
    We can use any method of our choice and that method can take any arguments.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有一个方法（`run()`），在这种情况下，它被设计为并行执行。这就是Python探索的另一种线程方法，在这种方法中，我们可以使用线程使任何方法并行执行。我们可以使用我们选择的任何方法，该方法可以接受任何参数。
- en: 'The following code snippet shows the other way of using threading. Here, we
    can see that we defined an `add(num1,num2)` method normally and then used it with
    threads:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了使用线程的另一种方式。在这里，我们可以看到我们通常定义了一个`add(num1,num2)`方法，然后在线程中使用它：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `for` loop creates a thread object `t`. On calling the `start()` method,
    the method specified in the target parameter while creating the thread object
    is invoked. In the preceding case, we have passed the `add()` method to the thread
    instance. The arguments that are to be passed to the method to be invoked with
    threads are passed under the `args` parameter as a tuple. The `add()` method is
    called five times via threads and the output is printed on the screen, as shown
    in the preceding example.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`for`循环创建了一个线程对象`t`。在调用`start()`方法时，会调用在创建线程对象时指定的目标参数中的方法。在前面的例子中，我们将`add()`方法传递给了线程实例。要传递给使用线程调用的方法的参数作为元组传递给`args`参数。`add()`方法通过线程调用了五次，并且输出显示在屏幕上，如前面的例子所示。'
- en: Demonic and non-demonic threads
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恶魔线程和非恶魔线程
- en: 'It must be noted that the thread is invoked from the main program and the main
    program will not exit (by default) until the thread is executed completely. The
    reason is that the main program invokes the thread by default in non-demonic mode,
    which makes the thread run in the foreground rather than wait for it to run in
    the background. Thus, a non-demonic thread is one that runs in the foreground,
    causing the main program to wait for the running threads to finish their execution.
    A demonic thread, on the other hand, is one that runs in the background, therefore
    not causing the main program to wait for it to finish its execution. Take a look
    at the following example:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 必须注意的是，线程是从主程序中调用的，主程序不会退出（默认情况下）直到线程完全执行。原因是主程序默认以非恶魔模式调用线程，这使得线程在前台运行，而不是等待它在后台运行。因此，非恶魔线程是在前台运行的，导致主程序等待运行线程完成执行。另一方面，恶魔线程是在后台运行的，因此不会导致主程序等待其完成执行。请看下面的例子：
- en: '![](img/6e397ca8-b18b-4f3c-8ba6-924d43fa7c65.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6e397ca8-b18b-4f3c-8ba6-924d43fa7c65.png)'
- en: As can be seen from the preceding code snippet, when we create and execute a
    non-demonic thread (default), after printing `Main Ended`, the Terminal window
    halts for 4 seconds, waiting for the `ND` thread to finish its execution. When
    it finishes, we get an  `Exit Non Demonic` message, which is when the main program
    exits. Up until this point, the main program would not exit.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码片段可以看出，当我们创建和执行一个非恶魔线程（默认情况下）时，在打印`Main Ended`后，终端窗口会暂停4秒，等待`ND`线程完成执行。当它完成时，我们会得到一个`Exit
    Non Demonic`的消息，这时主程序退出。在此之前，主程序不会退出。
- en: 'Let''s see how this changes with demonic threads, which run in the background:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这在恶魔线程中如何改变，它在后台运行：
- en: '![](img/1282d560-dbce-4a16-afca-418123f2620f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1282d560-dbce-4a16-afca-418123f2620f.png)'
- en: In the preceding code snippet, we saw how to make use of a demonic thread. Interestingly
    enough, the main program did not wait for the demonic thread to finish execution.
    The demonic thread ran in the background and by the time it finished, the main
    thread had already exited from the memory, and thus we did not see the `Exit :Daemonic` message printed
    on the screen. In this case, we are making use of the logging module. By default,
    the logging module will log to the `stdout`, which, in our case, happens to be
    the Terminal.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '在前面的代码片段中，我们看到了如何使用一个恶魔线程。有趣的是，主程序并没有等待恶魔线程完成执行。恶魔线程在后台运行，当它完成时，主线程已经从内存中退出，因此我们没有在屏幕上看到`Exit:
    Daemonic`的消息。在这种情况下，我们正在使用日志记录模块。默认情况下，日志记录模块将记录到`stdout`，在我们的情况下，这是终端。'
- en: Thread joins and enumeration
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程加入和枚举
- en: As we saw in the previous section, the main thread will, by default, wait until
    the thread is executed. Despite this, the code of the main method will still be
    executed, as the main thread will run on a different processor core to the child
    thread. There may be occasions in which we want to control the execution of the
    main thread, in line with the execution cycle of the child threads. Let's say
    that we want a portion of the code of the main thread to be executed only after
    the child threads are executed. This can be achieved with the help of the `join()`
    method. If we invoke this on a thread T from a main thread M at line X, then the
    line X+1 of the main thread will not be executed until the T thread has finished
    its execution. In other words, we joined the tail of the main thread with the
    thread T, and therefore the execution of the main thread will be halted until
    T is complete. Take a look at the following example, in which we use thread enumeration
    and `join()` to execute threads in batches of three.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中看到的，主线程默认情况下会等待线程执行。尽管如此，主方法的代码仍将被执行，因为主线程将在不同的处理器核心上运行，与子线程不同。有时我们可能希望控制主线程的执行，与子线程的执行周期一致。假设我们希望在子线程执行后仅执行主线程的一部分代码。这可以通过`join()`方法实现。如果我们在主线程M的第X行调用线程T上的`join()`，那么主线程的X+1行将在T线程完成执行之前不会被执行。换句话说，我们将主线程的尾部与线程T连接起来，因此主线程的执行将在T完成之前暂停。让我们看下面的例子，我们在其中使用线程枚举和`join()`来批量执行线程。
- en: 'The main program must validate that all the threads have executed before exiting:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 主程序必须在退出之前验证所有线程是否已执行：
- en: '![](img/d55f6fa9-2ca8-4942-a604-9df8396064a2.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d55f6fa9-2ca8-4942-a604-9df8396064a2.png)'
- en: 'The following screenshot depicts the output of the preceding code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图描述了前面代码的输出：
- en: '![](img/bcdb3300-4256-4c30-8704-458809e8c604.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bcdb3300-4256-4c30-8704-458809e8c604.png)'
- en: Intercommunication between threads
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程之间的互通
- en: Although threads are meant to be executed independently of each other, there
    are many occasions in which threads need to communicate with each other, such
    as if a thread needs to start a task only when another thread has reached a certain
    point. Let's say we are dealing with a producer and consumer problem, where one
    thread (the producer) is responsible for putting items in the queue. The producer
    thread needs to send a message to the consumer thread, so that it knows that it
    can consume data from the queue. This can be achieved with the help of thread
    events in Python. Invoking `threading.event()` returns an event instance, which
    can be set using the `set()` method and reset using the `clear()` method.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管线程应该独立执行，但有许多情况下需要线程之间进行通信，例如如果一个线程需要在另一个线程达到某个特定点时才开始任务。假设我们正在处理生产者和消费者问题，其中一个线程（生产者）负责将项目放入队列。生产者线程需要向消费者线程发送消息，以便它知道可以从队列中消费数据。这可以通过Python中的线程事件来实现。调用`threading.event()`返回一个事件实例，可以使用`set()`方法设置，使用`clear()`方法重置。
- en: 'In the following code block, we will see an example in which one thread will
    be incrementing a counter. The other thread is required to perform an action when
    the counter value reaches 5\. It must be noted that the event also has a `wait()`
    method, which waits until the event is blocked or set. The event can wait for
    a timeout interval, or it can wait indefinitely, but once the set flag is `true`,
    the `wait()` method will not actually block the execution of the thread. This
    is depicted in the following code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们将看到一个示例，其中一个线程将递增一个计数器。另一个线程需要在计数器值达到5时执行一个动作。必须注意，事件还有一个`wait()`方法，它会等待事件被阻塞或设置。事件可以等待一个超时间隔，或者可以无限期等待，但一旦设置标志为`true`，`wait()`方法将不会实际阻塞线程的执行。这在下面的代码中有所体现：
- en: '![](img/1032f145-f810-4804-85e9-895ad8059ce6.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1032f145-f810-4804-85e9-895ad8059ce6.png)'
- en: Thread concurrency control
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程并发控制
- en: 'There are many occasions in which multiple threads need to share a resource.
    We want to ensure that if one thread is changing the state of an object, the other
    must wait. In order to avoid inconsistent results, a shared resource must be locked
    before changing its state. Once the state is changed, the lock should be released.
    Python provides thread locks to do this. Take a look at the following code snippet, `Thread_locking.py`
    , which demonstrates thread locking and concurrency control:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多情况下，多个线程需要共享资源。我们希望确保如果一个线程正在改变对象的状态，另一个线程必须等待。为了避免不一致的结果，在改变其状态之前必须锁定共享资源。状态改变后，应释放锁。Python提供了线程锁来做到这一点。看一下下面的代码片段`Thread_locking.py`，它演示了线程锁定和并发控制：
- en: '![](img/f5d301dc-49fd-4ef6-a601-f7f981c008b7.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f5d301dc-49fd-4ef6-a601-f7f981c008b7.png)'
- en: The preceding code snippet shows thread locking. Here, `count` is a shared variable
    that multiple threads try to update. The first output did not have the locking
    mechanism (lines 16 and 22 were commented out). When there is no locking in place,
    it can be seen that `thread_3` read the value as 1 when it acquired the lock and
    the same is the case with `thread_4`. Each thread increments the value of the
    count by 1, but by the end of `thread_4`, the value of the count is 3. It can
    be seen from the second output obtained when we make use of locking that while
    the shared resource `counter` is being updated, no other thread can actually read
    it, so the results obtained are consistent.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段显示了线程锁定。在这里，`count`是一个多个线程尝试更新的共享变量。第一个输出没有锁定机制（第16行和第22行被注释掉）。当没有锁定时，可以看到`thread_3`在获取锁时将值读为1，`thread_4`也是一样。每个线程将计数的值增加1，但到`thread_4`结束时，计数的值为3。当我们使用锁定时，可以从第二个输出中看到，当共享资源`counter`被更新时，没有其他线程实际上可以读取它，因此获得的结果是一致的。
- en: Multitasking with processes
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用进程进行多任务处理
- en: 'Like the threading module, the multiprocessing module is also used to provide
    multitasking capabilities. The threading module is actually a bit deceptive: its
    implementation in Python is not actually for parallel processing, but instead
    for processing on a single core with time-sharing. The default Python implementation
    **CPython**, at interpreter level, is not thread safe. Whenever threads are used,
    there is a **global interpreter lock** (**GIL**) that is placed over the objects
    that are accessed within Python threads. This lock executes the threads in time-sharing
    manner, giving a small quantity of time to every thread, and thus there is no
    performance gain in our program. The multiprocessing module was developed, therefore,
    to provide parallel processing to the Python ecosystem. This decreases the execution
    time by spawning the load across multiple processor cores. Take a look at the
    following code, which uses multiprocessing:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与线程模块一样，多进程模块也用于提供多任务处理能力。线程模块实际上有点误导：它在Python中的实现实际上不是用于并行处理，而是用于在单个核心上进行时间共享的处理。默认的Python实现**CPython**在解释器级别上不是线程安全的。每当使用线程时，都会在Python线程中访问的对象上放置一个**全局解释器锁**（**GIL**）。这个锁以时间共享的方式执行线程，给每个线程一小部分时间，因此我们的程序中没有性能增益。因此，多进程模块被开发出来，以提供并行处理给Python生态系统。这通过将负载分布到多个处理器核心上来减少执行时间。看一下下面的代码，它使用了多进程：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding code snippet represents two implementations of multiprocessing:
    a simple approach and a class-based approach.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段表示了两种多进程的实现：一种简单的方法和一种基于类的方法。
- en: Demonic and non-demonic processes
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恶魔和非恶魔进程
- en: 'We have already studied what demonic and non-demonic threads are. The same
    principle applies to processes as well. A demonic process runs in the background
    without blocking the main process, while a non-demonic process runs in the foreground.
    This is shown in the following example:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学习了什么是恶魔和非恶魔线程。同样的原则也适用于进程。恶魔进程在后台运行而不阻塞主进程，而非恶魔进程在前台运行。这在下面的示例中显示出来：
- en: '![](img/75c7a70a-38f0-4f46-b35e-17593e3f939a.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75c7a70a-38f0-4f46-b35e-17593e3f939a.png)'
- en: It can be seen from the preceding code snippet that when we create and execute
    a non-demonic process (the default option) as shown in output 1 and in line 20,
    after printing `Main Ended`, the Terminal window halts for 4 seconds while waiting
    for the non-demonic process to finish its execution. When it finishes, we get
    the `Exit Non Daemonic` message, which is when the main program exits. In the
    second case (shown in output 2), the main program does not wait for the demonic
    process to finish its execution. The daemonic process runs in the background and
    by the time it is finished, the main thread has already exited from the memory.
    For this reason, we did not see the `Exit :Daemonic` message printed on the screen.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从前面的代码片段中看到，当我们创建和执行一个非恶魔进程（默认选项）时，如输出1和第20行所示，在打印`Main Ended`后，终端窗口会在等待非恶魔进程完成执行时停顿4秒。当它完成时，我们会得到`Exit
    Non Daemonic`的消息，这时主程序退出。在第二种情况下（如输出2所示），主程序不会等待恶魔进程完成执行。恶魔进程在后台运行，当它完成时，主线程已经从内存中退出。因此，我们没有在屏幕上看到`Exit
    :Daemonic`的消息打印出来。
- en: Process joins, enumeration, and termination
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程连接、枚举和终止
- en: The same theory we saw relating to thread joins and enumeration can be applied
    to processes. The process can be joined to the main thread or to another process
    in such a way that another thread will not exit until the joined process finishes.
    On top of joins and enumeration, we can also explicitly terminate processes in
    Python.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关于线程连接和枚举的相同理论也可以应用于进程。进程可以连接到主线程或另一个进程，以便另一个线程在连接的进程完成之前不会退出。除了连接和枚举之外，我们还可以在Python中显式终止进程。
- en: 'Take a look at following code snippet, which demonstrates the preceding concepts.
    The objective of the following code is to spawn a few processes and make the main
    process wait for 10 seconds for the spawned processes to finish execution. If
    they do not finish, those that are still running will be terminated before exiting:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下代码片段，演示了上述概念。以下代码的目标是生成一些进程，并使主进程等待10秒，以便生成的进程完成执行。如果它们没有完成，那些仍在运行的进程将在退出之前被终止：
- en: '![](img/b26127f3-7bd5-4c9c-a991-e4171692dab8.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b26127f3-7bd5-4c9c-a991-e4171692dab8.png)'
- en: The preceding code `Join_enumerate_terminate.py` is fairly simple; what we are
    doing is identical to what we did with threads previously. The only difference
    here is that we apply the join operation for only 3 seconds, so that we deliberately
    get some processes that are alive. We then kill those processes by applying `terminate()`
    on them.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码`Join_enumerate_terminate.py`非常简单；我们所做的与之前的线程相同。这里唯一的区别是我们仅应用了3秒的加入操作，以便故意获得一些仍在运行的进程。然后我们通过对它们应用`terminate()`来终止这些进程。
- en: Multiprocess pooling
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程池
- en: One of the coolest features of multiprocessing libraries is **pooling**. This
    lets us distribute the tasks evenly across all the processor cores, without having
    to worry about the number of processes that are run actively at one time. This
    implies that this module has the ability to spawn a group of processes in a batch.
    Let's say that we define the batch size as 4, which is the number of processor
    cores we may have. This means that, at any time, the maximum number of processes
    that can be executed is four and if one of the processes completes its execution,
    meaning we now have three running processes, the module automatically picks the
    next set of processes to make the batch size equal to four again. The process
    will continue until we either finish our distributed task or we explicitly define
    a condition.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程库中最酷的功能之一是**池化**。这让我们可以将任务均匀分配到所有处理器核心上，而不必担心同时运行的进程数量。这意味着该模块有能力批量生成一组进程。假设我们将批处理大小定义为4，这是我们可能拥有的处理器核心数量。这意味着，任何时候，可以执行的最大进程数量为四个，如果其中一个进程完成执行，也就是说现在有三个正在运行的进程，模块会自动选择下一组进程，使批处理大小再次等于四。该过程将持续进行，直到我们完成分布式任务或明确定义条件。
- en: 'Take a look at the following example, where we are required to write 8 million
    records in eight different files (1 million records in each file). We have a four-core
    processor to carry out this task. Ideally, we need to spawn a batch of four processes
    twice, so that each process writes 1 million records in the file. Since we have
    four cores, we want each core to carry out a different part of our task. If we
    choose to spawn eight processes together, we would waste some time in context
    switching, so we need to use our processor and processing capabilities wisely
    to get the maximum throughput:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下示例，我们需要在八个不同的文件中写入800万条记录（每个文件中有100万条记录）。我们有一个四核处理器来执行此任务。理想情况下，我们需要两次生成一个批处理大小为四的进程，以便每个进程在文件中写入100万条记录。由于我们有四个核心，我们希望每个核心执行我们任务的不同部分。如果我们选择一次生成八个进程，我们将在上下文切换中浪费一些时间，因此我们需要明智地使用我们的处理器和处理能力，以获得最大的吞吐量：
- en: '![](img/7fc29816-ce6c-46a5-ab31-5a75a7b60de3.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7fc29816-ce6c-46a5-ab31-5a75a7b60de3.png)'
- en: In the preceding code `Multiprocess_pool.py`, we are creating a multiprocessing
    pool at line 30\. We define the size of the pool as `size=mp.cpu_count()`, which
    in our case is `4`, so we are defining a pool of size four. We need to create
    eight files, each holding 1 million records. We use a `for` loop to define eight
    processes that would be sent to the pool object by invoking `apply_async()` on
    the created pool object. The `apply_async()` method expects the name of the method
    that we wish to execute as a process with multiprocessing module as an argument. The
    second argument is the parameters that are passed to the method that we wish to
    execute. Note that the process, when it gets executed with the pool module, also
    has the capability to return data from the method.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码`Multiprocess_pool.py`中，我们在第30行创建了一个多进程池。我们将池的大小定义为`size=mp.cpu_count()`，在我们的情况下是`4`，因此我们定义了一个大小为四的池。我们需要创建八个文件，每个文件包含100万条记录。我们使用`for`循环来定义八个进程，这些进程将通过在创建的池对象上调用`apply_async()`来发送到池对象。`apply_async()`方法期望我们希望使用多进程模块作为参数执行的方法的名称。第二个参数是传递给我们希望执行的方法的参数。请注意，当使用池模块执行进程时，进程还具有从方法返回数据的能力。
- en: As can be seen from the output, at no time are there more than four processes
    being executed simultaneously. It can also be verified that the first process
    to finish is `Forkpoolworker4`. When the batch size is 3, another process is immediately
    spawned by the module. This can be verified by the output, which states `Started
    process Poolworker4` on the sixth line of section (1) .
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看到，没有同时执行的进程超过四个。还可以验证，第一个完成的进程是`Forkpoolworker4`。当批处理大小为3时，模块会立即生成另一个进程。这可以通过输出来验证，输出中在第一部分的第六行中声明了`Started
    process Poolworker4`。
- en: Note that two batches are executed in parallel. Each process took 13 to 14 seconds,
    but since they executed in parallel, one on each core, the overall batch execution
    time for each batch was 14 seconds. For two batches, therefore, the total time
    was 28 seconds. It can be clearly seen that by using parallelism, we solved our
    problem in a mere 28 seconds. If we had gone for a sequential or thread approach,
    the total time would have been close to *(13*8) = 104* seconds. Try it yourself
    as an exercise.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，两个批次是并行执行的。每个进程花费了13到14秒，但由于它们是并行执行的，每个批次的整体执行时间为14秒。因此，两个批次的总时间为28秒。很明显，通过使用并行处理，我们在短短28秒内解决了问题。如果我们选择顺序或线程方法，总时间将接近*(13*8)
    = 104*秒。作为练习，您可以自己尝试。
- en: 'Now let''s take another example, to show another dimension of the power of
    the pool module. Let''s say that as a part of our requirements, we need to parse
    four of the 8 million files that are created, those whose ID `%1700` yields a
    zero. We must then combine the results across all the four files in a different
    file. This is a very good example of distributed processing and aggregation of
    results: the processes should not only read the files in parallel, they must also
    aggregate the results as well. It is somewhat similar to Hadoop''s map-reduce
    problem. In a typical map-reduce problem, there are two sets of operations:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们举另一个例子，展示池模块的另一个强大功能。假设作为我们的要求的一部分，我们需要解析创建的800万个文件中的四个文件，其ID`％1700`的结果为零。然后我们必须将所有四个文件的结果合并到另一个文件中。这是分布式处理和结果聚合的一个很好的例子：这些进程不仅应该并行读取文件，还必须聚合结果。这与Hadoop的映射-减少问题有些类似。在典型的映射-减少问题中，有两组操作：
- en: '**Map**: This involves splitting a huge dataset across various nodes in a distributed
    system. Each node processes the chunk of data it receives.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**映射**：这涉及将一个巨大的数据集分布在分布式系统的各个节点上。每个节点处理它接收到的数据块。'
- en: '**Reduce**: This is the aggregation operation, where the output of the map
    phase from each node is returned, and, depending on the logic, the results are
    finally aggregated and given back.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少**：这是聚合操作，其中来自每个节点的映射阶段的输出被返回，并且根据逻辑，最终聚合并返回结果。'
- en: 'We are doing the same thing here, the only difference being that we are using
    processor cores in place of the nodes:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里做的是相同的事情，唯一的区别是我们使用处理器核心代替节点：
- en: '![](img/ba23f995-6aaf-4f2f-ae31-75806d6206f2.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba23f995-6aaf-4f2f-ae31-75806d6206f2.png)'
- en: As can be seen in the preceding code snippet, with the help of the `map()` method
    of the `Pool` module, we can make multiple processes work on different files in
    parallel and then combine all the results and send them as a single structure.
    The processes are executed in parallel and the records for which the `record_id
    %1700` returned us a zero are returned to us. Finally, we save the aggregated
    result in the `Modulo_1700_agg` file. This is a very powerful feature of the multiprocessing
    module, and can reduce the processing time and aggregation time by huge margin,
    if used properly.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码片段所示，借助`Pool`模块的`map()`方法，我们可以让多个进程并行处理不同的文件，然后将所有结果组合并作为单个结构发送。这些进程是并行执行的，对于`record_id％1700`返回零的记录将被返回。最后，我们将聚合结果保存在`Modulo_1700_agg`文件中。这是多进程模块的一个非常强大的特性，如果使用正确，可以大大减少处理时间和聚合时间。
- en: Subprocesses
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 子进程
- en: 'Invoking an external process from another process is called **subprocessing**.
    In this case, the communication between the processes happens with the help of
    OS pipes. In other words, if a process A is invoked as a subprocess by a process
    B, then the process B can pass an input to it and also read the output from it
    via OS pipes. This module is crucial when it comes to automating penetration testing
    and invoking other tools and utilities with Python. Python provides a very powerful
    module called `subprocess` to handle subprocessing. Take a look at the following
    code snippet `Subprocessing.py`, which shows how to invoke a system command called `ls` using
    subprocessing:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从另一个进程调用外部进程称为**子处理**。在这种情况下，进程之间的通信是通过操作系统管道进行的。换句话说，如果进程A被进程B作为子进程调用，那么进程B可以通过操作系统管道向其传递输入，也可以通过操作系统管道从中读取输出。在自动化渗透测试和使用Python调用其他工具和实用程序时，该模块至关重要。Python提供了一个非常强大的模块，称为`subprocess`来处理子处理。看一下下面的代码片段`Subprocessing.py`，它展示了如何使用子处理来调用一个名为`ls`的系统命令：
- en: '![](img/efe81042-63ce-4ee0-a4ea-6fe512989192.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/efe81042-63ce-4ee0-a4ea-6fe512989192.png)'
- en: In the preceding code snippet, we used the `subprocess.Popen()` method to call
    the `subprocess`. There are few other ways to call or invoke the `subprocess`,
    such as `call()`, but the one we are discussing here is `Popen`. This is because
    the `Popen` method returns the process ID of the process that would be spawned,
    which, in turn, gives us good control over that process. The `Popen` method takes
    many arguments, the first of which is actually the command that is to be executed
    at OS level. The named arguments include `stderr=subprocess.PIPE`, which means
    that if the external program or script produces an error, that error must be redirected
    to the OS pipe, from which the parent process must read the error. The `stdout=subprocess.PIPE`
    suggests that the output that the subprocess would produce must also be sent over
    the pipe to the parent process. `shell=True` suggests that whatever command is
    given, the first argument must be treated as the `shell` command, and if it has
    some arguments, they must be passed as arguments of the process to be invoked.
    Finally, if we want our parent process to read the output and error produced by
    the child process, we must call the `communicate()` method on the invoked `subprocess`.
    The `communicate()` method opens the `subprocess` pipe and the communication starts
    with the subprocess writing to one end of the pipe and the parent process reading
    from the other. It must be noted that the `communicate()` method will make the
    parent process wait until the child process is finished. The method returns a
    tuple with the output at the 0th index and the std error at the 1st index.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们使用了`subprocess.Popen()`方法来调用`subprocess`。还有一些其他调用或调用`subprocess`的方法，比如`call()`，但我们在这里讨论的是`Popen`。这是因为`Popen`方法返回将要生成的进程的进程ID，从而使我们对该进程有很好的控制。`Popen`方法接受许多参数，其中第一个实际上是要在操作系统级别执行的命令。命名参数包括`stderr=subprocess.PIPE`，这意味着如果外部程序或脚本产生错误，该错误必须重定向到操作系统管道，父进程必须从中读取错误。`stdout=subprocess.PIPE`表示子进程产生的输出也必须发送到管道到父进程。`shell=True`表示无论给出什么命令，第一个参数都必须被视为`shell`命令，如果有一些参数，它们必须作为要调用的进程的参数传递。最后，如果我们希望父进程读取子进程产生的输出和错误，我们必须在调用的`subprocess`上调用`communicate()`方法。`communicate()`方法打开`subprocess`管道，通信从子进程向管道的一端写入开始，父进程从另一端读取。必须注意`communicate()`方法将使父进程等待子进程完成。该方法返回一个元组，其中0号索引处是输出，1号索引处是标准错误。
- en: 'It should be noted that we should never use `shell=True` in real-world examples,
    as this makes an application vulnerable to shell injection. Avoid using the following
    line:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，我们在现实世界的示例中不应该使用`shell=True`，因为这会使应用程序容易受到shell注入的攻击。避免使用以下行：
- en: '`>>> subprocess.Popen(command, shell=True) #This would remove everything !!`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`>>> subprocess.Popen(command, shell=True) #这将删除所有内容！！`'
- en: 'Take a look at the following example, in which we will use `shell=False`. With
    `shell=False`, the command and  arguments to the process/command that we invoke
    must be passed separately as a list. Let''s try to execute `ls -l`  with `shell=False`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下示例，我们将使用`shell=False`。使用`shell=False`，我们调用的进程/命令的命令和参数必须作为列表分开传递。让我们尝试使用`shell=False`执行`ls
    -l`：
- en: '![](img/2b25936f-6483-4e7e-b78d-28918afffe3b.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b25936f-6483-4e7e-b78d-28918afffe3b.png)'
- en: So this is how we execute external processes with Python, with the help of the
    subprocess module.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们如何使用Python执行外部进程的方式，借助于subprocess模块。
- en: Socket programming basics
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 套接字编程基础
- en: When we talk of sockets, we are referring to both the TCP and the UDP socket.
    A **socket** connection is nothing but a combination of the IP address and the
    port number. Every service that we can think of that runs on a port implements
    and uses sockets internally.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论套接字时，我们指的是TCP套接字和UDP套接字。**套接字**连接只是IP地址和端口号的组合。我们可以想到的每个在端口上运行的服务都在内部实现和使用套接字。
- en: 'For example, our web server, which always listens on port `80` (by default),
    opens a socket connection to the outside world and binds to the socket with the
    IP address and the port `80`. The socket connection can be used in the following
    two modes:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们的Web服务器总是在端口`80`（默认情况下）上监听，它打开一个套接字连接到外部世界，并绑定到具有IP地址和端口`80`的套接字。套接字连接可以以以下两种模式使用：
- en: Server
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器
- en: Client
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端
- en: 'When the socket is used as a server, the sequence of steps that the server
    performs is as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当套接字用作服务器时，服务器执行的步骤顺序如下：
- en: Create a socket.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个套接字。
- en: Bind to the socket.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绑定到套接字。
- en: Listen at the socket.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在套接字上监听。
- en: Accept connections.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接受连接。
- en: Receive and send data.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接收和发送数据。
- en: 'On the other hand, when the socket connection is used as a client to connect
    to a server socket, the sequence of steps is as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，当套接字连接用作客户端连接到服务器套接字时，步骤顺序如下：
- en: Create a socket.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个套接字。
- en: Connect to the socket.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接到套接字。
- en: Receive and send data.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接收和发送数据。
- en: 'Take a look at the following code snippet `server_socket.py`, which implements
    a TCP server socket at port `80`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下代码片段`server_socket.py`，它在端口`80`实现了一个TCP服务器套接字：
- en: '![](img/c22814d3-51d0-4002-90b1-323f1a762121.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c22814d3-51d0-4002-90b1-323f1a762121.png)'
- en: In the preceding case, we created a socket with the `socket.socket` statement.
    Here, `socket.AF_INET` represents the IPv4 protocol and `socket.SOCK_STREAM` suggests
    the use of stream-based socket packets, which are nothing but TCP streams. The
    `bind()` method takes a tuple as an argument, with the first argument being the
    local IP address. You should replace this with your personal IP, or `127.0.0.1`.
    The second parameter that is given to tuple is the port, which in turn calls the
    `bind()` method. We then start listening on the socket and finally start a loop
    where we accept client connections. Note that the method creates a single-threaded
    server, which means that if any other client connects, it has to wait until the
    active client is disconnected. The `send ()` and `recv()` methods are self-explanatory.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的案例中，我们使用`socket.socket`语句创建了一个套接字。在这里，`socket.AF_INET`表示IPv4协议，`socket.SOCK_STREAM`表示使用基于流的套接字数据包，这些数据包仅是TCP流。`bind()`方法以元组作为参数，第一个参数是本地IP地址。您应该将其替换为您的个人IP，或`127.0.0.1`。传递给元组的第二个参数是端口，然后调用`bind()`方法。然后我们开始监听套接字，最后开始一个循环，我们接受客户端连接。请注意，该方法创建了一个单线程服务器，这意味着如果任何其他客户端连接，它必须等到活动客户端断开连接。`send()`和`recv()`方法是不言自明的。
- en: 'Let''s now create a basic client socket code ,`client_socket.py`, that connects
    to the previously created servers and passes messages to it:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个基本的客户端套接字代码`client_socket.py`，连接到之前创建的服务器并向其传递消息：
- en: '![](img/8a85859c-469a-48c9-a9ea-bfa613bc246f.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a85859c-469a-48c9-a9ea-bfa613bc246f.png)'
- en: 'The output produced by both the client and server sockets is as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端和服务器套接字产生的输出如下：
- en: '![](img/4f357662-4615-410d-8204-25603f3bd866.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f357662-4615-410d-8204-25603f3bd866.png)'
- en: 'This is how we use a socket connection with UDP:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们如何使用UDP进行套接字连接的方式：
- en: '[PRE3]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Reverse TCP shells with Python
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python进行反向TCP shell
- en: 'Now that we have understood the basics of subprocessing, multiprocessing, and
    so on, implementing a basic TCP reverse shell with Python is pretty straightforward.
    For this example, `rev_tcp.py`, we will be using the bash-based reverse TCP shell.
    In the later chapters of the book, we will see how to pass a reverse shell entirely
    with Python:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了子进程、多进程等基础知识，使用Python实现基本的TCP反向shell非常简单。在这个例子`rev_tcp.py`中，我们将使用基于bash的反向TCP
    shell。在本书的后面章节中，我们将看到如何完全使用Python传递反向shell：
- en: '![](img/91cc6614-9d64-417f-b396-ff81b57f0271.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/91cc6614-9d64-417f-b396-ff81b57f0271.png)'
- en: It should be noted that `OS.dup2` is used to create a duplicate of a file descriptor
    in Python. The `stdin` is defined to be file descriptor `0`, `stdout` is defined
    to be file descriptor `1`, and `stderr` is defined to be file descriptor `2`.
    The code line `OS.dup2(s.fileno(),0)` indicates that we should create a duplicate
    of `stdin` and redirect the traffic to the socket file, which happens to be on
    the localhost and port `1234` (where Netcat is listening). Finally, we invoke
    the shell in interactive mode and since we are not specifying the `stderr`, `stdin`
    and `stdout` parameters, by default, the parameters will be sent to `stdin` and
    `stdout` at system level, which is again mapped to the socket for the scope of
    the program. For this reason, the preceding code snippet will open the shell in
    interactive mode and pass it on to the socket. All input is taken from the socket
    as `stdin`, and all output is passed to the socket via `stdout`. This can be validated
    by looking at the output produced.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，`OS.dup2`用于在Python中创建文件描述符的副本。`stdin`被定义为文件描述符`0`，`stdout`被定义为文件描述符`1`，`stderr`被定义为文件描述符`2`。代码行`OS.dup2(s.fileno(),0)`表示我们应该创建`stdin`的副本并将流量重定向到套接字文件，该套接字文件恰好位于本地主机和端口`1234`（Netcat正在监听的地方）。最后，我们以交互模式调用shell，由于我们没有指定`stderr`、`stdin`和`stdout`参数，默认情况下，这些参数将被发送到系统级的`stdin`和`stdout`，再次映射到程序的范围内的套接字。因此，前面的代码片段将以交互模式打开shell，并将其传递给套接字。所有输入都从套接字作为`stdin`接收，所有输出都通过`stdout`传递到套接字。可以通过查看生成的输出来验证这一点。
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed some more advanced concepts of Python, which allow
    us to increase the throughput. We discussed multiprocessing Python modules and
    how they can be used to reduce the time taken and increase our processing capabilities.
    With this chapter, we have essentially covered everything that we would need from
    Python for us to step into the world of penetration testing, automation, and various
    cybersecurity use cases. It should be noted that, from here on, our emphasis will
    be on applying the concepts we have studied so far, with less explanation as to
    how they work. For this reason, if you have any doubts, I would strongly recommend
    that you clarify these before moving ahead. In the next chapter, we will talk
    about how can we use Python to parse PCAP files, automate Nmap scanning, and much
    more. For all security enthusiasts, let's get to business.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了一些更高级的Python概念，这些概念可以帮助我们增加吞吐量。我们讨论了多进程Python模块以及它们如何用于减少所需时间并增加我们的处理能力。通过本章，我们基本上涵盖了我们进入渗透测试、自动化和各种网络安全用例所需的Python的一切。需要注意的是，从现在开始，我们的重点将是应用我们到目前为止所学的概念，而不是解释它们的工作原理。因此，如果您有任何疑问，我强烈建议您在继续之前澄清这些疑问。在下一章中，我们将讨论如何使用Python解析PCAP文件，自动化Nmap扫描等等。对于所有的安全爱好者，让我们开始吧。
- en: Questions
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are other multiprocessing libraries that we can use with Python?
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用Python的其他多进程库吗？
- en: Where would threads become useful in Python, given that they actually execute
    on the same core?
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Python中，线程在哪些情况下会变得有用，考虑到它们实际上在同一个核心上执行？
- en: Further reading
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Multiprocessing: [https://docs.python.org/2/library/multiprocessing.html](https://docs.python.org/2/library/multiprocessing.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多进程：[https://docs.python.org/2/library/multiprocessing.html](https://docs.python.org/2/library/multiprocessing.html)
- en: 'Subprocesses: [https://docs.python.org/2/library/subprocess.html](https://docs.python.org/2/library/subprocess.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子进程：[https://docs.python.org/2/library/subprocess.html](https://docs.python.org/2/library/subprocess.html)
