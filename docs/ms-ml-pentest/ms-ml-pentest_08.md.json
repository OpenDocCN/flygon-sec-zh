["```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\n```", "```py\nnp.random.seed(0)\nn_samples = 30\ndegrees = [1, 4, 15]\nX = np.sort(np.random.rand(n_samples))\ny = np.cos(1.5 * np.pi * X) + np.random.randn(n_samples) * 0.1\nplt.figure(figsize=(14, 5))\n\nfor i in range(len(degrees)):\n ax = plt.subplot(1, len(degrees), i + 1)\n plt.setp(ax, xticks=(), yticks=())\n\n polynomial_features = PolynomialFeatures(degree=degrees[i],\n include_bias=False)\n linear_regression = LinearRegression()\n pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n (\"linear_regression\", linear_regression)])\n pipeline.fit(X[:, np.newaxis], y)\n\n # Evaluate the models using crossvalidation\n scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n scoring=\"neg_mean_squared_error\", cv=10)\n\n X_test = np.linspace(0, 1, 100)\n plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n plt.plot(X_test, true_fun(X_test), label=\"True function\")\n plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n plt.xlabel(\"x\")\n plt.ylabel(\"y\")\n plt.xlim((0, 1))\n plt.ylim((-2, 2))\n plt.legend(loc=\"best\")\n plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n degrees[i], -scores.mean(), scores.std()))\nplt.show()\n```", "```py\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout\nfrom keras.optimizers import RMSprop , adam\nfrom cleverhans.attacks import fgsm , jsma\nfrom cleverhans.utils_tf import model_train , model_eval , batch_eval\nfrom cleverhans.attacks_tf import jacobian_graph\nfrom cleverhans.utils import other_classes\nimport tensorflow as tf\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score , roc_curve , auc , f1_score\nfrom sklearn.preprocessing import LabelEncoder , MinMaxScaler\nimport matplotlib.pyplot as plt\n```", "```py\nnames = ['duration', 'protocol', 'service ', 'flag', 'src_bytes', 'dst_bytes', 'land',\n'wrong_fragment ','urgent ', 'hot', 'num_failed_logins ', 'logged_in ', 'num_compromised ', 'root_shell ', 'su_attempted ','num_root ', 'num_file_creations ', 'num_shells ', 'num_access_files ', 'num_outbound_cmds ','is_host_login ', 'is_guest_login ', 'count', 'srv_count ', 'serror_rate', 'srv_serror_rate ','rerror_rate ', 'srv_rerror_rate ', 'same_srv_rate ', 'diff_srv_rate', 'srv_diff_host_rate ','dst_host_count ', 'dst_host_srv_count ', 'dst_host_same_srv_rate ', 'dst_host_diff_srv_rate ','dst_host_same_src_port_rate ', 'dst_host_srv_diff_host_rate ', 'dst_host_serror_rate ','dst_host_srv_serror_rate ','dst_host_rerror_rate ', 'dst_host_srv_rerror_rate ','attack_type ', 'other ']\n```", "```py\nTrainingData = pd.read_csv('KDDTrain+.txt', names=names , header=None)\nTestingData = pd.read_csv('KDDTest+.txt', names=names , header=None)\n```", "```py\nAll = pd.concat ([TrainingData, TestingData])\nassert full.shape[0] == TrainingData.shape[0] + TestingData.shape[0]\n```", "```py\nAll['label'] = full['attack_type']\n```", "```py\nAll.loc[All.label == 'neptune ', 'label'] = 'dos'\nAll.loc[All.label == 'back', 'label '] = 'dos'\nAll.loc[All.label == 'land', 'label '] = 'dos'\nAll.loc[All.label == 'pod', 'label'] = 'dos'\nAll.loc[All.label == 'smurf ', 'label'] = 'dos'\nAll.loc[All.label == 'teardrop ', 'label '] = 'dos'\nAll.loc[All.label == 'mailbomb ', 'label '] = 'dos'\nAll.loc[All.label == 'processtable ', 'label'] = 'dos'\nAll.loc[All.label == 'udpstorm ', 'label '] = 'dos'\nAll.loc[All.label == 'apache2 ', 'label'] = 'dos'\nAll.loc[All.label == 'worm', 'label '] = 'dos'\n```", "```py\nfull = pd.get_dummies(All , drop_first=False)\n```", "```py\nfeatures = list(full.columns [:-5])\ny_train = np.array(full[0:TrainingData.shape[0]][[ 'label_normal ', 'label_dos ', 'label_probe\nlabel_r2l ', 'label_u2r ']])\nX_train = full[0:TrainingData.shape[0]][ features]\ny_test = np.array(full[TrainingData.shape[0]:][[ 'label_normal ', 'label_dos ', 'label_probe ', '\nlabel_r2l ', 'label_u2r ']])\nX_test = full[TrainingData.shape[0]:][features]\n```", "```py\nscaler = MinMaxScaler().fit(X_train)\n```", "```py\nX_train_scaled = np.array(scaler.transform(X_train))\n```", "```py\nlabels = All.label.unique()\nEn = LabelEncoder()\nEn.fit(labels)\ny_All = En.transform(All.label)\ny_train_l = y_All[0:TrainingData.shape[0]]\ny_test_l = y_All[TrainingData.shape[0]:]\n```", "```py\nresults = np.zeros((FLAGS.nb_classes , source_samples), dtype='i')\nperturbations = np.zeros((FLAGS.nb_classes , source_samples), dtype='f')\ngrads = jacobian_graph(predictions , x, FLAGS.nb_classes)\nX_adv = np.zeros(( source_samples , X_test_scaled.shape [1]))\nfor sample_ind in range(0, source_samples):\ncurrent_class = int(np.argmax(y_test[sample_ind ]))\nfor target in [0]:\nif current_class == 0:\nBreak\nadv_x , res , percent_perturb = jsma(sess , x, predictions , grads,X_test_scaled[sample_ind: (sample_ind+1)],target , theta=1, gamma =0.1,increase=True , back='tf',clip_min=0, clip_max =1)\nX_adv[sample_ind] = adv_x\nresults[target , sample_ind] = res\nperturbations[target , sample_ind] = percent_perturb\n```", "```py\ndef mlp_model ():\n    Generate a MultiLayer Perceptron model\n    model = Sequential ()\n    model.add(Dense (256, activation='relu', input_shape =( X_train_scaled.shape [1],)))\n    model.add(Dropout (0.4))\n    model.add(Dense (256, activation='relu'))\n    model.add(Dropout (0.4))\n    model.add(Dense(FLAGS.nb_classes , activation='softmax '))model.compile(loss='categorical_crossentropy ',optimizer='adam',metrics =['accuracy '])\n    model.summary ()\n    return model\n```", "```py\ny_pred_adv = dt.predict(X_adv)\nfpr_dt_adv , tpr_dt_adv , _ = roc_curve(y_test[:, 0], y_pred_adv [:, 0])\nroc_auc_dt_adv = auc(fpr_dt_adv , tpr_dt_adv)\nprint(\"Accuracy score adversarial:\", accuracy_score(y_test , y_pred_adv))\nprint(\"F1 score adversarial:\", f1_score(y_test , y_pred_adv , average='micro '))\nprint(\"AUC score adversarial:\", roc_auc_dt_adv)\n```"]