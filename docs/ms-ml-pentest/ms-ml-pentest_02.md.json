["```py\n>>> import numpy as np\n>>> from sklearn import *\n>>> from sklearn.linear_model import LogisticRegression\n>>> from sklearn.metrics import accuracy_score\n```", "```py\ntraining_data = np.genfromtxt('dataset.csv', delimiter=',', dtype=np.int32)\n```", "```py\n>>> inputs = training_data[:,:-1]\n>>> outputs = training_data[:, -1]\n```", "```py\ntraining_inputs = inputs[:2000]\ntraining_outputs = outputs[:2000] \ntesting_inputs = inputs[2000:]\ntesting_outputs = outputs[2000:]\n```", "```py\nclassifier = LogisticRegression()\n```", "```py\nclassifier.fit(training_inputs, training_outputs)\n```", "```py\npredictions = classifier.predict(testing_inputs)\n```", "```py\naccuracy = 100.0 * accuracy_score(testing_outputs, predictions) \nprint (\"The accuracy of your Logistic Regression on testing data is: \" + str(accuracy))\n```", "```py\n>>> from sklearn import tree\n```", "```py\nclassifier = tree.DecisionTreeClassifier()\n```", "```py\nclassifier.fit(training_inputs, training_outputs)\n```", "```py\npredictions = classifier.predict(testing_inputs)\n```", "```py\naccuracy = 100.0 * accuracy_score(testing_outputs, predictions)\n```", "```py\nprint (\"The accuracy of your decision tree on testing data is: \" + str(accuracy))\n```", "```py\n>>> import nltk\n```", "```py\n>>> nltk.download()\n```", "```py\n>> from nltk.book import *\n```", "```py\n>>> from urllib import urlopen\n>>> url = \"http://www.URL_HERE/file.txt\"\n```", "```py\n>>> tokens = nltk.word_tokenize(raw)\n>>> len(tokens)\n> tokens[:10]\n```", "```py\n>>> import nltk\n```", "```py\nimport os\nimport random\n#initiate a list called emails_list\nemails_list = []\nDirectory = '/home/azureuser/spam_filter/enron1/emails/'\nDir_list  = os.listdir(Directory)\nfor file in Dir_list:\n    f = open(Directory + file, 'r')\n    emails_list.append(f.read())\nf.close()\n```", "```py\n>> from nltk import word_tokenize\n```", "```py\n>>> from nltk import WordNetLemmatizer\n```", "```py\n>>> [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(unicode(sentence, errors='ignore'))]\n```", "```py\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n```", "```py\ndef Process(data):\n lemmatizer = WordNetLemmatizer()\n return [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(unicode(sentence,   errors='ignore'))]\n```", "```py\nfrom collections import Counter\ndef Features_Extraction(text, setting):\n if setting=='bow':\n# Bow means  bag-of-words\n return {word: count for word, count in Counter(Process(text)).items() if not word in stop}\n else:\n return {word: True for word in Process(text) if not word in stop}\n```", "```py\nfeatures = [(Features_Extraction(email, 'bow'), label) for (email, label) in emails]\n```", "```py\ndef training_Model (Features, samples):\n Size = int(len(Features) * samples)\n training , testing = Features[:Size], Features[Size:]\n print ('Training = ' + str(len(training)) + ' emails')\n print ('Testing = ' + str(len(testing)) + ' emails')\n```", "```py\nfrom nltk import NaiveBayesClassifier, classify\nclassifier = NaiveBayesClassifier.train(training)\n```", "```py\ndef evaluate(training, tesing, classifier):\n print ('Training Accuracy is ' + str(classify.accuracy(classifier, train_set)))\n print ('Testing Accuracy i ' + str(classify.accuracy(classifier, test_set)))\n```"]