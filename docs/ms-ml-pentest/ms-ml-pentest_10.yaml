- en: Best Practices for Machine Learning and Feature Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习和特征工程的最佳实践
- en: In the previous chapters, we learned about the fundamentals of machine learning,
    and we learned how to build many different Python projects by using a suite of
    amazing open source Python libraries. Also, we dove into how to break machine
    learning models.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们学习了机器学习的基础知识，并学习了如何使用一套令人惊叹的开源Python库构建许多不同的Python项目。此外，我们深入研究了如何打破机器学习模型。
- en: This last chapter will help you to build better models by illustrating many
    tips and best practices for different aspects of your projects.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将通过说明项目各个方面的许多技巧和最佳实践，帮助您构建更好的模型。
- en: 'In this chapter, we will cover the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: An in-depth overview of feature engineering in machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中特征工程的深入概述
- en: The best practices for machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的最佳实践
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can find the code files for this chapter at [https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter10](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter10).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此章节的代码文件中找到此代码：[https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter10](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter10)。
- en: Feature engineering in machine learning
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的特征工程
- en: Through building and developing all of the projects and prototypes in this book,
    you have certainly noticed that feature engineering and feature selection are
    essential to every modern data science product, especially machine learning based
    projects. According to research, over 50% of the time spent building the model
    is occupied by cleaning, processing, and selecting the data required to train
    the model. It is your responsibility to design, represent, and select the features.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在本书中构建和开发所有项目和原型，您肯定已经注意到特征工程和特征选择对于每个现代数据科学产品，特别是基于机器学习的项目至关重要。根据研究，构建模型所花费的时间中，超过50%的时间用于清理、处理和选择训练模型所需的数据。您有责任设计、表示和选择特征。
- en: 'Most machine learning algorithms cannot work on raw data. They are not smart
    enough to do so. Thus, feature engineering is needed, to transform data in its
    raw status into data that can be understood and consumed by algorithms. Professor
    Andrew Ng once said:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习算法无法处理原始数据。它们不够聪明。因此，需要特征工程，将原始状态的数据转换为算法可以理解和消化的数据。安德鲁·吴教授曾经说过：
- en: '"Coming up with features is difficult, time-consuming, requires expert knowledge.
    ''Applied machine learning'' is basically feature engineering."'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: “构建特征是困难的，耗时的，需要专业知识。‘应用机器学习’基本上就是特征工程。”
- en: 'Feature engineering is a process in the data preparation phase, according to
    the cross-industry standard process for data mining:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程是数据准备阶段的一个过程，根据数据挖掘的跨行业标准流程：
- en: '![](img/00220.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00220.jpeg)'
- en: 'The term **Feature Engineering** itself is not a formally defined term. It
    groups together all of the tasks for designing features to build intelligent systems.
    It plays an important role in the system. If you check data science competitions,
    I bet you have noticed that the competitors all use the same algorithms, but the
    winners perform the best feature engineering. If you want to enhance your data
    science and machine learning skills, I highly recommend that you visit and compete
    at [www.kaggle.com](http://www.kaggle.com):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: “特征工程”本身并没有正式定义的术语。它将所有设计特征以构建智能系统的任务组合在一起。它在系统中扮演着重要的角色。如果您参加数据科学竞赛，我敢打赌您已经注意到，竞争者们都使用相同的算法，但获胜者表现最佳的是特征工程。如果您想提高数据科学和机器学习技能，我强烈建议您访问并参加[www.kaggle.com](http://www.kaggle.com)：
- en: '![](img/00221.jpeg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00221.jpeg)'
- en: When searching for machine learning resources, you will face many different
    terminologies. To avoid any confusion, we need to distinguish between feature
    selection and feature engineering. Feature engineering transforms raw data into
    suitable features, while feature selection extracts necessary features from the
    engineered data. Featuring engineering is selecting the subset of all features,
    without including redundant or irrelevant features.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在搜索机器学习资源时，您将面临许多不同的术语。为了避免混淆，我们需要区分特征选择和特征工程。特征工程将原始数据转换为合适的特征，而特征选择从工程化的数据中提取必要的特征。特征工程是选择所有特征的子集，而不包括冗余或无关的特征。
- en: Feature selection algorithms
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择算法
- en: 'To enable the algorithms to train faster, and to reduce the complexity and
    overfitting of the model, in addition to improving its accuracy, you can use many
    feature selection algorithms and techniques. We are going to look at three different
    feature selection methods: filter methods, wrapper methods, and embedded methods.
    Let''s discuss the various methodologies and techniques.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使算法能够更快地训练，并减少模型的复杂性和过拟合，除了提高准确性之外，您可以使用许多特征选择算法和技术。我们将看一下三种不同的特征选择方法：过滤方法、包装方法和嵌入方法。让我们讨论各种方法和技术。
- en: Filter methods
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过滤方法
- en: 'In filter methods, each feature will be assigned a score, computed by different
    statistical measures. In other words, these methods rank features by considering
    the relationships between the features and the targets. Filter methods are usually
    used in the pre-processing phase:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在过滤方法中，每个特征将被分配一个分数，由不同的统计量计算得出。换句话说，这些方法通过考虑特征与目标之间的关系来对特征进行排名。过滤方法通常用于预处理阶段：
- en: '![](img/00222.jpeg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00222.jpeg)'
- en: Pearson's correlation
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数
- en: 'Pearson''s correlation is a statistical method used to measure the linear correlation
    between two variables, `x` and `y`. It is ranged between `+1` and `-1` ; `+1`
    means that there is a positive association. You need to know that `x` and `y`
    should be continuous variables. The formula for Pearson''s correlation coefficient
    is as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Pearson相关是一种用于测量两个变量`x`和`y`之间线性相关的统计方法。它的范围在`+1`和`-1`之间；`+1`表示有正相关。你需要知道`x`和`y`应该是连续变量。Pearson相关系数的公式如下：
- en: '![](img/00223.jpeg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00223.jpeg)
- en: '*Cov* is the **covariance,** and `dx` and `dy` are the standard deviations
    of `x` and `y`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*Cov*是**协方差**，`dx`和`dy`是`x`和`y`的标准差：'
- en: '![](img/00224.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00224.jpeg)
- en: To calculate this using Python, you can use `scipy.stats.pearsonr(x, y)`, from
    the `scipy` library.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Python计算这个，你可以使用`scipy.stats.pearsonr(x, y)`，来自`scipy`库。
- en: Linear discriminant analysis
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性判别分析
- en: 'In previous chapters, especially in [Chapter 1](part0021.html#K0RQ0-49a67f1d6e7843d3b2296f38e3fe05f5),
    *Introduction to Machine Learning in Pen Testing*, we saw the statistical procedure
    of **principal component analysis** (**PCA**). **Linear discriminant analysis**
    (**LDA**) is a dimensionality reduction technique, as well. It is used to find
    a linear combination of features that separate classes:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在以前的章节中，特别是在[第1章](part0021.html#K0RQ0-49a67f1d6e7843d3b2296f38e3fe05f5)，*渗透测试中的机器学习简介*中，我们看到了**主成分分析**（**PCA**）的统计程序。**线性判别分析**（**LDA**）也是一种降维技术。它用于找到将类别分开的特征的线性组合：
- en: '![](img/00225.jpeg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00225.jpeg)
- en: 'To use LDA with scikit-learn, import it with this line:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要在scikit-learn中使用LDA，请使用以下行导入：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Use it as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用方法如下：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Analysis of variance
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方差分析
- en: '**Analysis of variance** (**ANOVA**) is like LDA, but it operates using categorical
    features to check whether the means of several classes are equal, by analyzing
    the differences between them.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**方差分析**（**ANOVA**）类似于LDA，但它使用分类特征来检查几个类的均值是否相等，通过分析它们之间的差异。'
- en: Chi-square
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卡方
- en: '**Chi-square** is used to determine if a subset data matches a population.
    The values should be in categories. In other words, the chi-square test is used
    to check the correlations and associations between the different categories or
    classes.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**卡方**用于确定子集数据是否与总体相匹配。值应该是在类别中。换句话说，卡方检验用于检查不同类别或类别之间的相关性和关联。'
- en: 'The formula for the chi-square test is as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 卡方检验的公式如下：
- en: '![](img/00226.jpeg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00226.jpeg)
- en: 'The following is an example of chi-square using scikit-learn, delivered by
    Jason Brownlee, PhD:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用scikit-learn的卡方的示例，由Jason Brownlee，博士提供：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following diagram illustrates the preceding code:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了前面的代码：
- en: '![](img/00227.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00227.jpeg)
- en: Wrapper methods
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 包装方法
- en: 'Wrapper methods are performed by taking subsets and training learning algorithms.
    Based on the results of the training, we can select the best features for our
    model. And, as you may have guessed, these methods are computationally very expensive:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 包装方法是通过取子集和训练学习算法来执行的。根据训练的结果，我们可以选择我们模型的最佳特征。而且，你可能已经猜到，这些方法在计算上非常昂贵：
- en: '![](img/00228.jpeg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00228.jpeg)
- en: There are many wrapper techniques, including those listed in the following sections.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多包装技术，包括以下部分中列出的技术。
- en: Forward selection
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前向选择
- en: 'Forward selection uses searching as a technique for selecting the best features.
    It is an iterative method. In every iteration, we add more features to improve
    the model, until we no longer have any further improvements to make:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 前向选择使用搜索作为选择最佳特征的技术。这是一种迭代方法。在每次迭代中，我们添加更多特征以改进模型，直到我们没有进一步的改进为止：
- en: '![](img/00229.jpeg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00229.jpeg)
- en: Backward elimination
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向后消除
- en: 'Backward elimination is like the previous method but, this time, we start with
    all of the features, and we eliminate some in every iteration until the model
    stops improving:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 向后消除与前一种方法类似，但是这次我们从所有特征开始，并且在每次迭代中消除一些特征，直到模型停止改进：
- en: '![](img/00230.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00230.jpeg)
- en: Recursive feature elimination
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归特征消除
- en: You can see that recursive feature elimination as a greedy optimization algorithm.
    This technique is performed by creating models with different subsets and computing
    the best performing feature, scoring them according to an elimination ranking.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到递归特征消除作为一种贪婪的优化算法。这种技术是通过创建具有不同子集的模型并计算最佳执行特征来执行的，根据消除排名对它们进行评分。
- en: 'This script is like the previous one, but it uses recursive feature elimination
    as a feature selection method:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本与前一个类似，但它使用递归特征消除作为特征选择方法：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following diagram illustrates the preceding code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了前面的代码：
- en: '![](img/00231.gif)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00231.gif)
- en: Embedded methods
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入方法
- en: 'The main goal of feature selection''s embedded method is learning which features
    are the best in contributing to the accuracy of the machine learning model. They
    have built-in penalization functions to reduce overfitting:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择嵌入方法的主要目标是学习哪些特征对机器学习模型的准确性贡献最大。它们具有内置的惩罚函数以减少过拟合：
- en: '![](img/00232.jpeg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00232.jpeg)
- en: Some of the embedded techniques are listed in the following sections.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一些嵌入技术列在以下部分。
- en: Lasso linear regression L1
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lasso线性回归L1
- en: 'In statistics, Lasso is a regression analysis method. Lasso linear regression
    L1 simply adds a penalty equivalent to the absolute value of the magnitude of
    coefficients. The following is an implementation of the method in Python and sckit-learn:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，Lasso是一种回归分析方法。Lasso线性回归L1简单地增加了一个与系数大小的绝对值等价的惩罚。以下是Python和sckit-learn中该方法的实现：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](img/00233.jpeg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/00233.jpeg)
- en: Ridge regression L2
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 岭回归L2
- en: The ridge regression L2 method adds a penalty equivalent to the square of the
    magnitude of coefficients. In other words, it performs an L2 regularization.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归L2方法增加了一个与系数大小的平方等价的惩罚。换句话说，它执行L2正则化。
- en: Tree-based feature selection
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于树的特征选择
- en: 'The tree-based feature selection method is used to check and compute feature
    importance. The following is an example of how we can use the tree-based feature
    selection technique delivered by the official scikit-learn documentation:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 基于树的特征选择方法用于检查和计算特征的重要性。以下是一个示例，展示了如何使用scikit-learn官方文档提供的基于树的特征选择技术：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](img/00234.jpeg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00234.jpeg)'
- en: 'As I said previously, feature selection is used in the pre-processing phase,
    so you can use scikit-learn to build a pipeline, as in the following example:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前所说，特征选择是在预处理阶段使用的，因此您可以使用scikit-learn来构建一个流水线，就像以下示例中的那样：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A great book called *An Introduction to Variable and Feature Selection,* written
    by Isabelle Guyon and Andre Elisseeff, includes a checklist for better feature
    selection.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一本名为*An Introduction to Variable and Feature Selection*的好书，作者是Isabelle Guyon和Andre
    Elisseeff，其中包括了一个更好的特征选择清单。
- en: To learn more about the full checklist, you can browse to [https://machinelearningmastery.com/an-introduction-to-feature-selection/](https://machinelearningmastery.com/an-introduction-to-feature-selection/).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多有关完整清单的信息，您可以浏览[https://machinelearningmastery.com/an-introduction-to-feature-selection/](https://machinelearningmastery.com/an-introduction-to-feature-selection/)。
- en: Best practices for machine learning
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的最佳实践
- en: In the previous sections, we saw how to perform feature engineering to enhance
    the performance of our machine learning system. Now, we are going to discuss some
    tips and best practices to build robust intelligent systems. Let's explore some
    of the best practices in the different aspects of machine learning projects.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们看到了如何进行特征工程来增强我们的机器学习系统的性能。现在，我们将讨论一些建立健壮智能系统的技巧和最佳实践。让我们探索机器学习项目不同方面的一些最佳实践。
- en: Information security datasets
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信息安全数据集
- en: 'Data is a vital part of every machine learning model. To train models, we need
    to feed them datasets. While reading the earlier chapters, you will have noticed
    that to build an accurate and efficient machine learning model, you need a huge
    volume of data, even after cleaning data. Big companies with great amounts of
    available data use their internal datasets to build models, but small organizations,
    like startups, often struggle to acquire such a volume of data. International
    rules and regulations are making the mission harder because data privacy is an
    important aspect in information security. Every modern business must protect its
    users'' data. To solve this problem, many institutions and organizations are delivering
    publicly available datasets, so that others can download them and build their
    models for educational or commercial use. Some information security datasets are
    as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是每个机器学习模型的重要组成部分。为了训练模型，我们需要提供数据集。在阅读之前的章节时，您可能已经注意到，要构建准确和高效的机器学习模型，您需要大量的数据，即使在清理数据之后也是如此。拥有大量可用数据的大公司使用其内部数据集来构建模型，但是像初创公司这样的小组织通常很难获取这么多的数据。国际规则和法规使这一任务变得更加困难，因为数据隐私是信息安全的重要方面。每个现代企业都必须保护其用户的数据。为了解决这个问题，许多机构和组织提供了公开可用的数据集，以便其他人可以下载并构建用于教育或商业用途的模型。一些信息安全数据集如下：
- en: 'The **Controller Area Network** (**CAN**) dataset for intrusion detection (OTIDS):
    [http://ocslab.hksecurity.net/Dataset/CAN-intrusion-dataset](http://ocslab.hksecurity.net/Dataset/CAN-intrusion-dataset)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于入侵检测的**控制区域网络**（**CAN**）数据集（OTIDS）：[http://ocslab.hksecurity.net/Dataset/CAN-intrusion-dataset](http://ocslab.hksecurity.net/Dataset/CAN-intrusion-dataset)
- en: 'The car-hacking dataset for intrusion detection: [http://ocslab.hksecurity.net/Datasets/CAN-intrusion-dataset](http://ocslab.hksecurity.net/Datasets/CAN-intrusion-dataset)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于入侵检测的汽车黑客数据集：[http://ocslab.hksecurity.net/Datasets/CAN-intrusion-dataset](http://ocslab.hksecurity.net/Datasets/CAN-intrusion-dataset)
- en: 'The web-hacking dataset for cyber criminal profiling: [http://ocslab.hksecurity.net/Datasets/web-hacking-profiling](http://ocslab.hksecurity.net/Datasets/web-hacking-profiling)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于网络犯罪分析的网络黑客数据集：[http://ocslab.hksecurity.net/Datasets/web-hacking-profiling](http://ocslab.hksecurity.net/Datasets/web-hacking-profiling)
- en: 'The **API-based malware detection system** (**APIMDS**) dataset: [http://ocslab.hksecurity.net/apimds-dataset](http://ocslab.hksecurity.net/apimds-dataset)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于API的恶意软件检测系统**（**APIMDS**）数据集：[http://ocslab.hksecurity.net/apimds-dataset](http://ocslab.hksecurity.net/apimds-dataset)'
- en: 'The intrusion detection evaluation dataset (CICIDS2017): [http://www.unb.ca/cic/datasets/ids-2017.html](http://www.unb.ca/cic/datasets/ids-2017.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 入侵检测评估数据集（CICIDS2017）：[http://www.unb.ca/cic/datasets/ids-2017.html](http://www.unb.ca/cic/datasets/ids-2017.html)
- en: 'The Tor-nonTor dataset: [http://www.unb.ca/cic/datasets/tor.html](http://www.unb.ca/cic/datasets/tor.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tor-nonTor数据集：[http://www.unb.ca/cic/datasets/tor.html](http://www.unb.ca/cic/datasets/tor.html)
- en: 'The Android adware and general malware dataset: [http://www.unb.ca/cic/datasets/android-adware.html](http://www.unb.ca/cic/datasets/android-adware.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Android广告软件和一般恶意软件数据集：[http://www.unb.ca/cic/datasets/android-adware.html](http://www.unb.ca/cic/datasets/android-adware.html)
- en: Project Jupyter
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jupyter项目
- en: The Jupyter Notebook is an open source web application used to create and share
    coding documents. I highly recommend it, especially for novice data scientists,
    for many reasons. It will give you the ability to code and visualize output directly.
    It is great for discovering and playing with data; exploring data is an important
    step to building machine learning models.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook是一个开源的Web应用程序，用于创建和共享编码文档。我强烈推荐它，特别是对于新手数据科学家，原因有很多。它将使您能够直接编写和可视化输出。它非常适合发现和处理数据；探索数据是构建机器学习模型的重要步骤。
- en: 'Jupyter''s official website is [http://jupyter.org/](http://jupyter.org/):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter的官方网站是[http://jupyter.org/](http://jupyter.org/)：
- en: '![](img/00235.jpeg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00235.jpeg)'
- en: 'To install it using `pip`, simply type the following:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`pip`安装它，只需输入以下内容：
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Speed up training with GPUs
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GPU加速训练
- en: As you know, even with good feature engineering, training in machine learning
    is computationally expensive. The quickest way to train learning algorithms is
    to use **graphics processing units** (**GPUs**). Generally, though not in all
    cases, using GPUs is a wise decision for training models. In order to overcome
    CPU performance bottlenecks, the gather/scatter GPU architecture is best, performing
    parallel operations to speed up computing.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所知，即使进行了良好的特征工程，机器学习训练在计算上是昂贵的。训练学习算法的最快方法是使用**图形处理单元**（**GPU**）。一般来说，虽然不是所有情况，使用GPU是训练模型的明智决定。为了克服CPU性能瓶颈，最好使用聚集/分散GPU架构，执行并行操作以加快计算速度。
- en: 'TensorFlow supports the use of GPUs to train machine learning models. Hence,
    the devices are represented as strings; following is an example:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow支持使用GPU来训练机器学习模型。因此，设备被表示为字符串；以下是一个例子：
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To use a GPU device in TensorFlow, you can add the following line:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要在TensorFlow中使用GPU设备，可以添加以下行：
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You can use a single GPU or multiple GPUs. Don''t forget to install the CUDA
    toolkit, by using the following commands:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用单个GPU或多个GPU。不要忘记安装CUDA工具包，使用以下命令：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Install cuDNN as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下方式安装cuDNN：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Selecting models and learning curves
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择模型和学习曲线
- en: 'To improve the performance of machine learning models, there are many hyper
    parameters to adjust. The more data that is used, the more errors that can happen.
    To work on these parameters, there is a method called `GridSearchCV`. It performs
    searches on predefined parameter values, through iterations. `GridSearchCV` uses
    the `score()` function, by default. To use it in scikit-learn, import it by using
    this line:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高机器学习模型的性能，有许多超参数需要调整。使用的数据越多，出现的错误就越多。为了处理这些参数，有一种称为`GridSearchCV`的方法。它通过迭代在预定义的参数值上执行搜索。`GridSearchCV`默认使用`score()`函数。要在scikit-learn中使用它，可以使用以下行导入：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Learning curves are used to understand the performance of a machine learning
    model. To use a learning curve in scikit-learn, import it to your Python project,
    as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线用于了解机器学习模型的性能。要在scikit-learn中使用学习曲线，可以将其导入到Python项目中，如下所示：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Machine learning architecture
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习架构
- en: 'In the real world, data scientists do not find data to be as clean as the publicly
    available datasets. Real world data is stored by different means, and the data
    itself is shaped in different categories. Thus, machine learning practitioners
    need to build their own systems and pipelines to achieve their goals and train
    the models. A typical machine learning project respects the following architecture:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，数据科学家并不认为数据像公开可用的数据集那样干净。现实世界的数据以不同的方式存储，数据本身也以不同的类别呈现。因此，机器学习从业者需要构建自己的系统和流程来实现他们的目标并训练模型。典型的机器学习项目遵循以下架构：
- en: '![](img/00236.jpeg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00236.jpeg)'
- en: Coding
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编码
- en: Good coding skills are very important to data science and machine learning.
    In addition to using effective linear algebra, statistics, and mathematics, data
    scientists should learn how to code properly. As a data scientist, you can choose
    from many programming languages, like Python, R, Java, and so on.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的编码技能对于数据科学和机器学习非常重要。除了使用有效的线性代数、统计学和数学，数据科学家还应该学会如何正确编码。作为一名数据科学家，你可以选择许多编程语言，比如Python、R、Java等。
- en: 'Respecting coding''s best practices is very helpful and highly recommended.
    Writing elegant, clean, and understandable code can be done through these tips:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 尊重编码的最佳实践非常有帮助，也强烈推荐。通过以下提示可以编写优雅、清晰和易懂的代码：
- en: Comments are very important to understandable code. So, don't forget to comment
    your code, all of the time.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注释对于可理解的代码非常重要。因此，不要忘记一直对代码进行注释。
- en: Choose the right names for variables, functions, methods, packages, and modules.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为变量、函数、方法、包和模块选择正确的名称。
- en: Use four spaces per indentation level.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个缩进级别使用四个空格。
- en: Structure your repository properly.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确结构化你的存储库。
- en: Follow common style guidelines.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵循常见的样式指南。
- en: 'If you use Python, you can follow this great aphorism, called the *The Zen
    of Python,* written by the legend, Tim Peters:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用Python，你可以遵循这个伟大的格言，称为*Python之禅*，由传奇人物Tim Peters撰写：
- en: '"Beautiful is better than ugly.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '"美丽胜过丑陋。'
- en: Explicit is better than implicit.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 显式胜于隐式。
- en: Simple is better than complex.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 简单胜于复杂。
- en: Complex is better than complicated.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂胜于复杂。
- en: Flat is better than nested.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 扁平胜于嵌套。
- en: Sparse is better than dense.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏胜于密集。
- en: Readability counts.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 可读性很重要。
- en: Special cases aren't special enough to break the rules.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊情况并不特别到足以打破规则。
- en: Although practicality beats purity.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管实用性胜过纯粹性。
- en: Errors should never pass silently.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 错误不应该悄悄地传递。
- en: Unless explicitly silenced.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 除非明确地被压制。
- en: In the face of ambiguity, refuse the temptation to guess.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 面对模棱两可的情况，拒绝猜测的诱惑。
- en: There should be one-- and preferably only one --obvious way to do it.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 应该有一种——最好只有一种——明显的方法来做到这一点。
- en: Although that way may not be obvious at first unless you're Dutch.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方式一开始可能不太明显，除非你是荷兰人。
- en: Now is better than never.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在胜于永远。
- en: Although never is often better than *right* now.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从来没有比*现在*更好。
- en: If the implementation is hard to explain, it's a bad idea.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实现难以解释，那就是一个坏主意。
- en: If the implementation is easy to explain, it may be a good idea.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实现容易解释，那可能是一个好主意。
- en: Namespaces are one honking great idea -- let's do more of those!"
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间是一个伟大的想法——让我们做更多这样的事情！
- en: Data handling
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理
- en: Good data handling leads to successfully building machine learning projects.
    After loading a dataset, please make sure that all of the data has loaded properly,
    and that the reading process is performing correctly. After performing any operation
    on the dataset, check over the resulting dataset.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的数据处理有助于成功构建机器学习项目。加载数据集后，请确保所有数据都已正确加载，并且读取过程正在正确执行。在对数据集执行任何操作后，请检查生成的数据集。
- en: Business contexts
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业背景
- en: An intelligent system is highly connected to business aspects because, after
    all, you are using data science and machine learning to solve a business issue
    or to build a commercial product, or for getting useful insights from the data
    that is acquired, to make good decisions. Identifying the right problems and asking
    the right questions are important when building your machine learning model, in
    order to solve business issues.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 智能系统与业务方面高度相关，毕竟您正在使用数据科学和机器学习来解决业务问题或构建商业产品，或者从获取的数据中获得有用的见解，以做出明智的决策。在构建机器学习模型时，识别正确的问题并提出正确的问题是重要的，以解决业务问题。
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This book was a practical guide for learning how to build machine learning projects
    to defend against cyber threats and malicious activities, using open source libraries,
    Python, and a set of open source projects. We didn't stop there; we also showed
    you how to attack those models using adversarial machine learning. Through that,
    you acquired a set of skills to analyze data, build defensive systems, and break
    next-generation safeguards. We finished the book by discussing many points to
    help you build better models.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是一个实用指南，教你如何使用开源库、Python和一套开源项目来构建机器学习项目，以抵御网络威胁和恶意活动。我们不止于此；我们还向您展示了如何使用对抗机器学习来攻击这些模型。通过这样做，您获得了一套分析数据、构建防御系统和突破下一代安全防护的技能。我们在书中讨论了许多观点，以帮助您构建更好的模型。
- en: Questions
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the difference between feature engineering and feature selection?
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征工程和特征选择有什么区别？
- en: What is the difference between principal component analysis (PCA) and feature
    selection?
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）和特征选择有什么区别？
- en: How can we encode features like dates and hours?
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何对日期和小时等特征进行编码？
- en: Why it is useful to print out training and testing accuracy?
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么打印出训练和测试准确性很有用？
- en: How can we deploy a machine learning model and use it in a product?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何部署机器学习模型并在产品中使用它？
- en: Why does feature engineering take much more time than other steps?
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么特征工程比其他步骤花费更多时间？
- en: What is the role of a dummy variable?
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虚拟变量的作用是什么？
- en: Further reading
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '**Papers and slides**:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**论文和幻灯片**：'
- en: '*Feature Engineering* - *Knowledge Discovery and Data Mining 1*, by Roman Kern:
    [http://kti.tugraz.at/staff/denis/courses/kddm1/featureengineering.pdf](http://kti.tugraz.at/staff/denis/courses/kddm1/featureengineering.pdf)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程* - *知识发现与数据挖掘1*，作者：Roman Kern：[http://kti.tugraz.at/staff/denis/courses/kddm1/featureengineering.pdf](http://kti.tugraz.at/staff/denis/courses/kddm1/featureengineering.pdf)'
- en: '*Feature Engineering and Selection* ([https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf))
    - *CS 294: Practical Machine Learning,* Berkeley: [https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程和选择*（[https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf)）-
    *CS 294：实用机器学习*，伯克利：[https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/)'
- en: '*Feature Engineering* by Leon Bottou, Princeton: [http://www.cs.princeton.edu/courses/archive/spring10/cos424/slides/18-feat.pdf](http://www.cs.princeton.edu/courses/archive/spring10/cos424/slides/18-feat.pdf)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程* 作者：Leon Bottou，普林斯顿：[http://www.cs.princeton.edu/courses/archive/spring10/cos424/slides/18-feat.pdf](http://www.cs.princeton.edu/courses/archive/spring10/cos424/slides/18-feat.pdf)'
- en: '**Blog posts**:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**博客文章**：'
- en: '*Discover Feature Engineering - How to Engineer Features and How to Get Good
    at It:* [https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*发现特征工程-如何进行特征工程以及如何擅长它*：[https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)'
- en: '*Machine Learning Mastery*: [https://machinelearningmastery.com/start-here/](https://machinelearningmastery.com/start-here/)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习精通*：[https://machinelearningmastery.com/start-here/](https://machinelearningmastery.com/start-here/)'
- en: '**Books**:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**书籍**：'
- en: '*Feature Extraction, Construction, and Selection: A Data Mining Perspective*:
    [https://www.amazon.com/dp/0792381963?tag=inspiredalgor-20](https://www.amazon.com/dp/0792381963?tag=inspiredalgor-20)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征提取、构造和选择：数据挖掘视角*：[https://www.amazon.com/dp/0792381963?tag=inspiredalgor-20](https://www.amazon.com/dp/0792381963?tag=inspiredalgor-20)'
- en: '*Feature Extraction: Foundations and Applications*: [https://www.amazon.com/dp/3540354875?tag=inspiredalgor-20](https://www.amazon.com/dp/3540354875?tag=inspiredalgor-20)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征提取：基础和应用*：[https://www.amazon.com/dp/3540354875?tag=inspiredalgor-20](https://www.amazon.com/dp/3540354875?tag=inspiredalgor-20)'
- en: '*Feature Extraction and Image Processing for Computer Vision, Third Edition:*
    [https://www.amazon.com/dp/0123965497?tag=inspiredalgor-20](https://www.amazon.com/dp/0123965497?tag=inspiredalgor-20)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算机视觉的特征提取和图像处理，第三版*：[https://www.amazon.com/dp/0123965497?tag=inspiredalgor-20](https://www.amazon.com/dp/0123965497?tag=inspiredalgor-20)'
