["```py\nimport network.network as network\nimport network.mnist_loader as mnist_loader\n# To serialize data\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\n```", "```py\nModel = pickle.load( open( \"trained_network.pkl\", \"rb\" ) )    trainData, valData, testData =mnist_loader.load_data_wrapper()\n```", "```py\n>>> data = test_data[1][0]\n>>> activations = Model.feedforward(data)\n>>> prediction = np.argmax(activations) \n```", "```py\n>>> plt.imshow(data.reshape((28,28)), cmap='Greys')\n>>> plt.show()\n```", "```py\ndef input_derivative(net, x, y):\n    \"\"\" Calculate derivatives wrt the inputs\"\"\"\n    nabla_b = [np.zeros(b.shape) for b in net.biases]\n    nabla_w = [np.zeros(w.shape) for w in net.weights]\n\n    # feedforward\n    activation = x\n    activations = [x] # list to store all the activations, layer by layer\n    zs = [] # list to store all the z vectors, layer by layer\n    for b, w in zip(net.biases, net.weights):\n        z = np.dot(w, activation)+b\n        zs.append(z)\n        activation = sigmoid(z)\n        activations.append(activation)\n\n    # backward pass\n    delta = net.cost_derivative(activations[-1], y) * \\\n        sigmoid_prime(zs[-1])\n    nabla_b[-1] = delta\n    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n\n    for l in xrange(2, net.num_layers):\n        z = zs[-l]\n        sp = sigmoid_prime(z)\n        delta = np.dot(net.weights[-l+1].transpose(), delta) * sp\n        nabla_b[-l] = delta\n        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n    return net.weights[0].T.dot(delta)\n```", "```py\ngoal = np.zeros((10, 1))\ngoal[n] = 1\n```", "```py\nx = np.random.normal(.5, .3, (784, 1))\n```", "```py\nfor i in range(steps):\n        # Calculate the derivative\n        d = input_derivative(net,x,goal)       \n        x -= eta * d       \n    return x\n\n```", "```py\na = adversarial(net, n, 1000, 1)\nx = np.round(net.feedforward(a), 2)\nPrint (\"The input is:\", str(x))\nPrint (\"The prediction is\", str(np.argmax(x)))\n```", "```py\nplt.imshow(a.reshape(28,28), cmap='Greys')\nplt.show()\n```", "```py\npip install foolbox\n```", "```py\nimport foolbox\nimport keras\nimport numpy as np\nfrom keras.applications.resnet50 import ResNet50\n\nkeras.backend.set_learning_phase(0)\nkmodel = ResNet50(weights='imagenet')\npreprocessing = (np.array([104, 116, 123]), 1)\nfmodel = foolbox.models.KerasModel(kmodel, bounds=(0, 255), preprocessing=preprocessing)\n\nimage, label = foolbox.utils.imagenet_example()\nattack = foolbox.attacks.FGSM(fmodel)\nadversarial = attack(image[:, :, ::-1], label)\n```", "```py\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.subplot(1, 3, 1)\nplt.title('Original')\nplt.imshow(image / 255) \nplt.axis('off')\nplt.subplot(1, 3, 2)\nplt.title('Adversarial')\nplt.imshow(adversarial[:, :, ::-1] / 255)  # ::-1 to convert BGR to RGB\nplt.axis('off')\nplt.subplot(1, 3, 3)\nplt.title('Difference')\ndifference = adversarial[:, :, ::-1] - image\nplt.imshow(difference / abs(difference).max() * 0.2 + 0.5)\nplt.axis('off')\nplt.show()\n```", "```py\npip install -r requirements.txt \n```", "```py\ncp project.conf.template project.conf\nVi  project.conf\n```", "```py\n./utils/detection_agent_server.py ./utils/36vms_sigs.pickle\n```", "```py\n./utils/generate_ext_genome.py [classifier_name] [benign_sample_folder] [file_number]\n```", "```py\ngenerator = Sequential([\nDense(128, input_shape=(100,)),\nLeakyReLU(alpha=0.01),\nDense(784),\nActivation('tanh')\n], name='generator')\n```", "```py\ndiscriminator = Sequential([\nDense(128, input_shape=(784,)),\nLeakyReLU(alpha=0.01),\nDense(1),\nActivation('sigmoid')], name='discriminator')\n```", "```py\ngan = Sequential([\ngenerator,\ndiscriminator])\n```", "```py\nimport pickle as pkl\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nbatch_size = 100\nepochs = 100\nsamples = []\nlosses = []\nsaver = tf.train.Saver(var_list=g_vars)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for e in range(epochs):\n        for ii in range(mnist.train.num_examples//batch_size):\n            batch = mnist.train.next_batch(batch_size)\n\n            batch_images = batch[0].reshape((batch_size, 784))\n            batch_images = batch_images*2 - 1\n\n            batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n\n            _ = sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n            _ = sess.run(g_train_opt, feed_dict={input_z: batch_z})\n\n        train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images})\n        train_loss_g = g_loss.eval({input_z: batch_z})\n\n        print(\"Epoch {}/{}...\".format(e+1, epochs),\n              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n              \"Generator Loss: {:.4f}\".format(train_loss_g))    \n\n        losses.append((train_loss_d, train_loss_g))\n\n        sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n        gen_samples = sess.run(\n                       generator(input_z, input_size, n_units=g_hidden_size, reuse=True, alpha=alpha),\n                       feed_dict={input_z: sample_z})\n        samples.append(gen_samples)\n        saver.save(sess, './checkpoints/generator.ckpt')\nwith open('train_samples.pkl', 'wb') as f:\n    pkl.dump(samples, f)\n```", "```py\nWhile not converging do:\n    Sample a minibatch of Malware M\n    Generate adversarial samples M' from the generator\n    Sample a minibatch of Goodware B\n    Label M' and B using the detector\n    Update the weight of the detector\n    Update the generator weights\nEnd while\n```", "```py\ngit clone https://github.com/openai/gym\ncd gym\npip install -e\n```", "```py\nCartPole-v0 environment:\n```", "```py\nimport gym\n env = gym.make('CartPole-v0')\n env.reset()\n for _ in range(1000): # run for 1000 steps\n    env.render()\n    action = env.action_space.sampe() # pick a random action\n    env.step(action) # take action\n```", "```py\npip install https://github.com/lief-project/LIEF/releases/download/0.7.0/linux_lief-0.7.0_py3.6.tar.gz\n```", "```py\npython test_agent_chainer.py\n```"]