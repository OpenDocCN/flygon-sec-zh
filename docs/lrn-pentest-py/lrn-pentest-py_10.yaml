- en: Chapter 10. Adding Permanency to Python Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章。为Python工具增加永久性
- en: Python has enormous capabilities, and we have only scratched the surface of
    the tools and techniques available for us as assessors. We are going to cover
    a few of the more advanced features of the Python language that can be helpful
    to us. Specifically, we are going to highlight how we can build logging into our
    scripts and then develop multithreaded and multiprocessing tools. Adding in these
    more advanced capabilities means that the tools you develop will be more resilient
    to the test of time and stand apart from other solutions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Python具有巨大的能力，我们只是挖掘了作为评估者可用的工具和技术的一部分。我们将介绍Python语言的一些更高级功能，这些功能对我们很有帮助。具体来说，我们将重点介绍如何将日志记录集成到我们的脚本中，然后开发多线程和多进程工具。添加这些更高级的功能意味着您开发的工具将更加经受时间的考验，并脱颖而出。
- en: Understanding logging within Python
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解Python中的日志记录
- en: As you write your own modules, such as the one highlighted in [Chapter 9](ch09.html
    "Chapter 9. Automating Reports and Tasks with Python"), *Automating Reports and
    Tasks with Python*, you would want to be able to track errors, warnings, and debug
    messages easily. The logger library allows you to track events and output them
    to **Standard Error** (**STDERR**), files, and **Standard Output** (**STDOUT**).
    The benefit to using logger is that the format can be easily defined and sent
    to the relevant output using specific message types. The messages are similar
    to syslog messages, and they mimic the same logging levels.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当您编写自己的模块时，比如在[第9章](ch09.html "第9章。使用Python自动化报告和任务")中突出显示的模块，*使用Python自动化报告和任务*，您希望能够轻松跟踪错误、警告和调试消息。日志记录库允许您跟踪事件并将其输出到标准错误（STDERR）、文件和标准输出（STDOUT）。使用日志记录的好处是可以轻松定义格式，并使用特定的消息类型将其发送到相关的输出。这些消息类似于syslog消息，并且模仿相同的日志级别。
- en: Note
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: More details about the logger library can be found at [https://docs.python.org/2/library/logging.html](https://docs.python.org/2/library/logging.html).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 有关日志记录库的更多详细信息，请访问[https://docs.python.org/2/library/logging.html](https://docs.python.org/2/library/logging.html)。
- en: Understanding the difference between multithreading and multiprocessing
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解多线程和多进程之间的区别
- en: 'There are two different ways in which simultaneous requests can be executed
    within Python: multithreading and multiprocessing. Often, these two items are
    confused with each other, and when you read about them, you will see similar responses
    on blogs and newsgroups. If you are speaking about using multiple processors and
    processing cores, you are talking about multiprocessing. If you are staying within
    the same memory block but not using multiple cores or processes, then you are
    talking about multithreading. Multithreading, in turn, runs concurrent code but
    does not execute tasks in parallel due to the Python interpreter''s design.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中有两种不同的方式可以执行同时的请求：多线程和多进程。通常，这两个项目会被混淆在一起，当您阅读有关它们的内容时，您会在博客和新闻组上看到类似的回应。如果您谈论使用多个处理器和处理核心，您正在谈论多进程。如果您留在同一内存块中，但不使用多个核心或进程，那么您正在谈论多线程。多线程又会运行并发代码，但由于Python解释器的设计，不会并行执行任务。
- en: Tip
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you review [Chapter 8](ch08.html "Chapter 8. Exploit Development with Python,
    Metasploit, and Immunity"), *Exploit Development with Python, Metasploit, and
    Immunity*, and look at the defined areas of the Windows memory, you will gain
    a better understanding of how threads and processes work within the Windows memory
    structure. Keep in mind that the manner in which other **Operating Systems** (**OS**)
    handle these memory locations is different.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您回顾[第8章](ch08.html "第8章。使用Python、Metasploit和Immunity进行利用开发"), *使用Python、Metasploit和Immunity进行利用开发*，并查看Windows内存的定义区域，您将更好地理解线程和进程在Windows内存结构中的工作方式。请记住，其他操作系统（OS）处理这些内存位置的方式是不同的。
- en: Creating a multithreaded script in Python
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Python中创建多线程脚本
- en: To understand the limitations of multithreading, you have to understand the
    Python interpreter. The Python interpreter uses a **Global Interpreter Lock**
    (**GIL**), which means that when byte code is executed by a thread, it is done
    by a thread at a time.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解多线程的限制，您必须了解Python解释器。Python解释器使用全局解释器锁（GIL），这意味着当字节码由一个线程执行时，它是一次执行一个线程。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To better understand GIL, view the documentation at [https://docs.python.org/2/glossary.html#term-global-interpreter-lock](https://docs.python.org/2/glossary.html#term-global-interpreter-lock).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要更好地了解GIL，请查看[https://docs.python.org/2/glossary.html#term-global-interpreter-lock](https://docs.python.org/2/glossary.html#term-global-interpreter-lock)上的文档。
- en: This prevents problems related to data structure manipulation by more than one
    thread at a time. Think about data being written to a dictionary and you referencing
    different pieces of data by the same key in concurrent threads. You would clobber
    some of the data that you intended to write to the dictionary.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以防止由多个线程同时操作数据结构引起的问题。想象一下数据被写入字典，您在并发线程中使用相同的键引用不同的数据片段。您会破坏一些您打算写入字典的数据。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For multithreaded Python applications, you will hear a term called **thread
    safe**. This means, "Can something be modified by a thread without impacting the
    integrity or availability of the data or not?" Even if something is not considered
    **thread safe**, you can use locks, which is described later, to control the data
    entry as necessary.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多线程的Python应用程序，您会听到一个称为“线程安全”的术语。这意味着，“某物是否可以被线程修改而不影响数据的完整性或可用性？”即使某些东西被认为不是“线程安全”的，您也可以使用稍后描述的锁来控制数据输入。
- en: 'We are going to use the `head_request.py` script we previously created in [Chapter
    6](ch06.html "Chapter 6. Assessing Web Applications with Python"), *Assessing
    Web Applications with Python*, and we are going to mature it as a new script.
    This script will use a queue to hold all the tasks that need to be processed,
    which will be assigned dynamically during execution. This queue is built by reading
    values from a file and storing them for later processing. We will incorporate
    the new logger library to output the details to a `results.log` file as the script
    executes. The following screenshot shows the results of this new script after
    execution:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们在[第6章](ch06.html "第6章。使用Python评估Web应用程序")中之前创建的`head_request.py`脚本，并将其成熟为一个新脚本。此脚本将使用队列来保存需要处理的所有任务，这些任务将在执行期间动态分配。此队列是通过从文件中读取值并将其存储以供以后处理而构建的。我们将整合新的记录器库，将详细信息输出到`results.log`文件中，脚本执行时。以下屏幕截图显示了执行后此新脚本的结果：
- en: '![Creating a multithreaded script in Python](img/B04315_10_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![在Python中创建多线程脚本](img/B04315_10_01.jpg)'
- en: 'Additionally, the following highlighted log file contains the detailed execution
    of the script and the concurrent thread''s output:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下突出显示的日志文件包含了脚本的详细执行和并发线程的输出：
- en: '![Creating a multithreaded script in Python](img/B04315_10_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![在Python中创建多线程脚本](img/B04315_10_02.jpg)'
- en: Note
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This script can be found at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_threaded.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_threaded.py).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本可以在[https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_threaded.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_threaded.py)找到。
- en: 'Now, with the goal in sight, we begin with what libraries need to be imported
    and configure two global variables. The first variable holds our queued workload,
    and the second is used to lock the thread for a moment so that data can be printed
    on the screen:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，目标已在视野中，我们开始导入需要的库，并配置两个全局变量。第一个变量保存我们的排队工作量，第二个用于暂时锁定线程，以便可以在屏幕上打印数据：
- en: Note
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Remember the following: concurrent processing means that items are processed.
    The details are provided as executed, and displaying this can come out garbled
    at the console. To combat this, we use a lock to pause the execution sufficiently
    to return the necessary details. The logger is a thread-safe library, but print
    is not and other libraries may not be either. As such, use locks where appropriate.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住以下内容：并发处理意味着项目正在处理。详细信息将按执行的顺序提供，并且在控制台上显示可能会混乱。为了解决这个问题，我们使用锁来暂停执行，以足够时间返回必要的详细信息。记录器是一个线程安全的库，但打印不是，其他库可能也不是。因此，在适当的地方使用锁。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After this, we need to create the class that will spawn threads, with the only
    new constructor concept being `threading.Thread.__init__(self)`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们需要创建将生成线程的类，唯一的新构造概念是`threading.Thread.__init__(self)`：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, we need to create a function that will process the actual data in each
    of these threads. The function starts off by defining the initial values, and
    as you can see, these values are extracted from the queue. They represent an **Internet
    Protocol** (**IP**) address that was loaded into the queue from a file:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要创建一个函数，将在每个线程中处理实际数据。该函数首先通过定义初始值开始，如您所见，这些值是从队列中提取的。它们代表从文件加载到队列中的**Internet
    Protocol**（**IP**）地址：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'From here, we are going to process both insecure and secure versions of the
    host''s potential websites. The following code, which is for the insecure portion
    of the website, does a job similar to the script highlighted in [Chapter 6](ch06.html
    "Chapter 6. Assessing Web Applications with Python"), *Assessing Web Applications
    with Python*. The only difference is that we have added the new logger functions
    to print the details to a results log file. As you can see in following code,
    writing the details to the logger is almost identical to writing a print statement.
    You will also notice that we have used the `with` statement to lock the thread
    processes so that the details can be printed. This is not necessary for I**/O**,
    but it would be difficult to read otherwise:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，我们将处理主机潜在网站的不安全和安全版本。下面的代码是用于网站不安全部分的，它执行的工作类似于[第6章](ch06.html "第6章。使用Python评估Web应用程序")中突出显示的脚本，*使用Python评估Web应用程序*。唯一的区别是我们添加了新的记录器函数，将详细信息打印到结果日志文件中。如下代码所示，将详细信息写入记录器几乎与编写打印语句相同。您还会注意到，我们使用`with`语句锁定线程进程，以便可以打印详细信息。这对I**/O**来说并不是必需的，但否则将很难阅读：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The secure portion of the request-response instructions is almost identical
    to the non-secure portion of the code, as shown here:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请求-响应指令的安全部分几乎与代码的非安全部分相同，如下所示：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, this function lists the task that was provided as done:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，此函数列出了提供的任务已完成：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As highlighted before, the arguments and options are configured very similarly
    to other scripts. So, for the sake of brevity, these have been omitted, but they
    can be found in the aforementioned link. What has changed, however, is the configuration
    of the logger. We set up a variable that can have a log file''s name passed by
    argument. We then configure the logger so that it is at the appropriate level
    for outputting to a file, and the format stamps the output of the thread to include
    the time, thread name, logging level, and actual message. Finally, we configure
    the object that will be used as a reference for all logging operations:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，参数和选项的配置与其他脚本非常相似。因此，为了简洁起见，这些已被省略，但可以在上述链接中找到。但是，已更改的是记录器的配置。我们设置了一个可以通过参数传递日志文件名的变量。然后配置记录器，使其处于适当的级别以输出到文件，并且格式将线程的输出包括时间、线程名称、日志级别和实际消息。最后，我们配置将用作所有记录操作的引用的对象：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With the logger all set up, we can actually set up the final lines of code
    necessary to make the script multithreaded. We load all the targets into a list
    from the file, then parse the list into the queue. We could have done this a little
    tighter, but the following format is easier to read. We then generate workers
    and set `setDaemon` to `True` so that the script terminates after the main thread
    completes, which prevents the script from hanging:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录器设置好后，我们实际上可以设置使脚本多线程运行所需的最终代码行。我们从文件中将所有目标加载到列表中，然后将列表解析到队列中。我们本可以做得更紧凑一些，但以下格式更易于阅读。然后我们生成工作线程，并将`setDaemon`设置为`True`，以便在主线程完成后终止脚本，从而防止脚本挂起：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The preceding details create a functional multithreaded Python script, but there
    are problems. Python multithreading is very error-prone. Even with a well-written
    script, you can have different errors returned on each iteration. Additionally,
    it takes a significant amount of code to accomplish relatively minute tasks, as
    shown in the preceding code. Finally, depending on the situation and the OS that
    your script is being executed on, threading may not improve the processing performance.
    Another solution is to use multiprocessing instead of multithreading, which is
    easier to code, is less error-prone, and (again) can use more than one core or
    processor.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的细节创建了一个功能性的多线程Python脚本，但存在问题。Python多线程非常容易出错。即使是编写良好的脚本，每次迭代都可能返回不同的错误。此外，为了完成相对微小的任务，需要大量的代码，如前面的代码所示。最后，根据脚本执行的情况和操作系统，线程可能不会提高处理性能。另一个解决方案是使用多进程而不是多线程，这更容易编码，更少出错，并且（再次）可以使用多个核心或处理器。
- en: Note
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Python has a number of libraries that can support concurrency to make coding
    easier. As an example, handling URLs with currency can be done with simple-requests
    ([http://pythonhosted.org/simple-requests/](http://pythonhosted.org/simple-requests/)),
    which has been built at [http://www.gevent.org/](http://www.gevent.org/). The
    preceding code example was for showing how a concurrent script can be modified
    to include multithreaded support. When maturing a script, you should see whether
    other libraries can enable better functionality directly so as to improve your
    personal knowledge and create scripts that remain relevant.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Python有许多库可以支持并发，使编码更加简单。例如，可以使用simple-requests（[http://pythonhosted.org/simple-requests/](http://pythonhosted.org/simple-requests/)）处理URL，该库已在[http://www.gevent.org/](http://www.gevent.org/)上构建。前面的代码示例是为了展示如何修改并发脚本以包含多线程支持。在成熟脚本时，您应该查看其他库是否可以直接提供更好的功能，以改进您的个人知识并创建保持相关性的脚本。
- en: Creating a multiprocessing script in Python
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Python中创建多进程脚本
- en: 'Before getting into creating a multiprocessing script in Python, you should
    understand the pitfalls that most people run into. This will help you in the future
    as you attempt to mature your tool sets. There are four major issues that you
    will run into with multiprocessing scripts in Python:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建Python中的多进程脚本之前，您应该了解大多数人遇到的问题。这将有助于您在未来尝试成熟您的工具集时。在Python中，您将遇到四个主要问题：
- en: Serialization of objects
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象的序列化
- en: Parallel writing or reading of data and dealing with locks
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行写入或读取数据以及处理锁
- en: Operating system nuances with relevant parallelism **Application Program Interfaces**
    (**APIs**)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统细微差别与相关并行性**应用程序接口**（**API**）
- en: Translation of a current script (threaded or unthreaded script) into a script
    that takes advantage of parallelism
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将当前脚本（线程化或非线程化脚本）翻译成利用并行性的脚本
- en: When writing a multiprocessing script in Python, the biggest hurdle is dealing
    with serialization (known as pickling) and deserialization (known as unpickling)
    of objects. When you are writing your own code related to multiprocessing, you
    may see reference errors to the pickle library. This means that you have run into
    an issue related to the way your data is being serialized.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中编写多进程脚本时，最大的障碍是处理对象的序列化（称为pickling）和反序列化（称为unpickling）。当您编写与多进程相关的自己的代码时，可能会看到对pickle库的引用错误。这意味着您遇到了与数据序列化方式相关的问题。
- en: Note
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Some objects in Python cannot be serialized, so you have to find ways around
    that. The most common way that you will see referenced is by using the `copy_reg`
    library. This library provides a means of defining functions so that they can
    be serialized.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的一些对象无法被序列化，因此您必须找到解决方法。您将看到的最常见的方法是使用`copy_reg`库。该库提供了一种定义函数的方式，以便它们可以被序列化。
- en: As you can imagine, just like concurrent code, writing and reading of data to
    a singular file or some other **Input/Output** (**I/O**) resource will cause issues.
    This is because each core or processor is crunch data at the same time, and for
    the most part, this is handled without the other processes being aware of it.
    So, if you are writing code that needs to output the details, you can lock the
    processes so that the details can be handled appropriately. This capability is
    handled through the use of the `multiprocessing.Lock()` function.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可以想象的那样，就像并发代码一样，向单个文件或其他**输入/输出**（**I/O**）资源写入和读取数据会导致问题。这是因为每个核心或处理器同时处理数据，而大多数情况下，其他进程并不知道。因此，如果您正在编写需要输出详细信息的代码，可以锁定进程，以便适当处理详细信息。这种能力通过使用`multiprocessing.Lock()`函数来处理。
- en: Besides I/O, there is also an additional problem of shared memory used between
    processes. Since these processes run relatively independently (depending on the
    implementation), malleable data that would be referenced in memory can be problematic.
    Thankfully, the `multiprocessing` library provides a number of tools to help us.
    The basic solution is to use `multiprocessing.Values()` and `multiprocessing.Arrays()`,
    which can be shared across processes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了I/O之外，还存在一个共享内存在进程之间使用的额外问题。由于这些进程相对独立运行（取决于实现），在内存中引用的可塑数据可能会有问题。幸运的是，`multiprocessing`库提供了许多工具来帮助我们。基本解决方案是使用`multiprocessing.Values()`和`multiprocessing.Arrays()`，它们可以在进程之间共享。
- en: Note
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Additional details about shared memory and multiprocessing can be found at [https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.sharedctypes](https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.sharedctypes).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有关共享内存和多进程的其他细节可以在[https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.sharedctypes](https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.sharedctypes)找到。
- en: All OSes are not created equal when it comes to process and memory management.
    Understanding how these different operating systems work at these levels is necessary
    for system engineers and developers alike. As assessors, we have the same need
    when developing more advanced tools and creating exploits, as previously highlighted.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理进程和内存管理时，所有操作系统并不相同。了解这些不同操作系统在这些层面上的工作方式对于系统工程师和开发人员来说是必要的。正如之前所强调的，作为评估者，在开发更高级的工具和创建利用时，我们也有同样的需求。
- en: Think about how many times you see a new tool or script come out of and it has
    only been tested on one OS or distribution; when you use it, the product does
    not work elsewhere. Multiprocessing scripts are no different, and when you are
    writing these scripts, keep the final goal in mind. If you have no intention of
    making your script run anywhere other than on Kali, then make sure you test there.
    If you are going to run it on Windows, you need to verify that the same method
    of script design works there as well. Specifically, the entry point for the multiprocessing
    code needs to be within the `main()` function or, in essence, below the check
    to see whether `__name__` is equal to `'__main__':`. If it is not, you may be
    creating a fork bomb, or an infinite loop of spawning processes that eventually
    crashes the system.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 想想你有多少次看到一个新的工具或脚本出现，它只在一个操作系统或发行版上进行了测试；当你使用它时，产品在其他地方无法工作。多进程脚本也不例外，当你编写这些脚本时，要牢记最终目标。如果你没有打算让你的脚本在Kali之外的任何地方运行，那么请确保你在那里进行测试。如果你打算在Windows上运行它，你需要验证相同的脚本设计方法在那里也能工作。具体来说，多进程代码的入口点需要在`main()`函数内，或者说，在检查`__name__`是否等于`'__main__'`之下。如果不是，你可能会创建一个分叉炸弹，或者一个无限循环的生成进程，最终导致系统崩溃。
- en: Note
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To gain a better understanding of Windows' restrictions on the forking of processes
    and Python multiprocessing, you can refer to [https://docs.python.org/2/library/multiprocessing.html#windows](https://docs.python.org/2/library/multiprocessing.html#windows).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要更好地了解Windows对进程分叉和Python多进程的限制，可以参考[https://docs.python.org/2/library/multiprocessing.html#windows](https://docs.python.org/2/library/multiprocessing.html#windows)。
- en: The final consideration is the translation of established scripts into multiprocessing
    scripts. Though there are a large number of demos on the Internet that show a
    user taking a threaded or nonthreaded script and translating it into a multiprocessing
    script, they are usually good for demos only. Translating functional code into
    a multiprocessing script that is both stable and useful typically requires rewriting.
    This is because of the points noted earlier, which highlight the challenges you
    will have to overcome.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后要考虑的是将已建立的脚本转换为多进程脚本。尽管互联网上有大量的演示，展示了用户将一个线程化或非线程化的脚本转换为多进程脚本，但它们通常只适用于演示。将功能代码转换为稳定且有用的多进程脚本通常需要重写。这是因为前面提到的要点，突出了你将不得不克服的挑战。
- en: So what did you learn from all this?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那么你从这一切中学到了什么？
- en: The function that will be executed in parallel must be pickable
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将在并行执行的函数必须是可挑选的
- en: Locks may need to be incorporated while dealing with I/O, and shared memory
    requires specific functions from the multiprocessing library
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理I/O时可能需要加入锁，共享内存需要使用多进程库的特定函数
- en: The main entry point to parallel processes needs to be protected
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行进程的主入口点需要受到保护
- en: Scripts do not easily translate from threaded or unthreaded formats to multiprocessing
    formats, and as such, some thought should go into redesigning them
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 脚本不容易从线程化或非线程化格式转换为多进程格式，因此，一些思考应该放在重新设计它们上
- en: Note
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The details of the arguments and options have been removed for brevity, but
    the full details can be found at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_process.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_process.py).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，参数和选项的详细信息已被删除，但完整的细节可以在[https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_process.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/multi_process.py)找到。
- en: With all of this in mind, we can now rewrite the `head_request.py` script so
    as to accommodate multiple multiprocessing. The `run()` function's code is largely
    rewritten in order to accommodate the objects so that they can be pickled. This
    is because the `host_request` function is what is run by each subprocess. The
    `urllib2` request and responses are objects that are not picklable, and as such,
    the data needs to be converted to a string prior to passing. Additionally, with
    multiprocessing scripts, a logger has to be handled instead of being called directly.
    In this way, the subprocesses know what to write to, using a universal filename
    reference.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些，我们现在可以重写`head_request.py`脚本，以适应多进程。`run()`函数的代码在很大程度上被重写，以适应对象，以便它们可以被pickled。这是因为`host_request`函数是由每个子进程运行的。`urllib2`请求和响应是不可pickable的对象，因此在传递之前需要将数据转换为字符串。此外，使用多进程脚本时，必须处理记录器，而不是直接调用。通过这种方式，子进程知道要写入什么，使用通用文件名引用。
- en: 'This format prevents the file from being written to at the same time by multiple
    processes. To begin with, we create a timestamp, which will be used for reference
    when the log handler is grabbed. The following code highlights the configuration
    of the initial values and the insecure service request and response instructions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这种格式可以防止多个进程同时写入文件。首先，我们创建一个时间戳，这将在抓取日志处理程序时用作参考。以下代码突出了初始值和不安全服务请求和响应指令的配置：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Following the insecure request and response instructions are the secure service
    request and response instructions, as shown here:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在不安全的请求和响应指令之后是安全服务请求和响应指令，如下所示：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After the request and response details have been captured, the details are
    returned and logged appropriately:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在捕获请求和响应细节之后，将适当地返回和记录这些细节：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As mentioned earlier, the logger uses a handler and we accomplish this by creating
    a function that defines the logger''s design. This function will then be called
    by each subprocess using the `initializer` parameter within `multiprocessing.map`.
    This means that we have full control over the logger across processes, and this
    prevents problems with unpickable objects requiring to be passed:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，记录器使用处理程序，我们通过创建一个定义记录器设计的函数来实现这一点。然后，该函数将通过`multiprocessing.map`中的`initializer`参数由每个子进程调用。这意味着我们可以在各个进程之间完全控制记录器，并且这可以防止需要传递的不可拾取对象的问题：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, with all of these details in the `main()` function, we define the **Command-line
    Interface** (**CLI**) for the arguments and options. Then we generate the data
    that will be tested from the target''s file and the argument variables:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`main()`函数中，我们定义了**命令行界面**（**CLI**）以获取参数和选项。然后，我们从目标文件和参数变量生成将被测试的数据：
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Finally, the following code uses the `map` function, which calls the `host_request`
    function as it iterates through the list of targets. The `map` function allows
    a multiprocessing script to queue work in a manner similar to the previous multithreaded
    script. We can then use the processes variable loaded by the CLI argument to define
    the number of subprocesses to spawn, which allows us to dynamically control the
    number of processes that are forked. This is a very much guess-and-check method
    of process control.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，以下代码使用`map`函数，该函数在遍历目标列表时调用`host_request`函数。`map`函数允许多进程脚本以类似于先前多线程脚本的方式排队工作。然后，我们可以使用由CLI参数加载的processes变量来定义要生成的子进程数量，这允许我们动态控制分叉的进程数量。这是一种非常猜测和检查的进程控制方法。
- en: Tip
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'If you wanted to be more specific, another manner would be to determine the
    number of CPU and double it to determine the number of processes. This could be
    accomplished as follows: `processes = multiprocessing.cpu_count() *2`.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要更具体一些，另一种方法是确定CPU的数量，然后将其加倍以确定进程的数量。可以按照以下方式完成：`processes = multiprocessing.cpu_count()
    *2`。
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'With the code generated, we can output the help file to decide how the script
    needs to be run, as shown in the following screenshot:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有了生成的代码，我们可以输出帮助文件，以决定脚本需要如何运行，如下截图所示：
- en: '![Creating a multiprocessing script in Python](img/B04315_10_03.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![在Python中创建多进程脚本](img/B04315_10_03.jpg)'
- en: 'When the script is run, the output itemizes the request successes, failures,
    and relevant processes, as shown in the following screenshot:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本时，输出将详细列出请求的成功、失败和相关进程，如下截图所示：
- en: '![Creating a multiprocessing script in Python](img/B04315_10_04.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![在Python中创建多进程脚本](img/B04315_10_04.jpg)'
- en: 'Finally, the `results.log` file contains the details related to the activity
    produced by the script as shown in the following screenshot:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`results.log`文件包含了脚本产生的活动相关细节，如下截图所示：
- en: '![Creating a multiprocessing script in Python](img/B04315_10_05.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![在Python中创建多进程脚本](img/B04315_10_05.jpg)'
- en: We have now finished our multiprocessing script, which can handle logging in
    a controlled manner. This is the step in the right direction for creating industry-standard
    tools. With additional time, we could attach this script to the `nmap_parser.py`
    script that we created in the last chapter and even generate detailed reports
    using the `nmap_doc_generator.py` script as an example. The combination of these
    capabilities would make the tool even more useful.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完成了我们的多进程脚本，可以以受控方式处理记录。这是朝着创建行业标准工具的正确方向迈出的一步。如果有更多时间，我们可以将此脚本附加到上一章中创建的`nmap_parser.py`脚本，并使用`nmap_doc_generator.py`脚本生成详细报告。这些功能的结合将使工具更加有用。
- en: Building industry-standard tools
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建行业标准工具
- en: Python is a fantastic language and these advanced techniques, which highlight
    controlling threads, processes, I/O, and logging, are pivotal to adding permanency
    to your scripts. There are a number of examples in the industry that help assess
    security, such as Sulley. This is a tool that automates the fuzzing of applications
    in an effort to help identify security weaknesses, the results of which can later
    be used to write Frameworks such as Metasploit. Other tools help harden security
    by improving a code base, such as **Open Web Application Security Project's**
    (**OWASP**) Python Security Project. These are examples of tools that started
    out to fit a missing need and gained strong followings. These tools are mentioned
    here as to highlight what your tools could become with the right focus.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Python是一种很棒的语言，这些高级技术突出了控制线程、进程、I/O和日志记录，对于为您的脚本添加永久性至关重要。行业中有许多示例可以帮助评估安全性，比如Sulley。这是一种自动化应用程序模糊测试的工具，旨在帮助识别安全漏洞，其结果后来可以用于编写类似Metasploit的框架。其他工具通过改进代码库来加固安全性，比如**开放式Web应用安全项目**（**OWASP**）的Python安全项目。这些都是开始时为了满足某种需求而获得强大追随者的工具示例。这些工具在这里提到是为了突出你的工具在正确关注下可能会变成什么样。
- en: Tip
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: As you develop your own tools, keep in mind what your goals are, start small,
    and add capabilities. This will help you make the project manageable and successful,
    and the little rewards related to small successes will push you to engage in bigger
    innovations. Finally, never fear starting over. Many times, code will lead you
    in the right direction once you realize that the manner in which you were doing
    something may not be the right fit.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发自己的工具时，要牢记自己的目标，从小处着手，增加功能。这将有助于使项目易于管理和成功，并与小成功相关的小奖励将推动您进行更大的创新。最后，不要害怕重新开始。许多时候，一旦意识到自己做某事的方式可能不合适，代码就会引导您朝正确的方向发展。
- en: Summary
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: From [Chapter 2](ch02.html "Chapter 2. The Basics of Python Scripting"), *The
    Basics of Python Scripting* to [Chapter 10](ch10.html "Chapter 10. Adding Permanency
    to Python Tools"), *Adding Permanency to Python Tools*, we highlighted incremental
    ways of improving penetration testing scripts. This organic growth of knowledge
    showed how to improve code to meet the evaluation needs of today's environments.
    It also highlighted the fact that there are specific places where scripts fit
    the need that an assessor has, and that there are established tools or projects
    currently in place that can do the intended task. In this chapter, we witnessed
    a culmination of the previous examples to develop tools that are able run concurrent
    code and parallel processes, effectively logging data all the while. I hope you
    have enjoyed this read as much as I have enjoyed writing it.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从[第2章](ch02.html“第2章。Python脚本的基础”)，“Python脚本的基础”到[第10章](ch10.html“第10章。为Python工具添加永久性”)，“为Python工具添加永久性”，我们强调了改进渗透测试脚本的渐进方式。这种知识的有机增长展示了如何改进代码以满足当今环境的评估需求。它还突出了脚本适用于评估人员需求的特定场所，以及当前已经存在可以执行预期任务的已建立的工具或项目。在本章中，我们见证了之前示例的总结，开发了能够运行并发代码和并行进程，同时有效记录数据的工具。希望您喜欢阅读这篇文章，就像我写作时一样享受。
