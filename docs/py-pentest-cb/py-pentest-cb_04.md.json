["```py\npip install bs4 \npip install pandas  \n```", "```py\nimport urllib2 \nimport pandas as pd \nfrom bs4 import BeautifulSoup \n```", "```py\nurl = \"https://www.w3schools.com/html/html_tables.asp\" \ntry: \n    page = urllib2.urlopen(url) \nexcept Exception as e: \n    print e \n    pass \n```", "```py\nsoup = BeautifulSoup(page, \"html.parser\") \ntable = soup.find_all('table')[0] \n```", "```py\nnew_table = pd.DataFrame(columns=['Company', 'Contact', 'Country'], index=range(0, 7)) \n```", "```py\nrow_number = 0 \nfor row in table.find_all('tr'): \n    column_number = 0 \n    columns = row.find_all('td') \n    for column in columns: \n        new_table.iat[row_number, columns_number] = column.get_text() \n        columns_number += 1 \n    row_number += 1  \nprint new_table \n```", "```py\nimport urllib.request \nimport pandas as pd \nfrom bs4 import BeautifulSoup  \nurl = \"https://www.w3schools.com/html/html_tables.asp\" \ntry: \n    page = urllib.request.urlopen(url) \nexcept Exception as e: \n    print(e) \n    pass \nsoup = BeautifulSoup(page, \"html.parser\")  \ntable = soup.find_all('table')[0]  \nnew_table = pd.DataFrame(columns=['Company', 'Contact', 'Country'], index=range(0, 7))  \nrow_number = 0 \nfor row in table.find_all('tr'): \n    column_number = 0 \n    columns = row.find_all('td') \n    for column in columns: \n        new_table.iat[row_number, column_number] = column.get_text() \n        column_number += 1 \n    row_number += 1  \nprint(new_table) \n```", "```py\npip install openpyxl  \n```", "```py\nimport urllib.request \nimport pandas as pd \nfrom bs4 import BeautifulSoup  \nurl = \"https://www.w3schools.com/html/html_tables.asp\" \ntry: \n    page = urllib.request.urlopen(url) \nexcept Exception as e: \n    print(e) \n    pass \nsoup = BeautifulSoup(page, \"html.parser\")  \ntable = soup.find_all('table')[0]  \nnew_table = pd.DataFrame(columns=['Company', 'Contact', 'Country'], index=range(0, 7))  \nrow_number = 0 \nfor row in table.find_all('tr'): \n    column_number = 0 \n    columns = row.find_all('td') \n    for column in columns: \n        new_table.iat[row_number, column_number] = column.get_text() \n        column_number += 1 \n    row_number += 1  \nnew_table.to_csv('table.csv') \n```", "```py\nnew_table.to_excel('table.xlsx') \n```", "```py\npip install xml  \n```", "```py\nfrom urllib.request import urlopen \nfrom xml.etree.ElementTree import parse \n```", "```py\nurl = urlopen('http://feeds.feedburner.com/TechCrunch/Google') \n```", "```py\nxmldoc = parse(url) \n```", "```py\nfor item in xmldoc.iterfind('channel/item'): \n    title = item.findtext('title') \n    desc = item.findtext('description') \n    date = item.findtext('pubDate') \n    link = item.findtext('link')  \n    print(title) \n    print(desc) \n    print(date) \n    print(link) \n    print('---------') \n```", "```py\nfrom urllib2 import urlopen \nfrom xml.etree.ElementTree import parse  \nurl = urlopen('http://feeds.feedburner.com/TechCrunch/Google') \nxmldoc = parse(url) \nxmldoc.write('output.xml') \nfor item in xmldoc.iterfind('channel/item'): \n   title = item.findtext('title') \n   desc = item.findtext('description') \n   date = item.findtext('pubDate') \n   link = item.findtext('link')  \n    print title \n    print desc \n    print date \n    print link \n    print '---------' \n```"]