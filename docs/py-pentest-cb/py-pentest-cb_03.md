# 第三章：使用 Python 进行 Web 抓取

在本章中，我们将涵盖以下配方：

+   使用 Python 脚本下载网页

+   更改用户代理

+   下载文件

+   使用正则表达式从下载的网页中获取信息

+   请求和下载动态网站页面

+   动态 GET 请求

# 介绍

Web 抓取是自动从 Web 中提取数据并以便于您轻松分析或利用的格式的过程。`urllib` Python 模块帮助您从 Web 服务器下载数据。

# 使用 Python 脚本下载网页

要从 Web 服务器下载网页，可以使用标准 Python 库的一部分的`urllib`模块。`urllib`包括用于从 URL 检索数据的函数。

# 准备就绪

要了解基础知识，我们可以使用 Python 交互式终端。在终端窗口中输入`python`并按*Enter*。这将打开 Python（Python 2.x）交互式终端。

# 如何做...

在 Python 2.x 和 Python 3.x 中执行此操作的命令存在一些差异，主要是`print`语句。因此，请注意语法上的差异。这将有助于我们即将介绍的配方。

# 使用 Python 2

1.  首先，导入所需的模块`urllib`：

```py
>>> import urllib  
```

1.  使用`urlopen`方法，您可以下载网页：

```py
>>> webpage = urllib.urlopen("https://www.packtpub.com/")  
```

1.  我们可以使用`read`方法像返回对象一样读取文件：

```py
>>> source =  webpage.read()  
```

1.  完成后关闭对象：

```py
>>>  webpage.close()  
```

1.  现在我们可以打印 HTML，它是以字符串格式存在的：

```py
>>> print source  
```

1.  更新程序以将源字符串的内容写入计算机上的本地文件非常容易：

```py
>>> f = open('packtpub-home.html', 'w')
 >>> f.write(source)
 >>> f.close  
```

# 使用 Python 3

在 Python 3 中，`urllib`和`urllib2`都是`urllib`模块的一部分，因此在使用`urllib`时存在一些差异。此外，`urllib`包含以下模块：

+   `urllib.request`

+   `urllib.error`

+   `urllib.parse`

+   `urllib.robotparser`

`urllib.request`模块用于在 Python 3 中打开和获取 URL：

1.  首先从`urllib`包中导入`urllib.request`模块：

```py
>>> import urllib.request
```

1.  使用`urlopen`方法获取网页：

```py
>>> webpage = urllib.request.urlopen("https://www.packtpub.com/")  
```

1.  使用`read`方法读取对象：

```py
>>> source =  webpage.read()  
```

1.  关闭对象：

```py
>>> webpage.close()  
```

1.  打印源码：

```py
>>> print(source)  
```

1.  您可以将源字符串的内容写入计算机上的本地文件，如下所示。确保输出文件处于二进制模式：

```py
>>> f = open('packtpub-home.html', 'wb')
 >>> f.write(source)
 >>> f.close  
```

Python 2 模块`urllib`和`urllib2`帮助执行与 URL 请求相关的操作，但两者具有不同的功能。

`urllib`提供了`urlencode`方法，用于生成`GET`请求。但是，`urllib2`不支持`urlencode`方法。此外，`urllib2`可以接受请求对象并修改 URL 请求的标头，但`urllib`只能接受 URL，并且无法修改其中的标头。

# 更改用户代理

许多网站使用用户代理字符串来识别浏览器并相应地提供服务。由于我们使用`urllib`访问网站，它不会识别此用户代理并可能以奇怪的方式行事或失败。因此，在这种情况下，我们可以为我们的请求指定用户代理。

# 如何做...

我们在请求中使用自定义用户代理字符串如下：

1.  首先，导入所需的模块：

```py
>>> import urllib.request  
```

1.  然后定义我们计划为请求指定的用户代理：

```py
>>> user_agent = ' Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0'  
```

1.  为请求设置标头：

```py
>>> headers = {'User-Agent': user_agent}  
```

1.  创建请求如下：

```py
>>> request = urllib.request.Request("https://www.packtpub.com/", headers=headers)  
```

1.  使用`urlopen`请求网页：

```py
>>> with urllib.request.urlopen(request) as response:
...     with open('with_new_user_agent.html', 'wb') as out:
...         out.write(response.read())  
```

# 下载文件

我们可以利用`requests` Python 模块下载文件。`requests`模块是 Python 中一个**简单易用**的 HTTP 库，具有各种应用。此外，它有助于与 Web 服务建立无缝的交互。

# 准备就绪

首先，您必须安装`requests`库。可以通过输入以下命令使用`pip`来完成：

```py
pip install requests  
```

# 如何做...

让我们尝试使用`requests`模块下载一个简单的图像文件。打开 Python 2：

1.  像往常一样，首先导入`requests`库：

```py
>>> import requests  
```

1.  通过将 URL 传递给`get`方法创建 HTTP 响应对象：

```py
>>> response = requests.get("https://rejahrehim.com/images/me/rejah.png")  
```

1.  现在将 HTTP 请求发送到服务器并将其保存到文件中：

```py
>>> with open("me.png",'wb') as file:
...           file.write(response.content)
```

如果是一个大文件，`response.``content`将是一个大字符串，无法将所有数据保存在一个字符串中。在这里，我们使用`iter_content`方法以块的方式加载数据。

1.  在这里，我们可以创建一个 HTTP 响应对象作为`stream`：

```py
response = requests.get("https://rejahrehim.com/images/me/rejah.png", stream = True)

```

1.  然后，发送请求并使用以下命令保存文件：

```py
>>> with open("me.png",'wb') as file:
...        for chunk in response.iter_content(chunk_size=1024):
...        if chunk:
...             file.write(chunk) 
```

这将在 Python 3 中起作用。还要确保在 Python 3 环境中安装所需的库。

# 使用正则表达式从下载的网页中获取信息

**正则表达式**（**re**）模块有助于从下载的网页中找到特定的文本模式。正则表达式可用于解析网页中的数据。

例如，我们可以尝试使用正则表达式模块下载网页中的所有图像。

# 如何做...

为此，我们可以编写一个 Python 脚本，可以下载网页中的所有 JPG 图像：

1.  在您的工作目录中创建一个名为`download_image.py`的文件。

1.  在文本编辑器中打开此文件。您可以使用 sublime text3。

1.  像往常一样，导入所需的模块：

```py
import urllib2
import re
from os.path import basename
from urlparse import urlsplit  
```

1.  像在上一个配方中那样下载网页：

```py
url='https://www.packtpub.com/'    
response = urllib2.urlopen(url)
source = response.read()
file = open("packtpub.txt", "w")
file.write(source)
file.close()  
```

1.  现在，迭代下载的网页中的每一行，搜索图像 URL，并下载它们：

```py
patten = '(http)?s?:?(\/\/[^"]*\.(?:png|jpg|jpeg|gif|png|svg))'
for line in open('packtpub.txt'):
    for m in re.findall(patten, line): 
        fileName = basename(urlsplit(m[1])[2])
        try:
            img = urllib2.urlopen('https:' + m[1]).read()
            file = open(fileName, "w")
            file.write(img)
            file.close()
        except:
            pass
        break
```

第一个*for 循环*迭代下载的网页中的行。第二个*for 循环*使用正则表达式模式搜索每一行的图像 URL。

如果找到模式，则使用`urlparse`模块中的`urlsplit()`方法提取图像的文件名。然后，我们下载图像并将其保存到本地系统。

相同的脚本可以以最小的更改重写为 Python 3：

```py
import urllib.request 
import urllib.parse 
import re 
from os.path import basename  
url = 'https://www.packtpub.com/'  
response = urllib.request.urlopen(url) 
source = response.read() 
file = open("packtpub.txt", "wb") 
file.write(source) 
file.close()  
patten = '(http)?s?:?(\/\/[^"]*\.(?:png|jpg|jpeg|gif|png|svg))' 
for line in open('packtpub.txt'): 
    for m in re.findall(patten, line): 
        print('https:' + m[1]) 
        fileName = basename(urllib.parse.urlsplit(m[1])[2]) 
        print(fileName) 
        try: 
            img = urllib.request.urlopen('https:' + m[1]).read() 
            file = open(fileName, "wb") 
            file.write(img) 
            file.close() 
        except: 
            pass 
        break 
```

在 Python 3 中，请求和`urlparse`模块与`urllib`组合为`urllib.request`和`urllib.parse`。使用正则表达式模式，我们可以解析网页的许多有用信息。

您可以在[`docs.python.org/3.7/library/re.html`](https://docs.python.org/3.7/library/re.html)了解更多关于正则表达式模块的信息。

# 请求和下载动态网站页面

对于具有表单或接收用户输入的网站，我们必须提交`GET`请求或`POST`请求。现在让我们尝试使用 Python 创建`GET`请求和`POST`请求。查询字符串是向 URL 添加键值对的方法。

# 转义无效字符

在上一个配方中，如果我们在最后一步中删除 try catch 块，会发生什么？

```py
patten = '(http)?s?:?(\/\/[^"]*\.(?:png|jpg|jpeg|gif|png|svg))' 
for line in open('packtpub.txt'): 
    for m in re.findall(patten, line):          
        fileName = basename(urlsplit(m[1])[2])                
        img = urllib2.urlopen('https:' + m[1]).read() 
        file = open(fileName, "w") 
        file.write(img) 
        file.close()  
        break 
```

由于 URL 格式错误，脚本将在几次请求后失败。URL 中出现了一些额外的字符，这导致了`urllib`请求失败。

# 如何做...

不可能记住哪些字符是无效的，并手动用百分号转义它们，但内置的 Python 模块`urllib.parse`具有解决此问题所需的方法。

现在我们可以尝试通过转义/URL 编码请求来修复这个问题。将脚本重写如下：

```py
patten = '(http)?s?:?(\/\/[^"]*\.(?:png|jpg|jpeg|gif|png|svg))' 
for line in open('packtpub.txt'): 
    for m in re.findall(patten, line): 
        print('https:' + m[1]) 
        fileName = basename(urllib.parse.urlsplit(m[1])[2]) 
        print(fileName) 
        request = 'https:' + urllib.parse.quote(m[1]) 
        img = urllib.request.urlopen(request).read() 
        file = open(fileName, "wb") 
        file.write(img) 
        file.close()  
        break 
```

# 动态 GET 请求

现在我们知道，只要有 URL，Python 就可以以编程方式下载网站。如果我们必须下载多个页面，这些页面只有查询字符串不同，那么我们可以编写一个脚本来做到这一点，而不是反复运行脚本，而是在一次运行中下载我们需要的所有内容。

# 如何做...

查看此 URL- [`www.packtpub.com/all?search=&offset=12&rows=&sort=`](https://www.packtpub.com/all?search=&offset=12&rows=&sort=)。在这里，定义页面号（*offset**）的查询字符串变量是 12 的倍数：

要下载所有这些页面中的所有图像，我们可以将前一个配方重写如下：

1.  导入所需的模块：

```py
import urllib.request 
import urllib.parse 
import re 
from os.path import basename 
```

1.  定义 URL 和查询字符串：

```py
url = 'https://www.packtpub.com/' 
queryString = 'all?search=&offset=' 
```

1.  通过 12 的倍数迭代偏移量：

```py
for i in range(0, 200, 12): 
    query = queryString + str(i) 
    url += query 
    print(url) 
    response = urllib.request.urlopen(url) 
    source = response.read() 
    file = open("packtpub.txt", "wb") 
    file.write(source) 
    file.close() 
    patten = '(http)?s?:?(\/\/[^"]*\.(?:png|jpg|jpeg|gif|png|svg))' 
    for line in open('packtpub.txt'): 
        for m in re.findall(patten, line): 
            print('https:' + m[1]) 
            fileName = basename(urllib.parse.urlsplit(m[1])[2]) 
            print(fileName) 
            request = 'https:' + urllib.parse.quote(m[1]) 
            img = urllib.request.urlopen(request).read() 
            file = open(fileName, "wb") 
            file.write(img) 
            file.close() 
            break 
```
